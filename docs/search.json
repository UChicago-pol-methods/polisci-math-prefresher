[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "University of Chicago Political Science Math Prefresher",
    "section": "",
    "text": "The 2022 UChicago Math Prefresher for incoming Political Science graduate students will be held from September 12-14; September 19-21 and September 23rd. The course is designed as a brief review of math fundamentals – calculus, optimization, probability theory and linear algebra among other topics – as well as an introduction to programming in the R statistical computing language. The course is entirely optional and there are no grades or assignments but we encourage all incoming graduate students to attend if they are able.\n\n\n\nThe course notes for the math and programming sections as well as all practice problems are available on this website and can be accessed by navigating the menus in the sidebar.\n\n\n\nThe prefresher will run for a total of seven days September 12-14, September 19-21 and September 23rd, with breaks for the APSA conference and the new student orientation. Each day will run from around 9am to 4pm with many breaks in between. We will be meeting in room 407 of Pick Hall.\nThe morning will focus on math instruction. We will have two one hour sessions from 9:30am - 10:30am and 10:45am-11:45am, with a ~15 minute break in between. These sessions will involve a combination of lectures and working through practice problems.\nWe will break for lunch from 12:00pm-1:00pm. On September 13th and Spetember 19th, we will have a catered lunch with a faculty member guest. Otherwise, you are free to explore the campus for various lunch options.\nThe afternoon will focus on coding instruction with lecture/demonstration from 1:30pm-2:45pm. After a short break you will work together on a variety of coding exercises from 3:00-3:30pm. In the last 30 minutes we will regroup to wrap up and discuss any questions on the material.\n\n\n\nAs the afternoons of the prefresher will involve instruction in coding, you should be sure to bring a laptop and a charging cable. In addition, prior to the start of the prefresher, please make sure to have installed the following on your computer:\n\nR (version 4.2.1 or higher)\nRStudio Desktop Open Source License (this is the primary IDE or integrated development environment in which we will be working)\nLaTeX: This is primarily to allow you to generate PDF documents using RMarkdown. We will use the TinyTeX LaTeX distribution which is designed to be minimalist and tailored specifically for R users. After installing R and RStudio, open up an instance of R, install the ‘tinytex’ package and run the install_tinytex() command\n\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n\nWe will also spend some time discussing document preparation and typesetting using LaTeX and Markdown. For the former, we will be using the popular cloud platform Overleaf, which allows for collaborative document editing and streamlines a lot of the irritating parts of typesetting in LaTeX. You should register for an account using your university e-mail as all University of Chicago students and faculty have access to an Overleaf Pro account for free.\nYou are also welcome to install a LaTeX editor on your local machine to work alongside the TinyTeX distribution or any other TeX distribution that you prefer such as TexMaker\n\n\n\nThis prefresher draws heavily on the wonderful materials that have been developed by over 20 years of instructors at the Harvard Government Math Prefresher that have been so generously distributed under the GPL 3.0 License. Special thanks to Shiro Kuriwaki, Yon Soo Park, and Connor Jerzak for their efforts in converting the original prefresher materials into the easily distributed Markdown format."
  },
  {
    "objectID": "02_sets_and_functions.html",
    "href": "02_sets_and_functions.html",
    "title": "2  Sets, Operations, and Functions",
    "section": "",
    "text": "Sets are the fundamental building blocks of mathematics. Events are not inherently numerical: the onset of war or the stock market crashing is not inherently a number. Sets can define such events, and we wrap math around so that we have a transparent language to communicate about those events. Combining sets with operations, relations, metrics, measures, etc… allows us to define useful mathematical structures. For example, the set of real numbers (\\(\\mathbb{R}\\)) has a notion of order as well as defined operations of addition and multiplication.\nSet : A set is any well defined collection of elements. If \\(x\\) is an element of \\(S\\), \\(x \\in S\\).\nExamples:\n\nThe set of choices available to a player in Rock-Paper-Scissors \\(\\{\\text{Rock}, \\text{Paper}, \\text{Scissors}\\}\\)\nThe set of possible outcomes of a roll of a six-sided die \\(\\{1, 2, 3, 4, 5, 6\\}\\)\nThe set of all natural numbers \\(\\mathbb{N}\\)\nThe set of all real numbers \\(\\mathbb{R}\\)\n\nCommon mathematical notation relevant to sets:\n\n\\(\\in\\) = “is an element of”; \\(\\notin\\) = “is not an element of”\n\\(\\forall\\) = “for all” (univeral quantifier)\n\\(\\exists\\) = “there exists” (existential quantifier)\n\\(:\\) = “such that”\n\nSubset: If every element of set \\(A\\) is also in set \\(B\\), then \\(A\\) is a subset of \\(B\\). \\(A \\subseteq B\\). If, in addition to being a subset of \\(B\\), \\(A\\) is not equal to \\(B\\), \\(A\\) is a proper subset \\(A \\subset B\\).\nEmpty Set: a set with no elements. \\(S = \\{\\}\\). It is denoted by the symbol \\(\\emptyset\\).\nCardinality: The cardinality of a set \\(S\\), typically written \\(|S|\\) is the number of members of \\(S\\).\nMany sets are infinite. For example, \\(\\mathbb{N}\\) the set of natural numbers \\(\\mathbb{N} = \\{0, 1, 2, 3, 4, \\dotsc\\}\\) - Sets with cardinality less than \\(|\\mathbb{N}|\\) are countable - Sets with the same cardinality as \\(\\\\mathbb{N}|\\) are countably infinite - Sets with greater cardinality than \\(|\\mathbb{N}|\\) are uncountably infinite (e.g. the real numbers).\nSet operations:\n\nUnion: The union of two sets \\(A\\) and \\(B\\), \\(A \\cup B\\), is the set containing all of the elements in \\(A\\) or \\(B\\). \\(A_1 \\cup A_2 \\cup \\cdots \\cup A_n = \\bigcup_{i=1}^n A_i\\)\nIntersection: The intersection of sets \\(A\\) and \\(B\\), \\(A \\cap B\\), is the set containing all of the elements in both \\(A\\) and \\(B\\). \\(A_1 \\cap A_2 \\cap \\cdots \\cap A_n = \\bigcap_{i=1}^n A_i\\)\nComplement: If set \\(A\\) is a subset of \\(S\\), then the complement of \\(A\\), denoted \\(A^C\\), is the set containing all of the elements in \\(S\\) that are not in \\(A\\).\n\nProperties of set operations:\n\nCommutative: \\(A \\cup B = B \\cup A\\); \\(A \\cap B = B \\cap A\\)\nAssociative: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\); \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nDistributive: \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\); \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\nde Morgan’s laws: \\((A \\cup B)^C = A^C \\cap B^C\\); \\((A \\cap B)^C = A^C \\cup B^C\\)\nDisjointness: Sets are disjoint when they do not intersect, such that \\(A \\cap B = \\emptyset\\). A collection of sets is pairwise disjoint (mutually exclusive) if, for all \\(i \\neq j\\), \\(A_i \\cap A_j = \\emptyset\\). A collection of sets form a partition of set \\(S\\) if they are pairwise disjoint and they cover set \\(S\\), such that \\(\\bigcup_{i = 1}^k A_i = S\\).\n\n\nExample 2.1 (Sets) Let set \\(A\\) be \\(\\{1, 2, 3, 4\\}\\), \\(B\\) be \\(\\{3, 4, 5, 6\\}\\), and \\(C\\) be \\(\\{5, 6, 7, 8\\}\\). Sets \\(A\\), \\(B\\), and \\(C\\) are all subsets of the \\(S\\) which is \\(\\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}\\)\nWrite out the following sets:\n\n\\(A \\cup B\\)\n\\(C \\cap B\\)\n\\(B^c\\)\n\\(A \\cap (B \\cup C)\\)\n\n\n\nExercise 2.1 (Sets) Suppose you had a pair of four-sided dice. You sum the results from a single toss.\nWhat is the set of possible outcomes?\nConsider subsets \\(A=\\{2, 8\\}\\) and \\(B=\\{2,3,7\\}\\) of the sample space you found. What is\n\n\\(A^c\\)\n\\((A \\cup B)^c\\)"
  },
  {
    "objectID": "02_sets_and_functions.html#metric-spaces",
    "href": "02_sets_and_functions.html#metric-spaces",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.2 Metric spaces",
    "text": "2.2 Metric spaces\nA metric space is a set that has a notion of distance - called a “metric” - defined between any two elements (sometimes referred to as “points”).\nThe distance function \\(d(x,y)\\) defines the distance between element \\(x\\) and element \\(y\\)\n\nThe real numbers \\(\\mathbb{R}\\) have a single distance function: \\(d(x,y) = |x - y|\\)\nIn higher-dimensional real space (e.g. \\(\\mathbb{R}^2)\\), we can define multiple distance metrics between \\(x=(x_1, x_2)\\) and \\(y=(y_1, y_2)\\)\n\n“Euclidean” distance: \\(d(x, y) = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2}\\)\n“Taxicab” distance: \\(d(x, y) = |x_1 - y_1| + |x_2 - y_2|\\)\nChebyshev distance: \\(d(x, y) = \\text{max}\\{|x_1 - y_1| + |x_2 - y_2|\\}\\)\n\nAll of these generalize to \\(\\mathbb{R}^n\\)\n\nA metric is a function that satisfies the following axioms\n\nA distance between a point and itself is zero \\(d(x,x) = 0\\)\nThe distance between two points is strictly positive \\(d(x,y) > 0 \\forall x \\neq y\\)\nDistance from \\(x\\) to \\(y\\) is the same as the distance from \\(y\\) to \\(x\\) (\\(d(x,y) = d(y,x)\\))\nThe “triangle inequality” holds: \\(d(x,z) \\le d(x,y) + d(y,z)\\)\n\nOnce we have a metric space, we can define some additional useful concepts\nBall: A ball of radius \\(r\\) centered at \\(x_0\\) is a set that contains all points with a distance less than \\(r\\) from \\(x_0\\).\nSphere: A sphere of radius \\(r\\) centered at \\(x_0\\) is the set that contains all points with a distance exactly \\(r\\) from \\(x_0\\).\nInterior Point: The point \\(x\\) is an interior point of the set \\(S\\) if \\(x\\) is in \\(S\\) and if there is some \\(\\epsilon\\)-ball around \\(x\\) that contains only points in \\(S\\). The interior of \\(S\\) is the collection of all interior points in \\(S\\). The interior can also be defined as the union of all open sets in \\(S\\).\n\nIf the set \\(S\\) is circular, the interior points are everything inside of the circle, but not on the circle’s rim.\nExample: The interior of the set \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) is \\(\\{ (x,y) : x^2+y^2< 4 \\}\\) .\n\nBoundary Point: The point \\(\\mathbf x\\) is a boundary point of the set \\(S\\) if every \\(\\epsilon\\)-ball around \\(\\mathbf x\\) contains both points that are in \\(S\\) and points that are outside \\(S\\). The boundary is the collection of all boundary points.\n\nIf the set \\(S\\) is circular, the boundary points are everything on the circle’s rim.\nExample: The boundary of \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) is \\(\\{ (x,y) : x^2+y^2 = 4 \\}\\).\n\nOpen: A set \\(S\\) is open if for each point \\(\\mathbf x\\) in \\(S\\), there exists an open \\(\\epsilon\\)-ball around \\(\\mathbf x\\) completely contained in \\(S\\).\n\nIf the set \\(S\\) is circular and open, the points contained within the set get infinitely close to the circle’s rim, but do not touch it.\nExample: \\(\\{ (x,y) : x^2+y^2<4 \\}\\)\n\nClosed: A set \\(S\\) is closed if it contains all of its boundary points.\n\nAlternatively: A set is closed if its complement is open.\nIf the set \\(S\\) is circular and closed, the set contains all points within the rim as well as the rim itself.\nExample: \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\)\nNote: a set may be neither open nor closed. Example: \\(\\{ (x,y) : 2 < x^2+y^2\\le 4 \\}\\)"
  },
  {
    "objectID": "02_sets_and_functions.html#operators-sum-and-product-notation",
    "href": "02_sets_and_functions.html#operators-sum-and-product-notation",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.3 Operators; Sum and Product notation",
    "text": "2.3 Operators; Sum and Product notation\nAddition (+), Subtraction (-), multiplication and division are basic operations of arithmetic. In statistics or calculus, we will often want to add a sequence of numbers that can be expressed as a pattern without needing to write down all its components. For example, how would we express the sum of all numbers from 1 to 100 without writing a hundred numbers?\nFor this we use the summation operator \\(\\sum\\) and the product operator \\(\\prod\\).\nSummation:\n\\[\\sum\\limits_{i=1}^{100} x_i = x_1+x_2+x_3+\\cdots+x_{100}\\]\nThe bottom of the \\(\\sum\\) symbol indicates an index (here, \\(i\\)), and its start value \\(1\\). At the top is where the index ends. The notion of “addition” is part of the \\(\\sum\\) symbol. The content to the right of the summation is the meat of what we add. While you can pick your favorite index, start, and end values, the content must also have the index.\nA few important features of sums:\n\n\\(\\sum\\limits_{i=1}^n c x_i = c \\sum\\limits_{i=1}^n x_i\\)\n\\(\\sum\\limits_{i=1}^n (x_i + y_i) = \\sum\\limits_{i=1}^n x_i + \\sum\\limits_{i=1}^n y_i\\)\n\\(\\sum\\limits_{i=1}^n c = n c\\)\n\nProduct:\n\\[\\prod\\limits_{i=1}^n x_i = x_1 x_2 x_3 \\cdots x_n\\]\nProperties:\n\n\\(\\prod\\limits_{i=1}^n c x_i = c^n \\prod\\limits_{i=1}^n x_i\\)\n\\(\\prod\\limits_{i=k}^n c x_i = c^{n-k+1} \\prod\\limits_{i=k}^n x_i\\)\n\\(\\prod\\limits_{i=1}^n (x_i + y_i) =\\) a total mess\n\\(\\prod\\limits_{i=1}^n c = c^n\\)\n\nOther Useful Operations\nFactorials!:\n\\[x! = x\\cdot (x-1) \\cdot (x-2) \\cdots (1)\\]\nModulo: Tells you the remainder when you divide the first number by the second.\n\n\\(17 \\mod 3 = 2\\)\n\\(100 \\ \\% \\ 30 = 10\\)\n\n\n\nExample 2.2 (Operators) \n\\(\\sum\\limits_{i=1}^{5} i =\\)\n\\(\\prod\\limits_{i=1}^{5} i =\\)\n\\(14 \\mod 4 =\\)\n\\(4! =\\)\n\n\n\nExercise 2.2 (Operators) Let \\(x_1 = 4, x_2 = 3, x_3 = 7, x_4 = 11, x_5 = 2\\)\n\n\\(\\sum\\limits_{i=1}^{3} (7)x_i\\)\n\\(\\sum\\limits_{i=1}^{5} 2\\)\n\\(\\prod\\limits_{i=3}^{5} (2)x_i\\)"
  },
  {
    "objectID": "02_sets_and_functions.html#introduction-to-functions",
    "href": "02_sets_and_functions.html#introduction-to-functions",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.4 Introduction to Functions",
    "text": "2.4 Introduction to Functions\nA function is a mapping, or transformation, that relates members of one set to members of another set. For instance, if you have two sets: set \\(A\\) and set \\(B\\), a function from \\(A\\) to \\(B\\) maps every value \\(a\\) in set \\(A\\) such that \\(f(a) \\in B\\). Functions can be “many-to-one”, where many values or combinations of values from set \\(A\\) produce a single output in set \\(B\\), or they can be “one-to-one”, where each value in set \\(A\\) corresponds to a single value in set \\(B\\). A function by definition has a single function value for each element of its domain. This means, there cannot be “one-to-many” mapping.\nDimensionality: \\({\\mathbf R}^1\\) is the set of all real numbers extending from \\(-\\infty\\) to \\(+\\infty\\) — i.e., the real number line. \\({\\mathbf R}^n\\) is an \\(n\\)-dimensional space, where each of the \\(n\\) axes extends from \\(-\\infty\\) to \\(+\\infty\\).\n\n\\({\\mathbf R}^1\\) is a one dimensional line.\n\\({\\mathbf R}^2\\) is a two dimensional plane.\n\\({\\mathbf R}^3\\) is a three dimensional space.\n\nPoints in \\({\\mathbf R}^n\\) are ordered \\(n\\)-tuples (just means an combination of \\(n\\) elements where order matters), where each element of the \\(n\\)-tuple represents the coordinate along that dimension.\nFor example:\n\n\\({\\mathbf R}^1\\): (3)\n\\({\\mathbf R}^2\\): (-15, 5)\n\\({\\mathbf R}^3\\): (86, 4, 0)\n\nExamples of mapping notation:\nFunction of one variable: \\(f:{\\mathbf R}^1\\to{\\mathbf R}^1\\)\n\n\\(f(x)=x+1\\). For each \\(x\\) in \\({\\mathbf R}^1\\), \\(f(x)\\) assigns the number \\(x+1\\).\n\nFunction of two variables: \\(f: {\\mathbf R}^2\\to{\\mathbf R}^1\\).\n\n\\(f(x,y)=x^2+y^2\\). For each ordered pair \\((x,y)\\) in \\({\\mathbf R}^2\\), \\(f(x,y)\\) assigns the number \\(x^2+y^2\\).\n\nWe often use variable \\(x\\) as input and another \\(y\\) as output, e.g. \\(y=x+1\\)\n\nExample 2.3 (Functions) For each of the following, state whether they are one-to-one or many-to-one functions.\n\nFor \\(x \\in [0,\\infty]\\), \\(f : x \\rightarrow x^2\\) (this could also be written as \\(f(x) = x^2\\)).\nFor \\(x \\in [-\\infty, \\infty]\\), \\(f: x \\rightarrow x^2\\).\n\n\n\nExercise 2.3 (Functions) For each of the following, state whether they are one-to-one or many-to-one functions.\n\nFor \\(x \\in [-3, \\infty]\\), \\(f: x \\rightarrow x^2\\).\nFor \\(x \\in [0, \\infty]\\), \\(f: x \\rightarrow \\sqrt{x}\\)\n\n\nSome functions are defined only on proper subsets of \\({\\mathbf R}^n\\).\n\nDomain: the set of numbers in \\(X\\) at which \\(f(x)\\) is defined.\nRange: elements of \\(Y\\) assigned by \\(f(x)\\) to elements of \\(X\\), or \\(f(X)=\\{ y : y=f(x), x\\in X\\}\\) Most often used when talking about a function \\(f:{\\mathbf R}^1\\to{\\mathbf R}^1\\).\nImage: same as range, but more often used when talking about a function \\(f:{\\mathbf R}^n\\to{\\mathbf R}^1\\).\n\nSome General Types of Functions\nMonomials: \\(f(x)=a x^k\\)\n\\(a\\) is the coefficient. \\(k\\) is the degree.\nExamples: \\(y=x^2\\), \\(y=-\\frac{1}{2}x^3\\)\nPolynomials: sum of monomials.\nExamples: \\(y=-\\frac{1}{2}x^3+x^2\\), \\(y=3x+5\\)\nThe degree of a polynomial is the highest degree of its monomial terms. Also, it’s often a good idea to write polynomials with terms in decreasing degree."
  },
  {
    "objectID": "02_sets_and_functions.html#logexponents",
    "href": "02_sets_and_functions.html#logexponents",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.5 Logarithms and Exponents",
    "text": "2.5 Logarithms and Exponents\nExponential Functions: Example: \\(y=2^x\\)\nRelationship of logarithmic and exponential functions: \\[y=\\log_a(x) \\iff a^y=x\\]\nThe log function can be thought of as an inverse for exponential functions. \\(a\\) is referred to as the “base” of the logarithm.\nCommon Bases: The two most common logarithms are base 10 and base \\(e\\).\n\nBase 10: \\(\\quad y=\\log_{10}(x) \\iff 10^y=x\\). The base 10 logarithm is often simply written as “\\(\\log(x)\\)” with no base denoted.\nBase \\(e\\): \\(\\quad y=\\log_e(x) \\iff e^y=x\\). The base \\(e\\) logarithm is referred to as the “natural” logarithm and is written as ``\\(\\ln(x)\\)“.\n\nProperties of exponential functions:\n\n\\(a^x a^y = a^{x+y}\\)\n\\(a^{-x} = 1/a^x\\)\n\\(a^x/a^y = a^{x-y}\\)\n\\((a^x)^y = a^{x y}\\)\n\\(a^0 = 1\\)\n\nProperties of logarithmic functions (any base):\nGenerally, when statisticians or social scientists write \\(\\log(x)\\) they mean \\(\\log_e(x)\\). In other words: \\(\\log_e(x) \\equiv \\ln(x) \\equiv \\log(x)\\)\n\\[\\log_a(a^x)=x\\] and \\[a^{\\log_a(x)}=x\\]\n\n\\(\\log(x y)=\\log(x)+\\log(y)\\)\n\\(\\log(x^y)=y\\log(x)\\)\n\\(\\log(1/x)=\\log(x^{-1})=-\\log(x)\\)\n\\(\\log(x/y)=\\log(x\\cdot y^{-1})=\\log(x)+\\log(y^{-1})=\\log(x)-\\log(y)\\)\n\\(\\log(1)=\\log(e^0)=0\\)\n\nChange of Base Formula: Use the change of base formula to switch bases as necessary: \\[\\log_b(x) = \\frac{\\log_a(x)}{\\log_a(b)}\\]\nExample: \\[\\log_{10}(x) = \\frac{\\ln(x)}{\\ln(10)}\\]\nYou can use logs to go between sum and product notation. This will be particularly important when you’re learning how to optimize likelihood functions.\n\\[\\begin{eqnarray*}\n            \\log \\bigg(\\prod\\limits_{i=1}^n x_i \\bigg) &=& \\log(x_1 \\cdot x_2 \\cdot x_3 \\cdots \\cdot x_n)\\\\\n            &=& \\log(x_1) + \\log(x_2) + \\log(x_3) + \\cdots + \\log(x_n)\\\\\n            &=& \\sum\\limits_{i=1}^n \\log (x_i)\n\\end{eqnarray*}\\]\nTherefore, you can see that the log of a product is equal to the sum of the logs. We can write this more generally by adding in a constant, \\(c\\):\n\\[\\begin{eqnarray*}\n            \\log \\bigg(\\prod\\limits_{i=1}^n c x_i\\bigg) &=& \\log(cx_1 \\cdot cx_2 \\cdots cx_n)\\\\\n            &=& \\log(c^n \\cdot x_1 \\cdot x_2 \\cdots x_n)\\\\\n            &=& \\log(c^n) + \\log(x_1) + \\log(x_2) + \\cdots + \\log(x_n)\\\\\\\\\n            &=& n \\log(c) +  \\sum\\limits_{i=1}^n \\log (x_i)\\\\\n\\end{eqnarray*}\\]\n\nExample 2.4 (Logarithms) Evaluate each of the following logarithms\n\n\\(\\log_4(16)\\)\n\\(\\log_2(16)\\)\n\nSimplify the following logarithm. By “simplify”, we actually really mean - use as many of the logarithmic properties as you can.\n\n\\(\\log_4(x^3y^5)\\)\n\n\n\nExercise 2.4 Evaluate each of the following logarithms\n\n\\(\\log_\\frac{3}{2}(\\frac{27}{8})\\)\n\nSimplify each of the following logarithms. By “simplify”, we actually really mean - use as many of the logarithmic properties as you can.\n\n\\(\\log(\\frac{x^9y^5}{z^3})\\)\n\\(\\ln{\\sqrt{xy}}\\)"
  },
  {
    "objectID": "02_sets_and_functions.html#graphing-functions",
    "href": "02_sets_and_functions.html#graphing-functions",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.6 Graphing Functions",
    "text": "2.6 Graphing Functions\nWhat can a graph tell you about a function?\n\nIs the function increasing or decreasing? Over what part of the domain?\nHow ``fast” does it increase or decrease?\nAre there global or local maxima and minima? Where?\nAre there inflection points?\nIs the function continuous?\nIs the function differentiable?\nDoes the function tend to some limit?\nOther questions related to the substance of the problem at hand."
  },
  {
    "objectID": "02_sets_and_functions.html#solving-for-variables-and-finding-roots",
    "href": "02_sets_and_functions.html#solving-for-variables-and-finding-roots",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.7 Solving for Variables and Finding Roots",
    "text": "2.7 Solving for Variables and Finding Roots\nSometimes we’re given a function \\(y=f(x)\\) and we want to find how \\(x\\) varies as a function of \\(y\\). Use algebra to move \\(x\\) to the left hand side (LHS) of the equation and so that the right hand side (RHS) is only a function of \\(y\\).\n\nExample 2.5 (Solving) Solve for x:\n\n\\(y=3x+2\\)\n\\(y=e^x\\)\n\n\nSolving for variables is especially important when we want to find the roots of an equation: those values of variables that cause an equation to equal zero. Especially important in finding equilibria and in doing maximum likelihood estimation.\nProcedure: Given \\(y=f(x)\\), set \\(f(x)=0\\). Solve for \\(x\\).\nMultiple Roots: \\[f(x)=x^2 - 9 \\quad\\Longrightarrow\\quad 0=x^2 - 9 \\quad\\Longrightarrow\\quad 9=x^2 \\quad\\Longrightarrow\\quad \\pm \\sqrt{9}=\\sqrt{x^2} \\quad\\Longrightarrow\\quad \\pm 3=x\\]\nQuadratic Formula: For quadratic equations \\(ax^2+bx+c=0\\), use the quadratic formula: \\[x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\\]\n\nExercise 2.5 (Roots) Solve for x:\n\n\\(f(x)=3x+2 = 0\\)\n\\(f(x)=x^2+3x-4=0\\)\n\\(f(x)=e^{-x}-10 = 0\\)"
  },
  {
    "objectID": "03_limits.html",
    "href": "03_limits.html",
    "title": "3  Limits",
    "section": "",
    "text": "Solving limits, i.e. finding out the value of functions as its input moves closer to some value, is important for the social scientist’s mathematical toolkit for two related tasks. The first is for the study of calculus, which will be in turn useful to show where certain functions are maximized or minimized. The second is for the study of statistical inference, which is the study of inferring things about things you cannot see by using things you can see."
  },
  {
    "objectID": "03_limits.html#example-the-central-limit-theorem",
    "href": "03_limits.html#example-the-central-limit-theorem",
    "title": "3  Limits",
    "section": "Example: The Central Limit Theorem",
    "text": "Example: The Central Limit Theorem\nPerhaps the most important theorem in statistics is the Central Limit Theorem,\n\nTheorem 3.1 (Central Limit Theorem) For any series of independent and identically distributed random variables \\(X_1, X_2, \\cdots\\), we know the distribution of its sum even if we do not know the distribution of \\(X\\). The distribution of the sum is a Normal distribution.\n\\[\\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\xrightarrow{d} \\text{Normal}(0, 1)\\]\nwhere \\(\\mu\\) is the mean of \\(X\\) and \\(\\sigma\\) is the standard deviation of \\(X\\). The arrow is read as “converges in distribution to”. \\(\\text{Normal}(0, 1)\\) indicates a Normal Distribution with mean 0 and variance 1.\nThat is, the limit of the distribution of the lefthand side is the distribution of the righthand side.\n\nThe sign of a limit is the arrow “\\(\\rightarrow\\)”. Although we have not yet covered probability so we have not described what distributions and random variables are, it is worth foreshadowing the Central Limit Theorem. The Central Limit Theorem is powerful because it gives us a guarantee of what would happen if \\(n \\rightarrow \\infty\\), which in this case means we collected more data."
  },
  {
    "objectID": "03_limits.html#example-the-law-of-large-numbers",
    "href": "03_limits.html#example-the-law-of-large-numbers",
    "title": "3  Limits",
    "section": "Example: The Law of Large Numbers",
    "text": "Example: The Law of Large Numbers\nA finding that perhaps rivals the Central Limit Theorem is the (Weak) Law of Large Numbers:\n\nTheorem 3.2 ((Weak) Law of Large Numbers) For any draw of identically distributed independent variables with mean \\(\\mu\\), the sample average after \\(n\\) draws, \\(\\bar{X}_n\\), converges in probability to the true mean as \\(n \\rightarrow \\infty\\):\n\\[\\lim\\limits_{n\\to \\infty} P(|\\bar{X}_n - \\mu | > \\varepsilon) = 0\\]\nA shorthand of which is \\(\\bar{X}_n \\xrightarrow{p} \\mu\\), where the arrow is read as “converges in probability to”.\n\nIntuitively, the more data, the more accurate is your guess. For example, Figure 3.1 shows how the sample average from many coin tosses converges to the true value : 0.5.\n\n\n\n\n\nFigure 3.1: As the number of coin tosses goes to infinity, the average probabiity of heads converges to 0.5"
  },
  {
    "objectID": "03_limits.html#sequences",
    "href": "03_limits.html#sequences",
    "title": "3  Limits",
    "section": "3.1 Sequences",
    "text": "3.1 Sequences\nWe need a couple of steps until we get to limit theorems in probability. First we will introduce a “sequence”, then we will think about the limit of a sequence, then we will think about the limit of a function.\nA sequence \\(\\{x_n\\}=\\{x_1, x_2, x_3, \\ldots, x_n\\}\\) is an ordered set of real numbers, where \\(x_1\\) is the first term in the sequence and \\(y_n\\) is the \\(n\\)th term. Generally, a sequence is infinite, that is it extends to \\(n=\\infty\\). We can also write the sequence as \\(\\{x_n\\}^\\infty_{n=1}\\)\nwhere the subscript and superscript are read together as “from 1 to infinity.”\n\nExample 3.1 (Sequences) How do these sequences behave?\n\n\\(\\{A_n\\}=\\left\\{ 2-\\frac{1}{n^2} \\right\\}\\)\n\\(\\{B_n\\}=\\left\\{\\frac{n^2+1}{n} \\right\\}\\)\n\\(\\{C_n\\}=\\left\\{(-1)^n \\left(1-\\frac{1}{n}\\right) \\right\\}\\)\n\n\nWe find the sequence by simply “plugging in” the integers into each \\(n\\). The important thing is to get a sense of how these numbers are going to change.\nGraphing helps you make this point more clearly. See the sequence of \\(n = 1, ...20\\) for each of the three examples in Figure 3.2.\n\n\n\n\n\nFigure 3.2: Behavior of Some Sequences"
  },
  {
    "objectID": "03_limits.html#the-limit-of-a-sequence",
    "href": "03_limits.html#the-limit-of-a-sequence",
    "title": "3  Limits",
    "section": "3.2 The Limit of a Sequence",
    "text": "3.2 The Limit of a Sequence\nThe notion of “converging to a limit” is the behavior of the points in Example -@#exm-seqbehav. In some sense, that’s the counterfactual we want to know. What happens as \\(n\\rightarrow \\infty\\)?\n\nSequences like 1 above that converge to a limit.\nSequences like 2 above that increase without bound.\nSequences like 3 above that neither converge nor increase without bound — alternating over the number line.\n\nDefinition: Limit The sequence \\(\\{y_n\\}\\) has the limit \\(L\\), which we write as \\(\\lim\\limits_{n \\to \\infty} y_n =L\\), if for any \\(\\epsilon>0\\) there is an integer \\(N\\) (which depends on \\(\\epsilon\\)) with the property that \\(|y_n -L|<\\epsilon\\) for each \\(n>N\\). \\(\\{y_n\\}\\) is said to converge to \\(L\\). If the above does not hold, then \\(\\{y_n\\}\\) diverges.\nWe can also express the behavior of a sequence as bounded or not:\n\nBounded: if \\(|y_n|\\le K\\) for all \\(n\\)\nMonotonically Increasing: \\(y_{n+1}>y_n\\) for all \\(n\\)\nMonotonically Decreasing: \\(y_{n+1}<y_n\\) for all \\(n\\)\n\nA limit is unique: If \\(\\{y_n\\}\\) converges, then the limit \\(L\\) is unique.\nIf a sequence converges, then the sum of such sequences also converges. Let \\(\\lim\\limits_{n \\to \\infty} y_n = y\\) and \\(\\lim\\limits_{n \\to \\infty} z_n =z\\). Then\n\n\\(\\lim\\limits_{n \\to \\infty} [k y_n + \\ell z_n]= k y + \\ell z\\)\n\\(\\lim\\limits_{n \\to \\infty} y_n z_n = yz\\)\n\\(\\lim\\limits_{n \\to \\infty} \\frac{y_n}{z_n} = \\frac{y}{z}\\), provided \\(z\\neq 0\\)\n\nThis looks reasonable enough. The harder question, obviously is when the parts of the fraction don’t converge. If \\(\\lim_{n\\to\\infty} y_n = \\infty\\) and \\(\\lim_{n\\to\\infty} z_n = \\infty\\), What is \\(\\lim_{n\\to\\infty} y_n - z_n\\)? What is \\(\\lim_{n\\to\\infty} \\frac{y_n}{z_n}\\)?\nIt is nice for a sequence to converge in limit. We want to know if complex-looking sequences converge or not. The name of the game here is to break that complex sequence up into sums of simple fractions where \\(n\\) only appears in the denominator: \\(\\frac{1}{n}, \\frac{1}{n^2}\\), and so on. Each of these will converge to 0, because the denominator gets larger and larger. Then, because of the properties above, we can then find the final sequence.\n\nExample 3.2 (Ratios) Find the limit of \\(\\lim_{n\\to \\infty} \\frac{n + 3}{n}\\)\n\n\nSolution. At first glance, \\(n + 3\\) and \\(n\\) both grow to \\(\\infty\\), so it looks like we need to divide infinity by infinity. However, we can express this fraction as a sum, then the limits apply separately:\n\\[\\lim_{n\\to \\infty} \\frac{n + 3}{n} = \\lim_{n\\to \\infty} \\left(1 + \\frac{3}{n}\\right) =  \\underbrace{\\lim_{n\\to \\infty}1}_{1} +  \\underbrace{\\lim_{n\\to \\infty}\\left(\\frac{3}{n}\\right)}_{0}\\]\nso, the limit is actually 1.\n\nAfter some practice, the key to intuition is whether one part of the fraction grows “faster” than another. If the denominator grows faster to infinity than the numerator, then the fraction will converge to 0, even if the numerator will also increase to infinity. In a sense, limits show how not all infinities are the same.\n\nExercise 3.1 (Limits) Find the following limits of sequences, then explain in English the intuition for why that is the case.\n\n\\(\\lim\\limits_{n\\to\\infty} \\frac{2n}{n^2 + 1}\\)\n\\(\\lim\\limits_{n\\to\\infty} (n^3 - 100n^2)\\)"
  },
  {
    "objectID": "03_limits.html#limitsfun",
    "href": "03_limits.html#limitsfun",
    "title": "3  Limits",
    "section": "3.3 Limits of a Function",
    "text": "3.3 Limits of a Function\nWe’ve now covered functions and just covered limits of sequences, so now is the time to combine the two.\nA function \\(f\\) is a compact representation of some behavior we care about. Like for sequences, we often want to know if \\(f(x)\\) approaches some number \\(L\\) as its independent variable \\(x\\) moves to some number \\(c\\) (which is usually 0 or \\(\\pm\\infty\\)). If it does, we say that the limit of \\(f(x)\\), as \\(x\\) approaches \\(c\\), is \\(L\\): \\(\\lim\\limits_{x \\to c} f(x)=L\\). Unlike a sequence, \\(x\\) is a continuous number, and we can move in decreasing order as well as increasing.\nFor a limit \\(L\\) to exist, the function \\(f(x)\\) must approach \\(L\\) from both the left (increasing) and the right (decreasing).\n\nDefinition 3.1 (Limits of a function) Let \\(f(x)\\) be defined at each point in some open interval containing the point \\(c\\). Then \\(L\\) equals \\(\\lim\\limits_{x \\to c} f(x)\\) if for any (small positive) number \\(\\epsilon\\), there exists a corresponding number \\(\\delta>0\\) such that if \\(0<|x-c|<\\delta\\), then \\(|f(x)-L|<\\epsilon\\).\n\nA neat, if subtle result is that \\(f(x)\\) does not necessarily have to be defined at \\(c\\) for \\(\\lim\\limits_{x \\to c}\\) to exist.\nProperties: Let \\(f\\) and \\(g\\) be functions with \\(\\lim\\limits_{x \\to c} f(x)=k\\) and \\(\\lim\\limits_{x \\to c} g(x)=\\ell\\).\n\n\\(\\lim\\limits_{x \\to c}[f(x)+g(x)]=\\lim\\limits_{x \\to c} f(x)+ \\lim\\limits_{x \\to c} g(x)\\)\n\\(\\lim\\limits_{x \\to c} kf(x) = k\\lim\\limits_{x \\to c} f(x)\\)\n\\(\\lim\\limits_{x \\to c} f(x) g(x) = \\left[\\lim\\limits_{x \\to c} f(x)\\right]\\cdot \\left[\\lim\\limits_{x \\to c} g(x)\\right]\\)\n\\(\\lim\\limits_{x \\to c} \\frac{f(x)}{g(x)} = \\frac{\\lim\\limits_{x \\to c} f(x)}{\\lim\\limits_{x \\to c} g(x)}\\), provided \\(\\lim\\limits_{x \\to c} g(x)\\ne 0\\).\n\nSimple limits of functions can be solved as we did limits of sequences. Just be careful which part of the function is changing.\n\nExample 3.3 (Limits of a function) Find the limit of the following functions.\n\n\\(\\lim_{x \\to c} k\\)\n\\(\\lim_{x \\to c} x\\)\n\\(\\lim_{x\\to 2} (2x-3)\\)\n\\(\\lim_{x \\to c} x^n\\)\n\n\nLimits can get more complex in roughly two ways. First, the functions may become large polynomials with many moving pieces. Second, the functions may become discontinuous.\nThe function can be thought of as a more general or “smooth” version of sequences. For example,\n\nExample 3.4 (Limits of ratios) Find the limit of\n\\[\\lim_{x\\to\\infty} \\frac{(x^4 +3x−99)(2−x^5)}{(18x^7 +9x^6 −3x^2 −1)(x+1)}\\]\n\nNow, the functions will become a bit more complex:\n\nExercise 3.2 (Limits of a function) Solve the following limits of functions\n\n\\(\\lim\\limits_{x\\to 0} |x|\\)\n\\(\\lim\\limits_{x\\to 0} \\left(1+\\frac{1}{x^2}\\right)\\)\n\n\nSo there are a few more alternatives about what a limit of a function could be:\n\nRight-hand limit: The value approached by \\(f(x)\\) when you move from right to left.\nLeft-hand limit: The value approached by \\(f(x)\\) when you move from left to right.\nInfinity: The value approached by \\(f(x)\\) as x grows infinitely large. Sometimes this may be a number; sometimes it might be \\(\\infty\\) or \\(-\\infty\\).\nNegative infinity: The value approached by \\(f(x)\\) as x grows infinitely negative. Sometimes this may be a number; sometimes it might be \\(\\infty\\) or \\(-\\infty\\).\n\nThe distinction between left and right becomes important when the function is not determined for some values of \\(x\\). What are those cases in the examples below?\n\n\n\n\n\nFunctions which are not defined in some areas"
  },
  {
    "objectID": "03_limits.html#continuity",
    "href": "03_limits.html#continuity",
    "title": "3  Limits",
    "section": "3.4 Continuity",
    "text": "3.4 Continuity\nTo repeat a finding from the limits of functions: \\(f(x)\\) does not necessarily have to be defined at \\(c\\) for \\(\\lim\\limits_{x \\to c}\\) to exist. Functions that have breaks in their lines are called discontinuous. Functions that have no breaks are called continuous. Continuity is a concept that is more fundamental to, but related to that of “differentiability”, which we will cover next in calculus.\n\nDefinition 3.2 (Continuity) Suppose that the domain of the function \\(f\\) includes an open interval containing the point \\(c\\). Then \\(f\\) is continuous at \\(c\\) if \\(\\lim\\limits_{x \\to c} f(x)\\) exists and if \\(\\lim\\limits_{x \\to c} f(x)=f(c)\\). Further, \\(f\\) is continuous on an open interval \\((a,b)\\) if it is continuous at each point in the interval.\n\nTo prove that a function is continuous for all points is beyond this practical introduction to math, but the general intuition can be grasped by graphing.\n\nExample 3.5 (Continuity) For each function, determine if it is continuous or discontinuous.\n\n\\(f(x) = \\sqrt{x}\\)\n\\(f(x) = e^x\\)\n\\(f(x) = 1 + \\frac{1}{x^2}\\)\n\\(f(x) = \\text{floor}(x)\\).\n\nThe floor is the smaller of the two integers bounding a number. So \\(\\text{floor}(x = 2.999) = 2\\), \\(\\text{floor}(x = 2.0001) = 2\\), and \\(\\text{floor}(x = 2) = 2.\\)\n\n\nSolution. In Figure 3.3, we can see that the first two functions are continuous, and the next two are discontinuous. \\(f(x) = 1 + \\frac{1}{x^2}\\) is discontinuous at \\(x= 0\\), and \\(f(x) = \\text{floor}(x)\\) is discontinuous at each whole number.\n\n\n\n\n\nFigure 3.3: Continuous and Discontinuous Functions\n\n\n\n\n\nSome properties of continuous functions:\n\nIf \\(f\\) and \\(g\\) are continuous at point \\(c\\), then \\(f+g\\), \\(f-g\\), \\(f \\cdot g\\), \\(|f|\\), and \\(\\alpha f\\) are continuous at point \\(c\\) also. \\(f/g\\) is continuous, provided \\(g(c)\\ne 0\\).\nBoundedness: If \\(f\\) is continuous on the closed bounded interval \\([a,b]\\), then there is a number \\(K\\) such that \\(|f(x)|\\le K\\) for each \\(x\\) in \\([a,b]\\).\nMax/Min: If \\(f\\) is continuous on the closed bounded interval \\([a,b]\\), then \\(f\\) has a maximum and a minimum on \\([a,b]\\). They may be located at the end points.\n\nExercise\nLet \\(f(x) = \\frac{x^2 + 2x}{x}.\\)\n\nGraph the function. Is it defined everywhere?\nWhat is the functions limit at \\(x \\rightarrow 0\\)?"
  },
  {
    "objectID": "04_calculus.html",
    "href": "04_calculus.html",
    "title": "4  Calculus",
    "section": "",
    "text": "Calculus is a fundamental part of any type of statistics exercise. Although you may not be taking derivatives and integral in your daily work as an analyst, calculus undergirds many concepts we use: maximization, expectation, and cumulative probability."
  },
  {
    "objectID": "04_calculus.html#example-the-mean-is-a-type-of-integral",
    "href": "04_calculus.html#example-the-mean-is-a-type-of-integral",
    "title": "4  Calculus",
    "section": "Example: The Mean is a Type of Integral",
    "text": "Example: The Mean is a Type of Integral\nThe average of a quantity is a type of weighted mean, where the potential values are weighted by their likelihood, loosely speaking. The integral is actually a general way to describe this weighted average when there are conceptually an infinite number of potential values.\nIf \\(X\\) is a continuous random variable, its expected value \\(E(X)\\) – the center of mass – is given by\n\\[E(X) = \\int^{\\infty}_{-\\infty}x f(x) dx\\]\nwhere \\(f(x)\\) is the probability density function of \\(X\\).\nThis is a continuous version of the case where \\(X\\) is discrete, in which case\n\\[E(X) = \\sum^\\infty_{j=1} x_j P(X = x_j)\\]\neven more concretely, if the potential values of \\(X\\) are finite, then we can write out the expected value as a weighted mean, where the weights is the probability that the value occurs.\n\\[E(X) = \\large \\sum_{x} \\quad\\left( \\underbrace{x}_{\\text{value}}\\cdot \\underbrace{P(X = x)}_{\\text{weight, or PMF}}\\right)\\]"
  },
  {
    "objectID": "04_calculus.html#sec-derivintro",
    "href": "04_calculus.html#sec-derivintro",
    "title": "4  Calculus",
    "section": "4.1 Derivatives",
    "text": "4.1 Derivatives\nThe derivative of \\(f\\) at \\(x\\) is its rate of change at \\(x\\): how much \\(f(x)\\) changes with a change in \\(x\\). The rate of change is a fraction — rise over run — but because not all lines are straight and the rise over run formula will give us different values depending on the range we examine, we need to take a limit (Section -Chapter 3).\n\nDefinition 4.1 (Derivative) Let \\(f\\) be a function whose domain includes an open interval containing the point \\(x\\). The derivative of \\(f\\) at \\(x\\) is given by\n\\[\\frac{d}{dx}f(x) =\\lim\\limits_{h\\to 0} \\frac{f(x+h)-f(x)}{(x+h)-x} = \\lim\\limits_{h\\to 0} \\frac{f(x+h)-f(x)}{h}\\]\nThere are a two main ways to denote a derivate:\n\nLeibniz Notation: \\(\\frac{d}{dx}(f(x))\\)\nPrime or Lagrange Notation: \\(f'(x)\\)\n\n\nIf \\(f(x)\\) is a straight line, the derivative is the slope. For a curve, the slope changes by the values of \\(x\\), so the derivative is the slope of the line tangent to the curve at \\(x\\). See, For example, Figure -Figure 4.1\n\n\n\n\n\nFigure 4.1: The Derivative as a Slope\n\n\n\n\nIf \\(f'(x)\\) exists at a point \\(x_0\\), then \\(f\\) is said to be differentiable at \\(x_0\\). That also implies that \\(f(x)\\) is continuous at \\(x_0\\).\n\nProperties of derivatives\nSuppose that \\(f\\) and \\(g\\) are differentiable at \\(x\\) and that \\(\\alpha\\) is a constant. Then the functions \\(f\\pm g\\), \\(\\alpha f\\), \\(f g\\), and \\(f/g\\) (provided \\(g(x)\\ne 0\\)) are also differentiable at \\(x\\). Additionally,\nConstant rule: \\[\\left[k f(x)\\right]' = k f'(x)\\]\nSum rule: \\[\\left[f(x)\\pm g(x)\\right]' = f'(x)\\pm g'(x)\\]\nWith a bit more algebra, we can apply the definition of derivatives to get a formula for of the derivative of a product and a derivative of a quotient.\nProduct rule: \\[\\left[f(x)g(x)\\right]^\\prime = f^\\prime(x)g(x)+f(x)g^\\prime(x)\\]\nQuotient rule: \\[\\left[f(x)/g(x)\\right]^\\prime = \\frac{f^\\prime(x)g(x) - f(x)g^\\prime(x)}{[g(x)]^2}, ~g(x)\\neq 0\\]\nFinally, one way to think of the power of derivatives is that it takes a function a notch down in complexity. The power rule applies to any higher-order function:\nPower rule: \\[\\left[x^k\\right]^\\prime = k x^{k-1}\\]\nFor any real number \\(k\\) (that is, both whole numbers and fractions). The power rule is proved by induction, a neat method of proof used in many fundamental applications to prove that a general statement holds for every possible case, even if there are countably infinite cases. We’ll show a simple case where \\(k\\) is an integer here.\n\nProposition 4.1 (Power Rule) \\[\\left[x^k\\right]^\\prime = k x^{k-1}\\] for any integer \\(k\\).\n\n\nProof. First, consider the first case (the base case) of \\(k = 1\\). We can show by the definition of derivatives (setting \\(f(x) = x^1 = 1\\)) that\n\\[[x^1]^\\prime = \\lim_{h \\rightarrow 0}\\frac{(x + h) - x}{(x + h) - x}= 1.\\]\nBecause \\(1\\) is also expressed as \\(1 x^{1- 1}\\), the statement we want to prove holds for the case \\(k =1\\).\nNow, that the statement holds for some integer \\(m\\). That is, assume \\[\\left[x^m\\right]^\\prime = m x^{m-1}\\]\nThen, for the case \\(m + 1\\), using the product rule above, we can simplify\n\\[\\begin{align*}\n\\left[x^{m + 1}\\right]^\\prime &= [x^{m}\\cdot x]^\\prime\\\\\n&= (x^m)^\\prime\\cdot x + (x^m)\\cdot (x)^\\prime\\\\\n&= m x^{m - 1}\\cdot x + x^m ~~\\because \\text{by previous assumption}\\\\\n&= mx^m + x^m\\\\\n&= (m + 1)x^m\\\\\n&= (m + 1)x^{(m + 1) - 1}\n\\end{align*}\\]\nTherefore, the rule holds for the case \\(k = m + 1\\) once we have assumed it holds for \\(k = m\\). Combined with the first case, this completes proof by induction – we have now proved that the statement holds for all integers \\(k = 1, 2, 3, \\cdots\\).\nTo show that it holds for real fractions as well, we can prove expressing that exponent by a fraction of two integers.\n\nThese “rules” become apparent by applying the definition of the derivative above to each of the things to be “derived”, but these come up so frequently that it is best to repeat until it is muscle memory.\n\nExercise 4.1 (Derivatives) For each of the following functions, find the first-order derivative \\(f^\\prime(x)\\).\n\n\\(f(x)=c\\)\n\\(f(x)=x\\)\n\\(f(x)=x^2\\)\n\\(f(x)=x^3\\)\n\\(f(x)=\\frac{1}{x^2}\\)\n\\(f(x)=(x^3)(2x^4)\\)\n\\(f(x) = x^4 - x^3 + x^2 - x + 1\\)\n\\(f(x) = (x^2 + 1)(x^3 - 1)\\)\n\\(f(x) = 3x^2 + 2x^{1/3}\\)\n\\(f(x)=\\frac{x^2+1}{x^2-1}\\)"
  },
  {
    "objectID": "04_calculus.html#derivpoly",
    "href": "04_calculus.html#derivpoly",
    "title": "4  Calculus",
    "section": "4.2 Higher-Order Derivatives (Derivatives of Derivatives of Derivatives)",
    "text": "4.2 Higher-Order Derivatives (Derivatives of Derivatives of Derivatives)\nThe first derivative is applying the definition of derivatives on the function, and it can be expressed as\n\\[f'(x),  ~~ y',  ~~ \\frac{d}{dx}f(x), ~~ \\frac{dy}{dx}\\]\nWe can keep applying the differentiation process to functions that are themselves derivatives. The derivative of \\(f'(x)\\) with respect to \\(x\\), would then be \\[f''(x)=\\lim\\limits_{h\\to 0}\\frac{f'(x+h)-f'(x)}{h}\\] and we can therefore call it the Second derivative:\n\\[f''(x), ~~ y'', ~~ \\frac{d^2}{dx^2}f(x), ~~ \\frac{d^2y}{dx^2}\\]\nSimilarly, the derivative of \\(f''(x)\\) would be called the third derivative and is denoted \\(f'''(x)\\). And by extension, the nth derivative is expressed as \\(\\frac{d^n}{dx^n}f(x)\\), \\(\\frac{d^ny}{dx^n}\\).\n\nExample 4.1 (Succession of derivatives) \\[\\begin{align*}\nf(x) &=x^3\\\\\nf^{\\prime}(x) &=3x^2\\\\\nf^{\\prime\\prime}(x) &=6x \\\\\nf^{\\prime\\prime\\prime}(x) &=6\\\\\nf^{\\prime\\prime\\prime\\prime}(x) &=0\\\\\n\\end{align*}\\]\n\nEarlier, in Section -Section 4.1, we said that if a function differentiable at a given point, then it must be continuous. Further, if \\(f'(x)\\) is itself continuous, then \\(f(x)\\) is called continuously differentiable. All of this matters because many of our findings about optimization (Section @ref(optim)) rely on differentiation, and so we want our function to be differentiable in as many layers. A function that is continuously differentiable infinitly is called “smooth”. Some examples: \\(f(x) = x^2\\), \\(f(x) = e^x\\)."
  },
  {
    "objectID": "04_calculus.html#composite-functions-and-the-chain-rule",
    "href": "04_calculus.html#composite-functions-and-the-chain-rule",
    "title": "4  Calculus",
    "section": "4.3 Composite Functions and the Chain Rule",
    "text": "4.3 Composite Functions and the Chain Rule\nAs useful as the above rules are, many functions you’ll see won’t fit neatly in each case immediately. Instead, they will be functions of functions. For example, the difference between \\(x^2 + 1^2\\) and \\((x^2 + 1)^2\\) may look trivial, but the sum rule can be easily applied to the former, while it’s actually not obvious what do with the latter.\nComposite functions are formed by substituting one function into another and are denoted by \\[(f\\circ g)(x)=f[g(x)].\\] To form \\(f[g(x)]\\), the range of \\(g\\) must be contained (at least in part) within the domain of \\(f\\). The domain of \\(f\\circ g\\) consists of all the points in the domain of \\(g\\) for which \\(g(x)\\) is in the domain of \\(f\\).\n\nExample 4.2 (Composite functions) Let \\(f(x)=\\log x\\) for \\(0<x<\\infty\\) and \\(g(x)=x^2\\) for \\(-\\infty<x<\\infty\\).\nThen \\[(f\\circ g)(x)=\\log x^2, -\\infty<x<\\infty - \\{0\\}\\]\nAlso \\[(g\\circ f)(x)=[\\log x]^2, 0<x<\\infty\\]\nNotice that \\(f\\circ g\\) and \\(g\\circ f\\) are not the same functions.\n\nWith the notation of composite functions in place, now we can introduce a helpful additional rule that will deal with a derivative of composite functions as a chain of concentric derivatives.\nChain Rule:\nLet \\(y=(f\\circ g)(x)= f[g(x)]\\). The derivative of \\(y\\) with respect to \\(x\\) is \\[\\frac{d}{dx} \\{ f[g(x)] \\} = f'[g(x)] g'(x)\\]\nWe can read this as: “the derivative of the composite function \\(y\\) is the derivative of \\(f\\) evaluated at \\(g(x)\\), times the derivative of \\(g\\).”\nThe chain rule can be thought of as the derivative of the “outside” times the derivative of the “inside”, remembering that the derivative of the outside function is evaluated at the value of the inside function.\n\nThe chain rule can also be written as \\[\\frac{dy}{dx}=\\frac{dy}{dg(x)} \\frac{dg(x)}{dx}\\] This expression does not imply that the \\(dg(x)\\)’s cancel out, as in fractions. They are part of the derivative notation and you can’t separate them out or cancel them.)\n\n\nExample 4.3 (Composite Exponent) Find \\(f^\\prime(x)\\) for \\(f(x) = (3x^2+5x-7)^6\\).\n\nThe direct use of a chain rule is when the exponent of is itself a function, so the power rule could not have applied generaly:\nGeneralized Power Rule:\nIf \\(f(x)=[g(x)]^p\\) for any rational number \\(p\\), \\[f^\\prime(x) =p[g(x)]^{p-1}g^\\prime(x)\\]"
  },
  {
    "objectID": "04_calculus.html#derivatives-of-natural-logs-and-the-exponent",
    "href": "04_calculus.html#derivatives-of-natural-logs-and-the-exponent",
    "title": "4  Calculus",
    "section": "4.4 Derivatives of natural logs and the exponent",
    "text": "4.4 Derivatives of natural logs and the exponent\nNatural logs and exponents (they are inverses of each other; see Section @ref(logexponents)) crop up everywhere in statistics. Their derivative is a special case from the above, but quite elegant.\n\nTheorem 4.1 (Derivative of Exponents/Logs) The functions \\(e^x\\) and the natural logarithm \\(\\log(x)\\) are continuous and differentiable in their domains, and their first derivative is \\[(e^x)^\\prime = e^x\\] \\[\\log(x)^\\prime = \\frac{1}{x}\\]\nAlso, when these are composite functions, it follows by the generalized power rule that\n\\[\\left(e^{g(x)}\\right)^\\prime = e^{g(x)} \\cdot g^\\prime(x)\\] \\[\\left(\\log g(x)\\right)^\\prime = \\frac{g^\\prime(x)}{g(x)}, ~~\\text{if}~~ g(x) > 0\\]\n\n\nDerivatives of natural exponential function (\\(e\\))\nTo repeat the main rule in Theorem @ref(thm:derivexplog), the intuition is that\n\nDerivative of \\(e^x\\) is itself: \\(\\frac{d}{dx}e^x = e^x\\) (See Figure 4.2)\nSame thing if there were a constant in front: \\(\\frac{d}{dx}\\alpha e^x = \\alpha e^x\\)\nSame thing no matter how many derivatives there are in front: \\(\\frac{d^n}{dx^n} \\alpha e^x = \\alpha e^x\\)\nChain Rule: When the exponent is a function of \\(x\\), remember to take derivative of that function and add to product. \\(\\frac{d}{dx}e^{g(x)}= e^{g(x)} g^\\prime(x)\\)\n\n\n\n\n\n\nFigure 4.2: Derivative of the Exponential Function\n\n\n\n\n\nExample 4.4 (Derivatives of exponents) Find the derivative for the following.\n\n\\(f(x)=e^{-3x}\\)\n\\(f(x)=e^{x^2}\\)\n\\(f(x)=(x-1)e^x\\)\n\n\n\n\nDerivatives of logarithms\nThe natural log is the mirror image of the natural exponent and has mirroring properties, again, to repeat the theorem,\n\nlog prime x is one over x: \\(\\frac{d}{dx} \\log x = \\frac{1}{x}\\) (Figure 4.3)\nExponents become multiplicative constants: \\(\\frac{d}{dx} \\log x^k = \\frac{d}{dx} k \\log x = \\frac{k}{x}\\)\nChain rule again: \\(\\frac{d}{dx} \\log u(x) = \\frac{u'(x)}{u(x)}\\quad\\)\nFor any positive base \\(b\\), \\(\\frac{d}{dx} b^x = (\\log b)\\left(b^x\\right)\\).\n\n\n\n\n\n\nFigure 4.3: Derivative of the Natural Log\n\n\n\n\n\nExample 4.5 (Derivatives of logs) Find \\(dy/dx\\) for the following.\n\n\\(f(x)=\\log(x^2+9)\\)\n\\(f(x)=\\log(\\log x)\\)\n\\(f(x)=(\\log x)^2\\)\n\\(f(x)=\\log e^x\\)\n\n\n\n\nOutline of Proof\nWe actually show the derivative of the log first, and then the derivative of the exponential naturally follows.\nThe general derivative of the log at any base \\(a\\) is solvable by the definition of derivatives.\n\\[\\begin{align*}\n(\\log_a x)^\\prime = \\lim\\limits_{h\\to 0} \\frac{1}{h}\\log_{a}\\left(1 + \\frac{h}{x}\\right)\n\\end{align*}\\]\nRe-express \\(g = \\frac{h}{x}\\) and get \\[\\begin{align*}\n(\\log_a x)^\\prime &= \\frac{1}{x}\\lim_{g\\to 0}\\log_{a} (1 + g)^{\\frac{1}{g}}\\\\\n&= \\frac{1}{x}\\log_a e\n\\end{align*}\\]\nBy definition of \\(e\\). As a special case, when \\(a = e\\), then \\((\\log x)^\\prime = \\frac{1}{x}\\).\nNow let’s think about the inverse, taking the derivative of \\(y = a^x\\).\n\\[\\begin{align*}\ny &= a^x \\\\\n\\Rightarrow \\log y &= x \\log a\\\\\n\\Rightarrow \\frac{y^\\prime}{y} &= \\log a\\\\\n\\Rightarrow  y^\\prime = y \\log a\\\\\n\\end{align*}\\]\nThen in the special case where \\(a = e\\),\n\\[(e^x)^\\prime = (e^x)\\]"
  },
  {
    "objectID": "04_calculus.html#partial-derivatives",
    "href": "04_calculus.html#partial-derivatives",
    "title": "4  Calculus",
    "section": "4.5 Partial Derivatives",
    "text": "4.5 Partial Derivatives\nWhat happens when there’s more than variable that is changing?\n\nIf you can do ordinary derivatives, you can do partial derivatives: just hold all the other input variables constant except for the one you’re differentiating with respect to. (Joe Blitzstein’s Math Notes)\n\nSuppose we have a function \\(f\\) now of two (or more) variables and we want to determine the rate of change relative to one of the variables. To do so, we would find its partial derivative, which is defined similar to the derivative of a function of one variable.\nPartial Derivative: Let \\(f\\) be a function of the variables \\((x_1,\\ldots,x_n)\\). The partial derivative of \\(f\\) with respect to \\(x_i\\) is\n\\[\\frac{\\partial f}{\\partial x_i} (x_1,\\ldots,x_n) = \\lim\\limits_{h\\to 0} \\frac{f(x_1,\\ldots,x_i+h,\\ldots,x_n)-f(x_1,\\ldots,x_i,\\ldots,x_n)}{h}\\]\nOnly the \\(i\\)th variable changes — the others are treated as constants.\nWe can take higher-order partial derivatives, like we did with functions of a single variable, except now the higher-order partials can be with respect to multiple variables.\n\nExample 4.6 (Partial derivatives) Notice that you can take partials with regard to different variables.\nSuppose \\(f(x,y)=x^2+y^2\\). Then\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x}(x,y) &=\\\\\n\\frac{\\partial f}{\\partial y}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x^2}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x \\partial y}(x,y) &=\n\\end{align*}\\]\n\n\nExercise 4.2 (Partial derivatives) Let \\(f(x,y)=x^3 y^4 +e^x -\\log y\\). What are the following partial derivatives?\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x}(x,y) &=\\\\\n\\frac{\\partial f}{\\partial y}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x^2}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x \\partial y}(x,y) &=\n\\end{align*}\\]"
  },
  {
    "objectID": "04_calculus.html#taylorapprox",
    "href": "04_calculus.html#taylorapprox",
    "title": "4  Calculus",
    "section": "4.6 Taylor Series Approximation",
    "text": "4.6 Taylor Series Approximation\nA common form of approximation used in statistics involves derivatives. A Taylor series is a way to represent common functions as infinite series (a sum of infinite elements) of the function’s derivatives at some point \\(a\\).\nFor example, Taylor series are very helpful in representing nonlinear (read: difficult) functions as linear (read: manageable) functions. One can thus approximate functions by using lower-order, finite series known as Taylor polynomials. If \\(a=0\\), the series is called a Maclaurin series.\nSpecifically, a Taylor series of a real or complex function \\(f(x)\\) that is infinitely differentiable in the neighborhood of point \\(a\\) is:\n\\[\\begin{align*}\n    f(x) &= f(a) + \\frac{f'(a)}{1!} (x-a) +  \\frac{f''(a)}{2!} (x-a)^2 + \\cdots\\\\\n     &= \\sum_{n=0}^\\infty \\frac{f^{(n)} (a)}{n!} (x-a)^n\n\\end{align*}\\]\nTaylor Approximation: We can often approximate the curvature of a function \\(f(x)\\) at point \\(a\\) using a 2nd order Taylor polynomial around point \\(a\\):\n\\[f(x) = f(a) + \\frac{f'(a)}{1!} (x-a) +  \\frac{f''(a)}{2!} (x-a)^2\n+ R_2\\]\n\\(R_2\\) is the remainder (R for remainder, 2 for the fact that we took two derivatives) and often treated as negligible, giving us:\n\\[f(x) \\approx f(a) + f'(a)(x-a) +  \\dfrac{f''(a)}{2} (x-a)^2\\]\nThe more derivatives that are added, the smaller the remainder \\(R\\) and the more accurate the approximation. Proofs involving limits guarantee that the remainder converges to 0 as the order of derivation increases."
  },
  {
    "objectID": "04_calculus.html#the-indefinite-integration",
    "href": "04_calculus.html#the-indefinite-integration",
    "title": "4  Calculus",
    "section": "4.7 The Indefinite Integration",
    "text": "4.7 The Indefinite Integration\nSo far, we’ve been interested in finding the derivative \\(f=F'\\) of a function \\(F\\). However, sometimes we’re interested in exactly the reverse: finding the function \\(F\\) for which \\(f\\) is its derivative. We refer to \\(F\\) as the antiderivative of \\(f\\).\n\nDefinition 4.2 (Antiderivative) The antiverivative of a function \\(f(x)\\) is a differentiable function \\(F\\) whose derivative is \\(f\\).\n\\[F^\\prime = f.\\]\n\nAnother way to describe is through the inverse formula. Let \\(DF\\) be the derivative of \\(F\\). And let \\(DF(x)\\) be the derivative of \\(F\\) evaluated at \\(x\\). Then the antiderivative is denoted by \\(D^{-1}\\) (i.e., the inverse derivative). If \\(DF=f\\), then \\(F=D^{-1}f\\).\nThis definition bolsters the main takeaway about integrals and derivatives: They are inverses of each other.\n\nExercise 4.3 (Antiderivative) Find the antiderivative of the following:\n\n\\(f(x) = \\frac{1}{x^2}\\)\n\\(f(x) = 3e^{3x}\\)\n\n\nWe know from derivatives how to manipulate \\(F\\) to get \\(f\\). But how do you express the procedure to manipulate \\(f\\) to get \\(F\\)? For that, we need a new symbol, which we will call indefinite integration.\n:::{#def-indefint}"
  },
  {
    "objectID": "04_calculus.html#the-definite-integral-the-area-under-the-curve",
    "href": "04_calculus.html#the-definite-integral-the-area-under-the-curve",
    "title": "4  Calculus",
    "section": "5.1 The Definite Integral: The Area under the Curve",
    "text": "5.1 The Definite Integral: The Area under the Curve\nIf there is a indefinite integral, there must be a definite integral. Indeed there is, but the notion of definite integrals comes from a different objective: finding the are a under a function. We will find, perhaps remarkably, that the formula we find to get the sum turns out to be expressible by the anti-derivative.\nSuppose we want to determine the area \\(A(R)\\) of a region \\(R\\) defined by a curve \\(f(x)\\) and some interval \\(a\\le x \\le b\\).\n\n\n\n\n\nFigure 5.2: The Riemann Integral as a Sum of Evaluations\n\n\n\n\nOne way to calculate the area would be to divide the interval \\(a\\le x\\le b\\) into \\(n\\) subintervals of length \\(\\Delta x\\) and then approximate the region with a series of rectangles, where the base of each rectangle is \\(\\Delta x\\) and the height is \\(f(x)\\) at the midpoint of that interval. \\(A(R)\\) would then be approximated by the area of the union of the rectangles, which is given by \\[S(f,\\Delta x)=\\sum\\limits_{i=1}^n f(x_i)\\Delta x\\] and is called a Riemann sum.\nAs we decrease the size of the subintervals \\(\\Delta x\\), making the rectangles “thinner,” we would expect our approximation of the area of the region to become closer to the true area. This allows us to express the area as a limit of a series: \\[A(R)=\\lim\\limits_{\\Delta x\\to 0}\\sum\\limits_{i=1}^n f(x_i)\\Delta x\\]\nFigure 5.2 shows that illustration. The curve depicted is \\(f(x) = -15(x - 5) + (x - 5)^3 + 50.\\) We want approximate the area under the curve between the \\(x\\) values of 0 and 10. We can do this in blocks of arbitrary width, where the sum of rectangles (the area of which is width times \\(f(x)\\) evaluated at the midpoint of the bar) shows the Riemann Sum. As the width of the bars \\(\\Delta x\\) becomes smaller, the better the estimate of \\(A(R)\\).\nThis is how we define the “Definite” Integral:\n\nDefinition 5.1 (The Definite Integral (Riemann)) If for a given function \\(f\\) the Riemann sum approaches a limit as \\(\\Delta x \\to 0\\), then that limit is called the Riemann integral of \\(f\\) from \\(a\\) to \\(b\\). We express this with the \\(\\int\\), symbol, and write \\[\\int\\limits_a^b f(x) dx= \\lim\\limits_{\\Delta x\\to 0} \\sum\\limits_{i=1}^n f(x_i)\\Delta x\\]\nThe most straightforward of a definite integral is the definite integral. That is, we read \\[\\int\\limits_a^b f(x) dx\\] as the definite integral of \\(f\\) from \\(a\\) to \\(b\\) and we defined as the area under the “curve” \\(f(x)\\) from point \\(x=a\\) to \\(x=b\\).\n\nThe fundamental theorem of calculus shows us that this sum is, in fact, the antiderivative.\n\nTheorem 5.1 (First Fundamental Theorem of Calculus) Let the function \\(f\\) be bounded on \\([a,b]\\) and continuous on \\((a,b)\\). Then, suggestively, use the symbol \\(F(x)\\) to denote the definite integral from \\(a\\) to \\(x\\): \\[F(x)=\\int\\limits_a^x f(t)dt, \\quad a\\le x\\le b\\]\nThen \\(F(x)\\) has a derivative at each point in \\((a,b)\\) and \\[F^\\prime(x)=f(x), \\quad a<x<b\\] That is, the definite integral function of \\(f\\) is the one of the antiderivatives of some \\(f\\).\n\nThis is again a long way of saying that that differentiation is the inverse of integration. But now, we’ve covered definite integrals.\nThe second theorem gives us a simple way of computing a definite integral as a function of indefinite integrals.\n\nTheorem 5.2 (Second Fundamental Theorem of Calculus) Let the function \\(f\\) be bounded on \\([a,b]\\) and continuous on \\((a,b)\\). Let \\(F\\) be any function that is continuous on \\([a,b]\\) such that \\(F^\\prime(x)=f(x)\\) on \\((a,b)\\). Then \\[\\int\\limits_a^bf(x)dx = F(b)-F(a)\\]\n\nSo the procedure to calculate a simple definite integral \\(\\int\\limits_a^b f(x)dx\\) is then\n\nFind the indefinite integral \\(F(x)\\).\nEvaluate \\(F(b)-F(a)\\).\n\n\nExample 5.3 (Definite Integral of a monomial) Solve \\(\\int\\limits_1^3 3x^2 dx.\\)\nLet \\(f(x) = 3x^2\\).\n\n\nExercise 5.1 (Indefinite integrals) What is the value of \\(\\int\\limits_{-2}^2 e^x e^{e^x} dx\\)?\n\n\nCommon Rules for Definite Integrals\nThe area-interpretation of the definite integral provides some rules for simplification.\n\nThere is no area below a point: \\[\\int\\limits_a^a f(x)dx=0\\]\nReversing the limits changes the sign of the integral: \\[\\int\\limits_a^b f(x)dx=-\\int\\limits_b^a f(x)dx\\]\nSums can be separated into their own integrals: \\[\\int\\limits_a^b [\\alpha f(x)+\\beta g(x)]dx = \\alpha \\int\\limits_a^b f(x)dx + \\beta \\int\\limits_a^b g(x)dx\\]\nAreas can be combined as long as limits are linked: \\[\\int\\limits_a^b f(x) dx +\\int\\limits_b^c f(x)dx = \\int\\limits_a^c f(x)dx\\]\n\n\nExercise 5.2 (Definite integrals) Simplify the following definite intergrals.\n\n\\(\\int\\limits_1^1 3x^2 dx =\\)\n\\(\\int\\limits_0^4 (2x+1)dx=\\)\n\\(\\int\\limits_{-2}^0 e^x e^{e^x} dx + \\int\\limits_0^2 e^x e^{e^x} dx =\\)"
  },
  {
    "objectID": "04_calculus.html#integration-by-substitution",
    "href": "04_calculus.html#integration-by-substitution",
    "title": "4  Calculus",
    "section": "5.2 Integration by Substitution",
    "text": "5.2 Integration by Substitution\nFrom the second fundamental theorem of calculus, we now that a quick way to get a definite integral is to first find the indefinite integral, and then just plug in the bounds.\nSometimes the integrand (the thing that we are trying to take an integral of) doesn’t appear integrable using common rules and antiderivatives. A method one might try is integration by substitution, which is related to the Chain Rule.\nSuppose we want to find the indefinite integral \\[\\int g(x)dx\\] but \\(g(x)\\) is complex and none of the formulas we have seen so far seem to apply immediately. The trick is to come up with a new function \\(u(x)\\) such that \\[g(x)=f[u(x)]u'(x).\\]\nWhy does an introduction of yet another function end of simplifying things? Let’s refer to the antiderivative of \\(f\\) as \\(F\\). Then the chain rule tells us that \\[\\frac{d}{dx} F[u(x)]=f[u(x)]u'(x)\\]. So, \\(F[u(x)]\\) is the antiderivative of \\(g\\). We can then write \\[\\int g(x) dx= \\int f[u(x)]u'(x)dx = \\int \\frac{d}{dx} F[u(x)]dx = F[u(x)]+c\\]\nTo summarize, the procedure to determine the indefinite integral \\(\\int g(x)dx\\) by the method of substitution:\n\nIdentify some part of \\(g(x)\\) that might be simplified by substituting in a single variable \\(u\\) (which will then be a function of \\(x\\)).\nDetermine if \\(g(x)dx\\) can be reformulated in terms of \\(u\\) and \\(du\\).\nSolve the indefinite integral.\nSubstitute back in for \\(x\\)\n\nSubstitution can also be used to calculate a definite integral. Using the same procedure as above, \\[\\int\\limits_a^b g(x)dx=\\int\\limits_c^d f(u)du = F(d)-F(c)\\] where \\(c=u(a)\\) and \\(d=u(b)\\).\n\nExample 5.4 Integration by Substitution I\nSolve the indefinite integral \\[\\int x^2 \\sqrt{x+1}dx.\\]\n\nFor the above problem, we could have also used the substitution \\(u=\\sqrt{x+1}\\). Then \\(x=u^2-1\\) and \\(dx=2u du\\). Substituting these in, we get \\[\\int x^2\\sqrt{x+1}dx=\\int (u^2-1)^2 u 2u du\\] which when expanded is again a polynomial and gives the same result as above.\nAnother case in which integration by substitution is is useful is with a fraction.\n\nExample 5.5 (Integration by Substitutiton II) Simplify \\[\\int\\limits_0^1 \\frac{5e^{2x}}{(1+e^{2x})^{1/3}}dx.\\]"
  },
  {
    "objectID": "04_calculus.html#integration-by-parts",
    "href": "04_calculus.html#integration-by-parts",
    "title": "4  Calculus",
    "section": "5.3 Integration by Parts",
    "text": "5.3 Integration by Parts\nAnother useful integration technique is integration by parts, which is related to the Product Rule of differentiation. The product rule states that \\[\\frac{d}{dx}(uv)=u\\frac{dv}{dx}+v\\frac{du}{dx}\\] Integrating this and rearranging, we get \\[\\int u\\frac{dv}{dx}dx= u v - \\int v \\frac{du}{dx}dx\\] or \\[\\int u(x) v'(x)dx=u(x)v(x) - \\int v(x)u'(x)dx\\]\nMore easily remembered with the mnemonic “Ultraviolet Voodoo”: \\[\\int u dv = u v - \\int v du\\] where \\(du=u'(x)dx\\) and \\(dv=v'(x)dx\\).\nFor definite integrals, this is simply \\[\\int\\limits_a^b u\\frac{dv}{dx}dx = \\left. u v \\right|_a^b - \\int\\limits_a^b v \\frac{du}{dx}dx\\]\nOur goal here is to find expressions for \\(u\\) and \\(dv\\) that, when substituted into the above equation, yield an expression that’s more easily evaluated.\n\nExample 5.6 (Integration by parts) Simplify the following integrals. These seemingly obscure forms of integrals come up often when integrating distributions.\n\\[\\int x e^{ax} dx\\]\n\n\nSolution. Let \\(u=x\\) and \\(\\frac{dv}{dx} = e^{ax}\\). Then \\(du=dx\\) and \\(v=(1/a)e^{ax}\\). Substituting this into the integration by parts formula, we obtain\n\\[\\begin{eqnarray}\n\\int x e^{ax} dx &=& u v - \\int v du\\nonumber\\\\\n                &=&x\\left( \\frac{1}{a}e^{ax}\\right) -\\int\\frac{1}{a}e^{ax}dx\\nonumber\\\\\n                &=&\\frac{1}{a}xe^{ax}-\\frac{1}{a^2}e^{ax}+c\\nonumber\n\\end{eqnarray}\\]\n\n\n\nExercise 5.3 (Integration by parts) \nIntegrate \\[\\int x^n e^{ax} dx\\]\nIntegrate \\[\\int x^3 e^{-x^2} dx\\]"
  }
]