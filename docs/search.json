[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "University of Chicago Political Science Math Prefresher",
    "section": "",
    "text": "The 2022 UChicago Math Prefresher for incoming Political Science graduate students will be held from September 12-14; September 19-21 and September 23rd. The course is designed as a brief review of math fundamentals – calculus, optimization, probability theory and linear algebra among other topics – as well as an introduction to programming in the R statistical computing language. The course is entirely optional and there are no grades or assignments but we encourage all incoming graduate students to attend if they are able.\n\n\n\nThe course notes for the math and programming sections as well as all practice problems are available on this website and can be accessed by navigating the menus in the sidebar.\n\n\n\nThe prefresher will run for a total of seven days September 12-14, September 19-21 and September 23rd, with breaks for the APSA conference and the new student orientation. Each day will run from around 9am to 4pm with many breaks in between. We will be meeting in room 407 of Pick Hall.\nThe morning will focus on math instruction. We will have two one hour sessions from 9:30am - 10:30am and 10:45am-11:45am, with a ~15 minute break in between. These sessions will involve a combination of lectures and working through practice problems.\nWe will break for lunch from 12:00pm-1:00pm. On September 13th and Spetember 19th, we will have a catered lunch with a faculty member guest. Otherwise, you are free to explore the campus for various lunch options.\nThe afternoon will focus on coding instruction with lecture/demonstration from 1:30pm-2:45pm. After a short break you will work together on a variety of coding exercises from 3:00-3:30pm. In the last 30 minutes we will regroup to wrap up and discuss any questions on the material.\n\n\n\nAs the afternoons of the prefresher will involve instruction in coding, you should be sure to bring a laptop and a charging cable. In addition, prior to the start of the prefresher, please make sure to have installed the following on your computer:\n\nR (version 4.2.1 or higher)\nRStudio Desktop Open Source License (this is the primary IDE or integrated development environment in which we will be working)\nLaTeX: This is primarily to allow you to generate PDF documents using RMarkdown. We will use the TinyTeX LaTeX distribution which is designed to be minimalist and tailored specifically for R users. After installing R and RStudio, open up an instance of R, install the ‘tinytex’ package and run the install_tinytex() command\n\n\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n\nWe will also spend some time discussing document preparation and typesetting using LaTeX and Markdown. For the former, we will be using the popular cloud platform Overleaf, which allows for collaborative document editing and streamlines a lot of the irritating parts of typesetting in LaTeX. You should register for an account using your university e-mail as all University of Chicago students and faculty have access to an Overleaf Pro account for free.\nYou are also welcome to install a LaTeX editor on your local machine to work alongside the TinyTeX distribution or any other TeX distribution that you prefer such as TexMaker\n\n\n\nThis prefresher draws heavily on the wonderful materials that have been developed by over 20 years of instructors at the Harvard Government Math Prefresher that have been so generously distributed under the GPL 3.0 License. Special thanks to Shiro Kuriwaki, Yon Soo Park, and Connor Jerzak for their efforts in converting the original prefresher materials into the easily distributed Markdown format."
  },
  {
    "objectID": "02_sets_and_functions.html",
    "href": "02_sets_and_functions.html",
    "title": "2  Sets, Operations, and Functions",
    "section": "",
    "text": "Sets are the fundamental building blocks of mathematics. Events are not inherently numerical: the onset of war or the stock market crashing is not inherently a number. Sets can define such events, and we wrap math around so that we have a transparent language to communicate about those events. Combining sets with operations, relations, metrics, measures, etc… allows us to define useful mathematical structures. For example, the set of real numbers (\\(\\mathbb{R}\\)) has a notion of order as well as defined operations of addition and multiplication.\nSet : A set is any well defined collection of elements. If \\(x\\) is an element of \\(S\\), \\(x \\in S\\).\nExamples:\n\nThe set of choices available to a player in Rock-Paper-Scissors \\(\\{\\text{Rock}, \\text{Paper}, \\text{Scissors}\\}\\)\nThe set of possible outcomes of a roll of a six-sided die \\(\\{1, 2, 3, 4, 5, 6\\}\\)\nThe set of all natural numbers \\(\\mathbb{N}\\)\nThe set of all real numbers \\(\\mathbb{R}\\)\n\nCommon mathematical notation relevant to sets:\n\n\\(\\in\\) = “is an element of”; \\(\\notin\\) = “is not an element of”\n\\(\\forall\\) = “for all” (univeral quantifier)\n\\(\\exists\\) = “there exists” (existential quantifier)\n\\(:\\) = “such that”\n\nSubset: If every element of set \\(A\\) is also in set \\(B\\), then \\(A\\) is a subset of \\(B\\). \\(A \\subseteq B\\). If, in addition to being a subset of \\(B\\), \\(A\\) is not equal to \\(B\\), \\(A\\) is a proper subset \\(A \\subset B\\).\nEmpty Set: a set with no elements. \\(S = \\{\\}\\). It is denoted by the symbol \\(\\emptyset\\).\nCardinality: The cardinality of a set \\(S\\), typically written \\(|S|\\) is the number of members of \\(S\\).\nMany sets are infinite. For example, \\(\\mathbb{N}\\) the set of natural numbers \\(\\mathbb{N} = \\{0, 1, 2, 3, 4, \\dotsc\\}\\) - Sets with cardinality less than \\(|\\mathbb{N}|\\) are countable - Sets with the same cardinality as \\(\\\\mathbb{N}|\\) are countably infinite - Sets with greater cardinality than \\(|\\mathbb{N}|\\) are uncountably infinite (e.g. the real numbers).\nSet operations:\n\nUnion: The union of two sets \\(A\\) and \\(B\\), \\(A \\cup B\\), is the set containing all of the elements in \\(A\\) or \\(B\\). \\(A_1 \\cup A_2 \\cup \\cdots \\cup A_n = \\bigcup_{i=1}^n A_i\\)\nIntersection: The intersection of sets \\(A\\) and \\(B\\), \\(A \\cap B\\), is the set containing all of the elements in both \\(A\\) and \\(B\\). \\(A_1 \\cap A_2 \\cap \\cdots \\cap A_n = \\bigcap_{i=1}^n A_i\\)\nComplement: If set \\(A\\) is a subset of \\(S\\), then the complement of \\(A\\), denoted \\(A^C\\), is the set containing all of the elements in \\(S\\) that are not in \\(A\\).\n\nProperties of set operations:\n\nCommutative: \\(A \\cup B = B \\cup A\\); \\(A \\cap B = B \\cap A\\)\nAssociative: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\); \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nDistributive: \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\); \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\nde Morgan’s laws: \\((A \\cup B)^C = A^C \\cap B^C\\); \\((A \\cap B)^C = A^C \\cup B^C\\)\nDisjointness: Sets are disjoint when they do not intersect, such that \\(A \\cap B = \\emptyset\\). A collection of sets is pairwise disjoint (mutually exclusive) if, for all \\(i \\neq j\\), \\(A_i \\cap A_j = \\emptyset\\). A collection of sets form a partition of set \\(S\\) if they are pairwise disjoint and they cover set \\(S\\), such that \\(\\bigcup_{i = 1}^k A_i = S\\).\n\n\nExample 2.1 (Sets) Let set \\(A\\) be \\(\\{1, 2, 3, 4\\}\\), \\(B\\) be \\(\\{3, 4, 5, 6\\}\\), and \\(C\\) be \\(\\{5, 6, 7, 8\\}\\). Sets \\(A\\), \\(B\\), and \\(C\\) are all subsets of the \\(S\\) which is \\(\\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}\\)\nWrite out the following sets:\n\n\\(A \\cup B\\)\n\\(C \\cap B\\)\n\\(B^c\\)\n\\(A \\cap (B \\cup C)\\)\n\n\n\nExercise 2.1 (Sets) Suppose you had a pair of four-sided dice. You sum the results from a single toss.\nWhat is the set of possible outcomes?\nConsider subsets \\(A=\\{2, 8\\}\\) and \\(B=\\{2,3,7\\}\\) of the sample space you found. What is\n\n\\(A^c\\)\n\\((A \\cup B)^c\\)"
  },
  {
    "objectID": "02_sets_and_functions.html#metric-spaces",
    "href": "02_sets_and_functions.html#metric-spaces",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.2 Metric spaces",
    "text": "2.2 Metric spaces\nA metric space is a set that has a notion of distance - called a “metric” - defined between any two elements (sometimes referred to as “points”).\nThe distance function \\(d(x,y)\\) defines the distance between element \\(x\\) and element \\(y\\)\n\nThe real numbers \\(\\mathbb{R}\\) have a single distance function: \\(d(x,y) = |x - y|\\)\nIn higher-dimensional real space (e.g. \\(\\mathbb{R}^2)\\), we can define multiple distance metrics between \\(x=(x_1, x_2)\\) and \\(y=(y_1, y_2)\\)\n\n“Euclidean” distance: \\(d(x, y) = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2}\\)\n“Taxicab” distance: \\(d(x, y) = |x_1 - y_1| + |x_2 - y_2|\\)\nChebyshev distance: \\(d(x, y) = \\text{max}\\{|x_1 - y_1| + |x_2 - y_2|\\}\\)\n\nAll of these generalize to \\(\\mathbb{R}^n\\)\n\nA metric is a function that satisfies the following axioms\n\nA distance between a point and itself is zero \\(d(x,x) = 0\\)\nThe distance between two points is strictly positive \\(d(x,y) > 0 \\forall x \\neq y\\)\nDistance from \\(x\\) to \\(y\\) is the same as the distance from \\(y\\) to \\(x\\) (\\(d(x,y) = d(y,x)\\))\nThe “triangle inequality” holds: \\(d(x,z) \\le d(x,y) + d(y,z)\\)\n\nOnce we have a metric space, we can define some additional useful concepts\nBall: A ball of radius \\(r\\) centered at \\(x_0\\) is a set that contains all points with a distance less than \\(r\\) from \\(x_0\\).\nSphere: A sphere of radius \\(r\\) centered at \\(x_0\\) is the set that contains all points with a distance exactly \\(r\\) from \\(x_0\\).\nInterior Point: The point \\(x\\) is an interior point of the set \\(S\\) if \\(x\\) is in \\(S\\) and if there is some \\(\\epsilon\\)-ball around \\(x\\) that contains only points in \\(S\\). The interior of \\(S\\) is the collection of all interior points in \\(S\\). The interior can also be defined as the union of all open sets in \\(S\\).\n\nIf the set \\(S\\) is circular, the interior points are everything inside of the circle, but not on the circle’s rim.\nExample: The interior of the set \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) is \\(\\{ (x,y) : x^2+y^2< 4 \\}\\) .\n\nBoundary Point: The point \\(\\mathbf x\\) is a boundary point of the set \\(S\\) if every \\(\\epsilon\\)-ball around \\(\\mathbf x\\) contains both points that are in \\(S\\) and points that are outside \\(S\\). The boundary is the collection of all boundary points.\n\nIf the set \\(S\\) is circular, the boundary points are everything on the circle’s rim.\nExample: The boundary of \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\) is \\(\\{ (x,y) : x^2+y^2 = 4 \\}\\).\n\nOpen: A set \\(S\\) is open if for each point \\(\\mathbf x\\) in \\(S\\), there exists an open \\(\\epsilon\\)-ball around \\(\\mathbf x\\) completely contained in \\(S\\).\n\nIf the set \\(S\\) is circular and open, the points contained within the set get infinitely close to the circle’s rim, but do not touch it.\nExample: \\(\\{ (x,y) : x^2+y^2<4 \\}\\)\n\nClosed: A set \\(S\\) is closed if it contains all of its boundary points.\n\nAlternatively: A set is closed if its complement is open.\nIf the set \\(S\\) is circular and closed, the set contains all points within the rim as well as the rim itself.\nExample: \\(\\{ (x,y) : x^2+y^2\\le 4 \\}\\)\nNote: a set may be neither open nor closed. Example: \\(\\{ (x,y) : 2 < x^2+y^2\\le 4 \\}\\)"
  },
  {
    "objectID": "02_sets_and_functions.html#operators-sum-and-product-notation",
    "href": "02_sets_and_functions.html#operators-sum-and-product-notation",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.3 Operators; Sum and Product notation",
    "text": "2.3 Operators; Sum and Product notation\nAddition (+), Subtraction (-), multiplication and division are basic operations of arithmetic. In statistics or calculus, we will often want to add a sequence of numbers that can be expressed as a pattern without needing to write down all its components. For example, how would we express the sum of all numbers from 1 to 100 without writing a hundred numbers?\nFor this we use the summation operator \\(\\sum\\) and the product operator \\(\\prod\\).\nSummation:\n\\[\\sum\\limits_{i=1}^{100} x_i = x_1+x_2+x_3+\\cdots+x_{100}\\]\nThe bottom of the \\(\\sum\\) symbol indicates an index (here, \\(i\\)), and its start value \\(1\\). At the top is where the index ends. The notion of “addition” is part of the \\(\\sum\\) symbol. The content to the right of the summation is the meat of what we add. While you can pick your favorite index, start, and end values, the content must also have the index.\nA few important features of sums:\n\n\\(\\sum\\limits_{i=1}^n c x_i = c \\sum\\limits_{i=1}^n x_i\\)\n\\(\\sum\\limits_{i=1}^n (x_i + y_i) = \\sum\\limits_{i=1}^n x_i + \\sum\\limits_{i=1}^n y_i\\)\n\\(\\sum\\limits_{i=1}^n c = n c\\)\n\nProduct:\n\\[\\prod\\limits_{i=1}^n x_i = x_1 x_2 x_3 \\cdots x_n\\]\nProperties:\n\n\\(\\prod\\limits_{i=1}^n c x_i = c^n \\prod\\limits_{i=1}^n x_i\\)\n\\(\\prod\\limits_{i=k}^n c x_i = c^{n-k+1} \\prod\\limits_{i=k}^n x_i\\)\n\\(\\prod\\limits_{i=1}^n (x_i + y_i) =\\) a total mess\n\\(\\prod\\limits_{i=1}^n c = c^n\\)\n\nOther Useful Operations\nFactorials!:\n\\[x! = x\\cdot (x-1) \\cdot (x-2) \\cdots (1)\\]\nModulo: Tells you the remainder when you divide the first number by the second.\n\n\\(17 \\mod 3 = 2\\)\n\\(100 \\ \\% \\ 30 = 10\\)\n\n\n\nExample 2.2 (Operators) \n\\(\\sum\\limits_{i=1}^{5} i =\\)\n\\(\\prod\\limits_{i=1}^{5} i =\\)\n\\(14 \\mod 4 =\\)\n\\(4! =\\)\n\n\n\nExercise 2.2 (Operators) Let \\(x_1 = 4, x_2 = 3, x_3 = 7, x_4 = 11, x_5 = 2\\)\n\n\\(\\sum\\limits_{i=1}^{3} (7)x_i\\)\n\\(\\sum\\limits_{i=1}^{5} 2\\)\n\\(\\prod\\limits_{i=3}^{5} (2)x_i\\)"
  },
  {
    "objectID": "02_sets_and_functions.html#introduction-to-functions",
    "href": "02_sets_and_functions.html#introduction-to-functions",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.4 Introduction to Functions",
    "text": "2.4 Introduction to Functions\nA function is a mapping, or transformation, that relates members of one set to members of another set. For instance, if you have two sets: set \\(A\\) and set \\(B\\), a function from \\(A\\) to \\(B\\) maps every value \\(a\\) in set \\(A\\) such that \\(f(a) \\in B\\). Functions can be “many-to-one”, where many values or combinations of values from set \\(A\\) produce a single output in set \\(B\\), or they can be “one-to-one”, where each value in set \\(A\\) corresponds to a single value in set \\(B\\). A function by definition has a single function value for each element of its domain. This means, there cannot be “one-to-many” mapping.\nDimensionality: \\({\\mathbf R}^1\\) is the set of all real numbers extending from \\(-\\infty\\) to \\(+\\infty\\) — i.e., the real number line. \\({\\mathbf R}^n\\) is an \\(n\\)-dimensional space, where each of the \\(n\\) axes extends from \\(-\\infty\\) to \\(+\\infty\\).\n\n\\({\\mathbf R}^1\\) is a one dimensional line.\n\\({\\mathbf R}^2\\) is a two dimensional plane.\n\\({\\mathbf R}^3\\) is a three dimensional space.\n\nPoints in \\({\\mathbf R}^n\\) are ordered \\(n\\)-tuples (just means an combination of \\(n\\) elements where order matters), where each element of the \\(n\\)-tuple represents the coordinate along that dimension.\nFor example:\n\n\\({\\mathbf R}^1\\): (3)\n\\({\\mathbf R}^2\\): (-15, 5)\n\\({\\mathbf R}^3\\): (86, 4, 0)\n\nExamples of mapping notation:\nFunction of one variable: \\(f:{\\mathbf R}^1\\to{\\mathbf R}^1\\)\n\n\\(f(x)=x+1\\). For each \\(x\\) in \\({\\mathbf R}^1\\), \\(f(x)\\) assigns the number \\(x+1\\).\n\nFunction of two variables: \\(f: {\\mathbf R}^2\\to{\\mathbf R}^1\\).\n\n\\(f(x,y)=x^2+y^2\\). For each ordered pair \\((x,y)\\) in \\({\\mathbf R}^2\\), \\(f(x,y)\\) assigns the number \\(x^2+y^2\\).\n\nWe often use variable \\(x\\) as input and another \\(y\\) as output, e.g. \\(y=x+1\\)\n\nExample 2.3 (Functions) For each of the following, state whether they are one-to-one or many-to-one functions.\n\nFor \\(x \\in [0,\\infty]\\), \\(f : x \\rightarrow x^2\\) (this could also be written as \\(f(x) = x^2\\)).\nFor \\(x \\in [-\\infty, \\infty]\\), \\(f: x \\rightarrow x^2\\).\n\n\n\nExercise 2.3 (Functions) For each of the following, state whether they are one-to-one or many-to-one functions.\n\nFor \\(x \\in [-3, \\infty]\\), \\(f: x \\rightarrow x^2\\).\nFor \\(x \\in [0, \\infty]\\), \\(f: x \\rightarrow \\sqrt{x}\\)\n\n\nSome functions are defined only on proper subsets of \\({\\mathbf R}^n\\).\n\nDomain: the set of numbers in \\(X\\) at which \\(f(x)\\) is defined.\nRange: elements of \\(Y\\) assigned by \\(f(x)\\) to elements of \\(X\\), or \\(f(X)=\\{ y : y=f(x), x\\in X\\}\\) Most often used when talking about a function \\(f:{\\mathbf R}^1\\to{\\mathbf R}^1\\).\nImage: same as range, but more often used when talking about a function \\(f:{\\mathbf R}^n\\to{\\mathbf R}^1\\).\n\nSome General Types of Functions\nMonomials: \\(f(x)=a x^k\\)\n\\(a\\) is the coefficient. \\(k\\) is the degree.\nExamples: \\(y=x^2\\), \\(y=-\\frac{1}{2}x^3\\)\nPolynomials: sum of monomials.\nExamples: \\(y=-\\frac{1}{2}x^3+x^2\\), \\(y=3x+5\\)\nThe degree of a polynomial is the highest degree of its monomial terms. Also, it’s often a good idea to write polynomials with terms in decreasing degree."
  },
  {
    "objectID": "02_sets_and_functions.html#logexponents",
    "href": "02_sets_and_functions.html#logexponents",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.5 Logarithms and Exponents",
    "text": "2.5 Logarithms and Exponents\nExponential Functions: Example: \\(y=2^x\\)\nRelationship of logarithmic and exponential functions: \\[y=\\log_a(x) \\iff a^y=x\\]\nThe log function can be thought of as an inverse for exponential functions. \\(a\\) is referred to as the “base” of the logarithm.\nCommon Bases: The two most common logarithms are base 10 and base \\(e\\).\n\nBase 10: \\(\\quad y=\\log_{10}(x) \\iff 10^y=x\\). The base 10 logarithm is often simply written as “\\(\\log(x)\\)” with no base denoted.\nBase \\(e\\): \\(\\quad y=\\log_e(x) \\iff e^y=x\\). The base \\(e\\) logarithm is referred to as the “natural” logarithm and is written as ``\\(\\ln(x)\\)“.\n\nProperties of exponential functions:\n\n\\(a^x a^y = a^{x+y}\\)\n\\(a^{-x} = 1/a^x\\)\n\\(a^x/a^y = a^{x-y}\\)\n\\((a^x)^y = a^{x y}\\)\n\\(a^0 = 1\\)\n\nProperties of logarithmic functions (any base):\nGenerally, when statisticians or social scientists write \\(\\log(x)\\) they mean \\(\\log_e(x)\\). In other words: \\(\\log_e(x) \\equiv \\ln(x) \\equiv \\log(x)\\)\n\\[\\log_a(a^x)=x\\] and \\[a^{\\log_a(x)}=x\\]\n\n\\(\\log(x y)=\\log(x)+\\log(y)\\)\n\\(\\log(x^y)=y\\log(x)\\)\n\\(\\log(1/x)=\\log(x^{-1})=-\\log(x)\\)\n\\(\\log(x/y)=\\log(x\\cdot y^{-1})=\\log(x)+\\log(y^{-1})=\\log(x)-\\log(y)\\)\n\\(\\log(1)=\\log(e^0)=0\\)\n\nChange of Base Formula: Use the change of base formula to switch bases as necessary: \\[\\log_b(x) = \\frac{\\log_a(x)}{\\log_a(b)}\\]\nExample: \\[\\log_{10}(x) = \\frac{\\ln(x)}{\\ln(10)}\\]\nYou can use logs to go between sum and product notation. This will be particularly important when you’re learning how to optimize likelihood functions.\n\\[\\begin{eqnarray*}\n            \\log \\bigg(\\prod\\limits_{i=1}^n x_i \\bigg) &=& \\log(x_1 \\cdot x_2 \\cdot x_3 \\cdots \\cdot x_n)\\\\\n            &=& \\log(x_1) + \\log(x_2) + \\log(x_3) + \\cdots + \\log(x_n)\\\\\n            &=& \\sum\\limits_{i=1}^n \\log (x_i)\n\\end{eqnarray*}\\]\nTherefore, you can see that the log of a product is equal to the sum of the logs. We can write this more generally by adding in a constant, \\(c\\):\n\\[\\begin{eqnarray*}\n            \\log \\bigg(\\prod\\limits_{i=1}^n c x_i\\bigg) &=& \\log(cx_1 \\cdot cx_2 \\cdots cx_n)\\\\\n            &=& \\log(c^n \\cdot x_1 \\cdot x_2 \\cdots x_n)\\\\\n            &=& \\log(c^n) + \\log(x_1) + \\log(x_2) + \\cdots + \\log(x_n)\\\\\\\\\n            &=& n \\log(c) +  \\sum\\limits_{i=1}^n \\log (x_i)\\\\\n\\end{eqnarray*}\\]\n\nExample 2.4 (Logarithms) Evaluate each of the following logarithms\n\n\\(\\log_4(16)\\)\n\\(\\log_2(16)\\)\n\nSimplify the following logarithm. By “simplify”, we actually really mean - use as many of the logarithmic properties as you can.\n\n\\(\\log_4(x^3y^5)\\)\n\n\n\nExercise 2.4 Evaluate each of the following logarithms\n\n\\(\\log_\\frac{3}{2}(\\frac{27}{8})\\)\n\nSimplify each of the following logarithms. By “simplify”, we actually really mean - use as many of the logarithmic properties as you can.\n\n\\(\\log(\\frac{x^9y^5}{z^3})\\)\n\\(\\ln{\\sqrt{xy}}\\)"
  },
  {
    "objectID": "02_sets_and_functions.html#graphing-functions",
    "href": "02_sets_and_functions.html#graphing-functions",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.6 Graphing Functions",
    "text": "2.6 Graphing Functions\nWhat can a graph tell you about a function?\n\nIs the function increasing or decreasing? Over what part of the domain?\nHow ``fast” does it increase or decrease?\nAre there global or local maxima and minima? Where?\nAre there inflection points?\nIs the function continuous?\nIs the function differentiable?\nDoes the function tend to some limit?\nOther questions related to the substance of the problem at hand."
  },
  {
    "objectID": "02_sets_and_functions.html#solving-for-variables-and-finding-roots",
    "href": "02_sets_and_functions.html#solving-for-variables-and-finding-roots",
    "title": "2  Sets, Operations, and Functions",
    "section": "2.7 Solving for Variables and Finding Roots",
    "text": "2.7 Solving for Variables and Finding Roots\nSometimes we’re given a function \\(y=f(x)\\) and we want to find how \\(x\\) varies as a function of \\(y\\). Use algebra to move \\(x\\) to the left hand side (LHS) of the equation and so that the right hand side (RHS) is only a function of \\(y\\).\n\nExample 2.5 (Solving) Solve for x:\n\n\\(y=3x+2\\)\n\\(y=e^x\\)\n\n\nSolving for variables is especially important when we want to find the roots of an equation: those values of variables that cause an equation to equal zero. Especially important in finding equilibria and in doing maximum likelihood estimation.\nProcedure: Given \\(y=f(x)\\), set \\(f(x)=0\\). Solve for \\(x\\).\nMultiple Roots: \\[f(x)=x^2 - 9 \\quad\\Longrightarrow\\quad 0=x^2 - 9 \\quad\\Longrightarrow\\quad 9=x^2 \\quad\\Longrightarrow\\quad \\pm \\sqrt{9}=\\sqrt{x^2} \\quad\\Longrightarrow\\quad \\pm 3=x\\]\nQuadratic Formula: For quadratic equations \\(ax^2+bx+c=0\\), use the quadratic formula: \\[x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}\\]\n\nExercise 2.5 (Roots) Solve for x:\n\n\\(f(x)=3x+2 = 0\\)\n\\(f(x)=x^2+3x-4=0\\)\n\\(f(x)=e^{-x}-10 = 0\\)"
  },
  {
    "objectID": "03_limits.html",
    "href": "03_limits.html",
    "title": "3  Limits",
    "section": "",
    "text": "Solving limits, i.e. finding out the value of functions as its input moves closer to some value, is important for the social scientist’s mathematical toolkit for two related tasks. The first is for the study of calculus, which will be in turn useful to show where certain functions are maximized or minimized. The second is for the study of statistical inference, which is the study of inferring things about things you cannot see by using things you can see."
  },
  {
    "objectID": "03_limits.html#example-the-central-limit-theorem",
    "href": "03_limits.html#example-the-central-limit-theorem",
    "title": "3  Limits",
    "section": "Example: The Central Limit Theorem",
    "text": "Example: The Central Limit Theorem\nPerhaps the most important theorem in statistics is the Central Limit Theorem,\n\nTheorem 3.1 (Central Limit Theorem) For any series of independent and identically distributed random variables \\(X_1, X_2, \\cdots\\), we know the distribution of its sum even if we do not know the distribution of \\(X\\). The distribution of the sum is a Normal distribution.\n\\[\\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\xrightarrow{d} \\text{Normal}(0, 1)\\]\nwhere \\(\\mu\\) is the mean of \\(X\\) and \\(\\sigma\\) is the standard deviation of \\(X\\). The arrow is read as “converges in distribution to”. \\(\\text{Normal}(0, 1)\\) indicates a Normal Distribution with mean 0 and variance 1.\nThat is, the limit of the distribution of the lefthand side is the distribution of the righthand side.\n\nThe sign of a limit is the arrow “\\(\\rightarrow\\)”. Although we have not yet covered probability so we have not described what distributions and random variables are, it is worth foreshadowing the Central Limit Theorem. The Central Limit Theorem is powerful because it gives us a guarantee of what would happen if \\(n \\rightarrow \\infty\\), which in this case means we collected more data."
  },
  {
    "objectID": "03_limits.html#example-the-law-of-large-numbers",
    "href": "03_limits.html#example-the-law-of-large-numbers",
    "title": "3  Limits",
    "section": "Example: The Law of Large Numbers",
    "text": "Example: The Law of Large Numbers\nA finding that perhaps rivals the Central Limit Theorem is the (Weak) Law of Large Numbers:\n\nTheorem 3.2 ((Weak) Law of Large Numbers) For any draw of identically distributed independent variables with mean \\(\\mu\\), the sample average after \\(n\\) draws, \\(\\bar{X}_n\\), converges in probability to the true mean as \\(n \\rightarrow \\infty\\):\n\\[\\lim\\limits_{n\\to \\infty} P(|\\bar{X}_n - \\mu | > \\varepsilon) = 0\\]\nA shorthand of which is \\(\\bar{X}_n \\xrightarrow{p} \\mu\\), where the arrow is read as “converges in probability to”.\n\nIntuitively, the more data, the more accurate is your guess. For example, Figure 3.1 shows how the sample average from many coin tosses converges to the true value : 0.5.\n\n\n\n\n\nFigure 3.1: As the number of coin tosses goes to infinity, the average probabiity of heads converges to 0.5"
  },
  {
    "objectID": "03_limits.html#sequences",
    "href": "03_limits.html#sequences",
    "title": "3  Limits",
    "section": "3.1 Sequences",
    "text": "3.1 Sequences\nWe need a couple of steps until we get to limit theorems in probability. First we will introduce a “sequence”, then we will think about the limit of a sequence, then we will think about the limit of a function.\nA sequence \\(\\{x_n\\}=\\{x_1, x_2, x_3, \\ldots, x_n\\}\\) is an ordered set of real numbers, where \\(x_1\\) is the first term in the sequence and \\(y_n\\) is the \\(n\\)th term. Generally, a sequence is infinite, that is it extends to \\(n=\\infty\\). We can also write the sequence as \\(\\{x_n\\}^\\infty_{n=1}\\)\nwhere the subscript and superscript are read together as “from 1 to infinity.”\n\nExample 3.1 (Sequences) How do these sequences behave?\n\n\\(\\{A_n\\}=\\left\\{ 2-\\frac{1}{n^2} \\right\\}\\)\n\\(\\{B_n\\}=\\left\\{\\frac{n^2+1}{n} \\right\\}\\)\n\\(\\{C_n\\}=\\left\\{(-1)^n \\left(1-\\frac{1}{n}\\right) \\right\\}\\)\n\n\nWe find the sequence by simply “plugging in” the integers into each \\(n\\). The important thing is to get a sense of how these numbers are going to change.\nGraphing helps you make this point more clearly. See the sequence of \\(n = 1, ...20\\) for each of the three examples in Figure 3.2.\n\n\n\n\n\nFigure 3.2: Behavior of Some Sequences"
  },
  {
    "objectID": "03_limits.html#the-limit-of-a-sequence",
    "href": "03_limits.html#the-limit-of-a-sequence",
    "title": "3  Limits",
    "section": "3.2 The Limit of a Sequence",
    "text": "3.2 The Limit of a Sequence\nThe notion of “converging to a limit” is the behavior of the points in Example -@#exm-seqbehav. In some sense, that’s the counterfactual we want to know. What happens as \\(n\\rightarrow \\infty\\)?\n\nSequences like 1 above that converge to a limit.\nSequences like 2 above that increase without bound.\nSequences like 3 above that neither converge nor increase without bound — alternating over the number line.\n\nDefinition: Limit The sequence \\(\\{y_n\\}\\) has the limit \\(L\\), which we write as \\(\\lim\\limits_{n \\to \\infty} y_n =L\\), if for any \\(\\epsilon>0\\) there is an integer \\(N\\) (which depends on \\(\\epsilon\\)) with the property that \\(|y_n -L|<\\epsilon\\) for each \\(n>N\\). \\(\\{y_n\\}\\) is said to converge to \\(L\\). If the above does not hold, then \\(\\{y_n\\}\\) diverges.\nWe can also express the behavior of a sequence as bounded or not:\n\nBounded: if \\(|y_n|\\le K\\) for all \\(n\\)\nMonotonically Increasing: \\(y_{n+1}>y_n\\) for all \\(n\\)\nMonotonically Decreasing: \\(y_{n+1}<y_n\\) for all \\(n\\)\n\nA limit is unique: If \\(\\{y_n\\}\\) converges, then the limit \\(L\\) is unique.\nIf a sequence converges, then the sum of such sequences also converges. Let \\(\\lim\\limits_{n \\to \\infty} y_n = y\\) and \\(\\lim\\limits_{n \\to \\infty} z_n =z\\). Then\n\n\\(\\lim\\limits_{n \\to \\infty} [k y_n + \\ell z_n]= k y + \\ell z\\)\n\\(\\lim\\limits_{n \\to \\infty} y_n z_n = yz\\)\n\\(\\lim\\limits_{n \\to \\infty} \\frac{y_n}{z_n} = \\frac{y}{z}\\), provided \\(z\\neq 0\\)\n\nThis looks reasonable enough. The harder question, obviously is when the parts of the fraction don’t converge. If \\(\\lim_{n\\to\\infty} y_n = \\infty\\) and \\(\\lim_{n\\to\\infty} z_n = \\infty\\), What is \\(\\lim_{n\\to\\infty} y_n - z_n\\)? What is \\(\\lim_{n\\to\\infty} \\frac{y_n}{z_n}\\)?\nIt is nice for a sequence to converge in limit. We want to know if complex-looking sequences converge or not. The name of the game here is to break that complex sequence up into sums of simple fractions where \\(n\\) only appears in the denominator: \\(\\frac{1}{n}, \\frac{1}{n^2}\\), and so on. Each of these will converge to 0, because the denominator gets larger and larger. Then, because of the properties above, we can then find the final sequence.\n\nExample 3.2 (Ratios) Find the limit of \\(\\lim_{n\\to \\infty} \\frac{n + 3}{n}\\)\n\n\nSolution. At first glance, \\(n + 3\\) and \\(n\\) both grow to \\(\\infty\\), so it looks like we need to divide infinity by infinity. However, we can express this fraction as a sum, then the limits apply separately:\n\\[\\lim_{n\\to \\infty} \\frac{n + 3}{n} = \\lim_{n\\to \\infty} \\left(1 + \\frac{3}{n}\\right) =  \\underbrace{\\lim_{n\\to \\infty}1}_{1} +  \\underbrace{\\lim_{n\\to \\infty}\\left(\\frac{3}{n}\\right)}_{0}\\]\nso, the limit is actually 1.\n\nAfter some practice, the key to intuition is whether one part of the fraction grows “faster” than another. If the denominator grows faster to infinity than the numerator, then the fraction will converge to 0, even if the numerator will also increase to infinity. In a sense, limits show how not all infinities are the same.\n\nExercise 3.1 (Limits) Find the following limits of sequences, then explain in English the intuition for why that is the case.\n\n\\(\\lim\\limits_{n\\to\\infty} \\frac{2n}{n^2 + 1}\\)\n\\(\\lim\\limits_{n\\to\\infty} (n^3 - 100n^2)\\)"
  },
  {
    "objectID": "03_limits.html#limitsfun",
    "href": "03_limits.html#limitsfun",
    "title": "3  Limits",
    "section": "3.3 Limits of a Function",
    "text": "3.3 Limits of a Function\nWe’ve now covered functions and just covered limits of sequences, so now is the time to combine the two.\nA function \\(f\\) is a compact representation of some behavior we care about. Like for sequences, we often want to know if \\(f(x)\\) approaches some number \\(L\\) as its independent variable \\(x\\) moves to some number \\(c\\) (which is usually 0 or \\(\\pm\\infty\\)). If it does, we say that the limit of \\(f(x)\\), as \\(x\\) approaches \\(c\\), is \\(L\\): \\(\\lim\\limits_{x \\to c} f(x)=L\\). Unlike a sequence, \\(x\\) is a continuous number, and we can move in decreasing order as well as increasing.\nFor a limit \\(L\\) to exist, the function \\(f(x)\\) must approach \\(L\\) from both the left (increasing) and the right (decreasing).\n\nDefinition 3.1 (Limits of a function) Let \\(f(x)\\) be defined at each point in some open interval containing the point \\(c\\). Then \\(L\\) equals \\(\\lim\\limits_{x \\to c} f(x)\\) if for any (small positive) number \\(\\epsilon\\), there exists a corresponding number \\(\\delta>0\\) such that if \\(0<|x-c|<\\delta\\), then \\(|f(x)-L|<\\epsilon\\).\n\nA neat, if subtle result is that \\(f(x)\\) does not necessarily have to be defined at \\(c\\) for \\(\\lim\\limits_{x \\to c}\\) to exist.\nProperties: Let \\(f\\) and \\(g\\) be functions with \\(\\lim\\limits_{x \\to c} f(x)=k\\) and \\(\\lim\\limits_{x \\to c} g(x)=\\ell\\).\n\n\\(\\lim\\limits_{x \\to c}[f(x)+g(x)]=\\lim\\limits_{x \\to c} f(x)+ \\lim\\limits_{x \\to c} g(x)\\)\n\\(\\lim\\limits_{x \\to c} kf(x) = k\\lim\\limits_{x \\to c} f(x)\\)\n\\(\\lim\\limits_{x \\to c} f(x) g(x) = \\left[\\lim\\limits_{x \\to c} f(x)\\right]\\cdot \\left[\\lim\\limits_{x \\to c} g(x)\\right]\\)\n\\(\\lim\\limits_{x \\to c} \\frac{f(x)}{g(x)} = \\frac{\\lim\\limits_{x \\to c} f(x)}{\\lim\\limits_{x \\to c} g(x)}\\), provided \\(\\lim\\limits_{x \\to c} g(x)\\ne 0\\).\n\nSimple limits of functions can be solved as we did limits of sequences. Just be careful which part of the function is changing.\n\nExample 3.3 (Limits of a function) Find the limit of the following functions.\n\n\\(\\lim_{x \\to c} k\\)\n\\(\\lim_{x \\to c} x\\)\n\\(\\lim_{x\\to 2} (2x-3)\\)\n\\(\\lim_{x \\to c} x^n\\)\n\n\nLimits can get more complex in roughly two ways. First, the functions may become large polynomials with many moving pieces. Second, the functions may become discontinuous.\nThe function can be thought of as a more general or “smooth” version of sequences. For example,\n\nExample 3.4 (Limits of ratios) Find the limit of\n\\[\\lim_{x\\to\\infty} \\frac{(x^4 +3x−99)(2−x^5)}{(18x^7 +9x^6 −3x^2 −1)(x+1)}\\]\n\nNow, the functions will become a bit more complex:\n\nExercise 3.2 (Limits of a function) Solve the following limits of functions\n\n\\(\\lim\\limits_{x\\to 0} |x|\\)\n\\(\\lim\\limits_{x\\to 0} \\left(1+\\frac{1}{x^2}\\right)\\)\n\n\nSo there are a few more alternatives about what a limit of a function could be:\n\nRight-hand limit: The value approached by \\(f(x)\\) when you move from right to left.\nLeft-hand limit: The value approached by \\(f(x)\\) when you move from left to right.\nInfinity: The value approached by \\(f(x)\\) as x grows infinitely large. Sometimes this may be a number; sometimes it might be \\(\\infty\\) or \\(-\\infty\\).\nNegative infinity: The value approached by \\(f(x)\\) as x grows infinitely negative. Sometimes this may be a number; sometimes it might be \\(\\infty\\) or \\(-\\infty\\).\n\nThe distinction between left and right becomes important when the function is not determined for some values of \\(x\\). What are those cases in the examples below?\n\n\n\n\n\nFunctions which are not defined in some areas"
  },
  {
    "objectID": "03_limits.html#continuity",
    "href": "03_limits.html#continuity",
    "title": "3  Limits",
    "section": "3.4 Continuity",
    "text": "3.4 Continuity\nTo repeat a finding from the limits of functions: \\(f(x)\\) does not necessarily have to be defined at \\(c\\) for \\(\\lim\\limits_{x \\to c}\\) to exist. Functions that have breaks in their lines are called discontinuous. Functions that have no breaks are called continuous. Continuity is a concept that is more fundamental to, but related to that of “differentiability”, which we will cover next in calculus.\n\nDefinition 3.2 (Continuity) Suppose that the domain of the function \\(f\\) includes an open interval containing the point \\(c\\). Then \\(f\\) is continuous at \\(c\\) if \\(\\lim\\limits_{x \\to c} f(x)\\) exists and if \\(\\lim\\limits_{x \\to c} f(x)=f(c)\\). Further, \\(f\\) is continuous on an open interval \\((a,b)\\) if it is continuous at each point in the interval.\n\nTo prove that a function is continuous for all points is beyond this practical introduction to math, but the general intuition can be grasped by graphing.\n\nExample 3.5 (Continuity) For each function, determine if it is continuous or discontinuous.\n\n\\(f(x) = \\sqrt{x}\\)\n\\(f(x) = e^x\\)\n\\(f(x) = 1 + \\frac{1}{x^2}\\)\n\\(f(x) = \\text{floor}(x)\\).\n\nThe floor is the smaller of the two integers bounding a number. So \\(\\text{floor}(x = 2.999) = 2\\), \\(\\text{floor}(x = 2.0001) = 2\\), and \\(\\text{floor}(x = 2) = 2.\\)\n\n\nSolution. In Figure 3.3, we can see that the first two functions are continuous, and the next two are discontinuous. \\(f(x) = 1 + \\frac{1}{x^2}\\) is discontinuous at \\(x= 0\\), and \\(f(x) = \\text{floor}(x)\\) is discontinuous at each whole number.\n\n\n\n\n\nFigure 3.3: Continuous and Discontinuous Functions\n\n\n\n\n\nSome properties of continuous functions:\n\nIf \\(f\\) and \\(g\\) are continuous at point \\(c\\), then \\(f+g\\), \\(f-g\\), \\(f \\cdot g\\), \\(|f|\\), and \\(\\alpha f\\) are continuous at point \\(c\\) also. \\(f/g\\) is continuous, provided \\(g(c)\\ne 0\\).\nBoundedness: If \\(f\\) is continuous on the closed bounded interval \\([a,b]\\), then there is a number \\(K\\) such that \\(|f(x)|\\le K\\) for each \\(x\\) in \\([a,b]\\).\nMax/Min: If \\(f\\) is continuous on the closed bounded interval \\([a,b]\\), then \\(f\\) has a maximum and a minimum on \\([a,b]\\). They may be located at the end points.\n\nExercise\nLet \\(f(x) = \\frac{x^2 + 2x}{x}.\\)\n\nGraph the function. Is it defined everywhere?\nWhat is the functions limit at \\(x \\rightarrow 0\\)?"
  },
  {
    "objectID": "04_calculus.html",
    "href": "04_calculus.html",
    "title": "4  Calculus",
    "section": "",
    "text": "Calculus is a fundamental part of any type of statistics exercise. Although you may not be taking derivatives and integral in your daily work as an analyst, calculus undergirds many concepts we use: maximization, expectation, and cumulative probability."
  },
  {
    "objectID": "04_calculus.html#example-the-mean-is-a-type-of-integral",
    "href": "04_calculus.html#example-the-mean-is-a-type-of-integral",
    "title": "4  Calculus",
    "section": "Example: The Mean is a Type of Integral",
    "text": "Example: The Mean is a Type of Integral\nThe average of a quantity is a type of weighted mean, where the potential values are weighted by their likelihood, loosely speaking. The integral is actually a general way to describe this weighted average when there are conceptually an infinite number of potential values.\nIf \\(X\\) is a continuous random variable, its expected value \\(E(X)\\) – the center of mass – is given by\n\\[E(X) = \\int^{\\infty}_{-\\infty}x f(x) dx\\]\nwhere \\(f(x)\\) is the probability density function of \\(X\\).\nThis is a continuous version of the case where \\(X\\) is discrete, in which case\n\\[E(X) = \\sum^\\infty_{j=1} x_j P(X = x_j)\\]\neven more concretely, if the potential values of \\(X\\) are finite, then we can write out the expected value as a weighted mean, where the weights is the probability that the value occurs.\n\\[E(X) = \\large \\sum_{x} \\quad\\left( \\underbrace{x}_{\\text{value}}\\cdot \\underbrace{P(X = x)}_{\\text{weight, or PMF}}\\right)\\]"
  },
  {
    "objectID": "04_calculus.html#sec-derivintro",
    "href": "04_calculus.html#sec-derivintro",
    "title": "4  Calculus",
    "section": "4.1 Derivatives",
    "text": "4.1 Derivatives\nThe derivative of \\(f\\) at \\(x\\) is its rate of change at \\(x\\): how much \\(f(x)\\) changes with a change in \\(x\\). The rate of change is a fraction — rise over run — but because not all lines are straight and the rise over run formula will give us different values depending on the range we examine, we need to take a limit (Section -Chapter 3).\n\nDefinition 4.1 (Derivative) Let \\(f\\) be a function whose domain includes an open interval containing the point \\(x\\). The derivative of \\(f\\) at \\(x\\) is given by\n\\[\\frac{d}{dx}f(x) =\\lim\\limits_{h\\to 0} \\frac{f(x+h)-f(x)}{(x+h)-x} = \\lim\\limits_{h\\to 0} \\frac{f(x+h)-f(x)}{h}\\]\nThere are a two main ways to denote a derivate:\n\nLeibniz Notation: \\(\\frac{d}{dx}(f(x))\\)\nPrime or Lagrange Notation: \\(f'(x)\\)\n\n\nIf \\(f(x)\\) is a straight line, the derivative is the slope. For a curve, the slope changes by the values of \\(x\\), so the derivative is the slope of the line tangent to the curve at \\(x\\). See, For example, Figure -Figure 4.1\n\n\n\n\n\nFigure 4.1: The Derivative as a Slope\n\n\n\n\nIf \\(f'(x)\\) exists at a point \\(x_0\\), then \\(f\\) is said to be differentiable at \\(x_0\\). That also implies that \\(f(x)\\) is continuous at \\(x_0\\).\n\nProperties of derivatives\nSuppose that \\(f\\) and \\(g\\) are differentiable at \\(x\\) and that \\(\\alpha\\) is a constant. Then the functions \\(f\\pm g\\), \\(\\alpha f\\), \\(f g\\), and \\(f/g\\) (provided \\(g(x)\\ne 0\\)) are also differentiable at \\(x\\). Additionally,\nConstant rule: \\[\\left[k f(x)\\right]' = k f'(x)\\]\nSum rule: \\[\\left[f(x)\\pm g(x)\\right]' = f'(x)\\pm g'(x)\\]\nWith a bit more algebra, we can apply the definition of derivatives to get a formula for of the derivative of a product and a derivative of a quotient.\nProduct rule: \\[\\left[f(x)g(x)\\right]^\\prime = f^\\prime(x)g(x)+f(x)g^\\prime(x)\\]\nQuotient rule: \\[\\left[f(x)/g(x)\\right]^\\prime = \\frac{f^\\prime(x)g(x) - f(x)g^\\prime(x)}{[g(x)]^2}, ~g(x)\\neq 0\\]\nFinally, one way to think of the power of derivatives is that it takes a function a notch down in complexity. The power rule applies to any higher-order function:\nPower rule: \\[\\left[x^k\\right]^\\prime = k x^{k-1}\\]\nFor any real number \\(k\\) (that is, both whole numbers and fractions). The power rule is proved by induction, a neat method of proof used in many fundamental applications to prove that a general statement holds for every possible case, even if there are countably infinite cases. We’ll show a simple case where \\(k\\) is an integer here.\n\nProposition 4.1 (Power Rule) \\[\\left[x^k\\right]^\\prime = k x^{k-1}\\] for any integer \\(k\\).\n\n\nProof. First, consider the first case (the base case) of \\(k = 1\\). We can show by the definition of derivatives (setting \\(f(x) = x^1 = 1\\)) that\n\\[[x^1]^\\prime = \\lim_{h \\rightarrow 0}\\frac{(x + h) - x}{(x + h) - x}= 1.\\]\nBecause \\(1\\) is also expressed as \\(1 x^{1- 1}\\), the statement we want to prove holds for the case \\(k =1\\).\nNow, that the statement holds for some integer \\(m\\). That is, assume \\[\\left[x^m\\right]^\\prime = m x^{m-1}\\]\nThen, for the case \\(m + 1\\), using the product rule above, we can simplify\n\\[\\begin{align*}\n\\left[x^{m + 1}\\right]^\\prime &= [x^{m}\\cdot x]^\\prime\\\\\n&= (x^m)^\\prime\\cdot x + (x^m)\\cdot (x)^\\prime\\\\\n&= m x^{m - 1}\\cdot x + x^m ~~\\because \\text{by previous assumption}\\\\\n&= mx^m + x^m\\\\\n&= (m + 1)x^m\\\\\n&= (m + 1)x^{(m + 1) - 1}\n\\end{align*}\\]\nTherefore, the rule holds for the case \\(k = m + 1\\) once we have assumed it holds for \\(k = m\\). Combined with the first case, this completes proof by induction – we have now proved that the statement holds for all integers \\(k = 1, 2, 3, \\cdots\\).\nTo show that it holds for real fractions as well, we can prove expressing that exponent by a fraction of two integers.\n\nThese “rules” become apparent by applying the definition of the derivative above to each of the things to be “derived”, but these come up so frequently that it is best to repeat until it is muscle memory.\n\nExercise 4.1 (Derivatives) For each of the following functions, find the first-order derivative \\(f^\\prime(x)\\).\n\n\\(f(x)=c\\)\n\\(f(x)=x\\)\n\\(f(x)=x^2\\)\n\\(f(x)=x^3\\)\n\\(f(x)=\\frac{1}{x^2}\\)\n\\(f(x)=(x^3)(2x^4)\\)\n\\(f(x) = x^4 - x^3 + x^2 - x + 1\\)\n\\(f(x) = (x^2 + 1)(x^3 - 1)\\)\n\\(f(x) = 3x^2 + 2x^{1/3}\\)\n\\(f(x)=\\frac{x^2+1}{x^2-1}\\)"
  },
  {
    "objectID": "04_calculus.html#derivpoly",
    "href": "04_calculus.html#derivpoly",
    "title": "4  Calculus",
    "section": "4.2 Higher-Order Derivatives (Derivatives of Derivatives of Derivatives)",
    "text": "4.2 Higher-Order Derivatives (Derivatives of Derivatives of Derivatives)\nThe first derivative is applying the definition of derivatives on the function, and it can be expressed as\n\\[f'(x),  ~~ y',  ~~ \\frac{d}{dx}f(x), ~~ \\frac{dy}{dx}\\]\nWe can keep applying the differentiation process to functions that are themselves derivatives. The derivative of \\(f'(x)\\) with respect to \\(x\\), would then be \\[f''(x)=\\lim\\limits_{h\\to 0}\\frac{f'(x+h)-f'(x)}{h}\\] and we can therefore call it the Second derivative:\n\\[f''(x), ~~ y'', ~~ \\frac{d^2}{dx^2}f(x), ~~ \\frac{d^2y}{dx^2}\\]\nSimilarly, the derivative of \\(f''(x)\\) would be called the third derivative and is denoted \\(f'''(x)\\). And by extension, the nth derivative is expressed as \\(\\frac{d^n}{dx^n}f(x)\\), \\(\\frac{d^ny}{dx^n}\\).\n\nExample 4.1 (Succession of derivatives) \\[\\begin{align*}\nf(x) &=x^3\\\\\nf^{\\prime}(x) &=3x^2\\\\\nf^{\\prime\\prime}(x) &=6x \\\\\nf^{\\prime\\prime\\prime}(x) &=6\\\\\nf^{\\prime\\prime\\prime\\prime}(x) &=0\\\\\n\\end{align*}\\]\n\nEarlier, in Section -Section 4.1, we said that if a function differentiable at a given point, then it must be continuous. Further, if \\(f'(x)\\) is itself continuous, then \\(f(x)\\) is called continuously differentiable. All of this matters because many of our findings about optimization (Section @ref(optim)) rely on differentiation, and so we want our function to be differentiable in as many layers. A function that is continuously differentiable infinitly is called “smooth”. Some examples: \\(f(x) = x^2\\), \\(f(x) = e^x\\)."
  },
  {
    "objectID": "04_calculus.html#composite-functions-and-the-chain-rule",
    "href": "04_calculus.html#composite-functions-and-the-chain-rule",
    "title": "4  Calculus",
    "section": "4.3 Composite Functions and the Chain Rule",
    "text": "4.3 Composite Functions and the Chain Rule\nAs useful as the above rules are, many functions you’ll see won’t fit neatly in each case immediately. Instead, they will be functions of functions. For example, the difference between \\(x^2 + 1^2\\) and \\((x^2 + 1)^2\\) may look trivial, but the sum rule can be easily applied to the former, while it’s actually not obvious what do with the latter.\nComposite functions are formed by substituting one function into another and are denoted by \\[(f\\circ g)(x)=f[g(x)].\\] To form \\(f[g(x)]\\), the range of \\(g\\) must be contained (at least in part) within the domain of \\(f\\). The domain of \\(f\\circ g\\) consists of all the points in the domain of \\(g\\) for which \\(g(x)\\) is in the domain of \\(f\\).\n\nExample 4.2 (Composite functions) Let \\(f(x)=\\log x\\) for \\(0<x<\\infty\\) and \\(g(x)=x^2\\) for \\(-\\infty<x<\\infty\\).\nThen \\[(f\\circ g)(x)=\\log x^2, -\\infty<x<\\infty - \\{0\\}\\]\nAlso \\[(g\\circ f)(x)=[\\log x]^2, 0<x<\\infty\\]\nNotice that \\(f\\circ g\\) and \\(g\\circ f\\) are not the same functions.\n\nWith the notation of composite functions in place, now we can introduce a helpful additional rule that will deal with a derivative of composite functions as a chain of concentric derivatives.\nChain Rule:\nLet \\(y=(f\\circ g)(x)= f[g(x)]\\). The derivative of \\(y\\) with respect to \\(x\\) is \\[\\frac{d}{dx} \\{ f[g(x)] \\} = f'[g(x)] g'(x)\\]\nWe can read this as: “the derivative of the composite function \\(y\\) is the derivative of \\(f\\) evaluated at \\(g(x)\\), times the derivative of \\(g\\).”\nThe chain rule can be thought of as the derivative of the “outside” times the derivative of the “inside”, remembering that the derivative of the outside function is evaluated at the value of the inside function.\n\nThe chain rule can also be written as \\[\\frac{dy}{dx}=\\frac{dy}{dg(x)} \\frac{dg(x)}{dx}\\] This expression does not imply that the \\(dg(x)\\)’s cancel out, as in fractions. They are part of the derivative notation and you can’t separate them out or cancel them.)\n\n\nExample 4.3 (Composite Exponent) Find \\(f^\\prime(x)\\) for \\(f(x) = (3x^2+5x-7)^6\\).\n\nThe direct use of a chain rule is when the exponent of is itself a function, so the power rule could not have applied generaly:\nGeneralized Power Rule:\nIf \\(f(x)=[g(x)]^p\\) for any rational number \\(p\\), \\[f^\\prime(x) =p[g(x)]^{p-1}g^\\prime(x)\\]"
  },
  {
    "objectID": "04_calculus.html#derivatives-of-natural-logs-and-the-exponent",
    "href": "04_calculus.html#derivatives-of-natural-logs-and-the-exponent",
    "title": "4  Calculus",
    "section": "4.4 Derivatives of natural logs and the exponent",
    "text": "4.4 Derivatives of natural logs and the exponent\nNatural logs and exponents (they are inverses of each other; see Section @ref(logexponents)) crop up everywhere in statistics. Their derivative is a special case from the above, but quite elegant.\n\nTheorem 4.1 (Derivative of Exponents/Logs) The functions \\(e^x\\) and the natural logarithm \\(\\log(x)\\) are continuous and differentiable in their domains, and their first derivative is \\[(e^x)^\\prime = e^x\\] \\[\\log(x)^\\prime = \\frac{1}{x}\\]\nAlso, when these are composite functions, it follows by the generalized power rule that\n\\[\\left(e^{g(x)}\\right)^\\prime = e^{g(x)} \\cdot g^\\prime(x)\\] \\[\\left(\\log g(x)\\right)^\\prime = \\frac{g^\\prime(x)}{g(x)}, ~~\\text{if}~~ g(x) > 0\\]\n\n\nDerivatives of natural exponential function (\\(e\\))\nTo repeat the main rule in Theorem @ref(thm:derivexplog), the intuition is that\n\nDerivative of \\(e^x\\) is itself: \\(\\frac{d}{dx}e^x = e^x\\) (See Figure 4.2)\nSame thing if there were a constant in front: \\(\\frac{d}{dx}\\alpha e^x = \\alpha e^x\\)\nSame thing no matter how many derivatives there are in front: \\(\\frac{d^n}{dx^n} \\alpha e^x = \\alpha e^x\\)\nChain Rule: When the exponent is a function of \\(x\\), remember to take derivative of that function and add to product. \\(\\frac{d}{dx}e^{g(x)}= e^{g(x)} g^\\prime(x)\\)\n\n\n\n\n\n\nFigure 4.2: Derivative of the Exponential Function\n\n\n\n\n\nExample 4.4 (Derivatives of exponents) Find the derivative for the following.\n\n\\(f(x)=e^{-3x}\\)\n\\(f(x)=e^{x^2}\\)\n\\(f(x)=(x-1)e^x\\)\n\n\n\n\nDerivatives of logarithms\nThe natural log is the mirror image of the natural exponent and has mirroring properties, again, to repeat the theorem,\n\nlog prime x is one over x: \\(\\frac{d}{dx} \\log x = \\frac{1}{x}\\) (Figure 4.3)\nExponents become multiplicative constants: \\(\\frac{d}{dx} \\log x^k = \\frac{d}{dx} k \\log x = \\frac{k}{x}\\)\nChain rule again: \\(\\frac{d}{dx} \\log u(x) = \\frac{u'(x)}{u(x)}\\quad\\)\nFor any positive base \\(b\\), \\(\\frac{d}{dx} b^x = (\\log b)\\left(b^x\\right)\\).\n\n\n\n\n\n\nFigure 4.3: Derivative of the Natural Log\n\n\n\n\n\nExample 4.5 (Derivatives of logs) Find \\(dy/dx\\) for the following.\n\n\\(f(x)=\\log(x^2+9)\\)\n\\(f(x)=\\log(\\log x)\\)\n\\(f(x)=(\\log x)^2\\)\n\\(f(x)=\\log e^x\\)\n\n\n\n\nOutline of Proof\nWe actually show the derivative of the log first, and then the derivative of the exponential naturally follows.\nThe general derivative of the log at any base \\(a\\) is solvable by the definition of derivatives.\n\\[\\begin{align*}\n(\\log_a x)^\\prime = \\lim\\limits_{h\\to 0} \\frac{1}{h}\\log_{a}\\left(1 + \\frac{h}{x}\\right)\n\\end{align*}\\]\nRe-express \\(g = \\frac{h}{x}\\) and get \\[\\begin{align*}\n(\\log_a x)^\\prime &= \\frac{1}{x}\\lim_{g\\to 0}\\log_{a} (1 + g)^{\\frac{1}{g}}\\\\\n&= \\frac{1}{x}\\log_a e\n\\end{align*}\\]\nBy definition of \\(e\\). As a special case, when \\(a = e\\), then \\((\\log x)^\\prime = \\frac{1}{x}\\).\nNow let’s think about the inverse, taking the derivative of \\(y = a^x\\).\n\\[\\begin{align*}\ny &= a^x \\\\\n\\Rightarrow \\log y &= x \\log a\\\\\n\\Rightarrow \\frac{y^\\prime}{y} &= \\log a\\\\\n\\Rightarrow  y^\\prime = y \\log a\\\\\n\\end{align*}\\]\nThen in the special case where \\(a = e\\),\n\\[(e^x)^\\prime = (e^x)\\]"
  },
  {
    "objectID": "04_calculus.html#partial-derivatives",
    "href": "04_calculus.html#partial-derivatives",
    "title": "4  Calculus",
    "section": "4.5 Partial Derivatives",
    "text": "4.5 Partial Derivatives\nWhat happens when there’s more than variable that is changing?\n\nIf you can do ordinary derivatives, you can do partial derivatives: just hold all the other input variables constant except for the one you’re differentiating with respect to. (Joe Blitzstein’s Math Notes)\n\nSuppose we have a function \\(f\\) now of two (or more) variables and we want to determine the rate of change relative to one of the variables. To do so, we would find its partial derivative, which is defined similar to the derivative of a function of one variable.\nPartial Derivative: Let \\(f\\) be a function of the variables \\((x_1,\\ldots,x_n)\\). The partial derivative of \\(f\\) with respect to \\(x_i\\) is\n\\[\\frac{\\partial f}{\\partial x_i} (x_1,\\ldots,x_n) = \\lim\\limits_{h\\to 0} \\frac{f(x_1,\\ldots,x_i+h,\\ldots,x_n)-f(x_1,\\ldots,x_i,\\ldots,x_n)}{h}\\]\nOnly the \\(i\\)th variable changes — the others are treated as constants.\nWe can take higher-order partial derivatives, like we did with functions of a single variable, except now the higher-order partials can be with respect to multiple variables.\n\nExample 4.6 (Partial derivatives) Notice that you can take partials with regard to different variables.\nSuppose \\(f(x,y)=x^2+y^2\\). Then\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x}(x,y) &=\\\\\n\\frac{\\partial f}{\\partial y}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x^2}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x \\partial y}(x,y) &=\n\\end{align*}\\]\n\n\nExercise 4.2 (Partial derivatives) Let \\(f(x,y)=x^3 y^4 +e^x -\\log y\\). What are the following partial derivatives?\n\\[\\begin{align*}\n\\frac{\\partial f}{\\partial x}(x,y) &=\\\\\n\\frac{\\partial f}{\\partial y}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x^2}(x,y) &=\\\\\n\\frac{\\partial^2 f}{\\partial x \\partial y}(x,y) &=\n\\end{align*}\\]"
  },
  {
    "objectID": "04_calculus.html#taylorapprox",
    "href": "04_calculus.html#taylorapprox",
    "title": "4  Calculus",
    "section": "4.6 Taylor Series Approximation",
    "text": "4.6 Taylor Series Approximation\nA common form of approximation used in statistics involves derivatives. A Taylor series is a way to represent common functions as infinite series (a sum of infinite elements) of the function’s derivatives at some point \\(a\\).\nFor example, Taylor series are very helpful in representing nonlinear (read: difficult) functions as linear (read: manageable) functions. One can thus approximate functions by using lower-order, finite series known as Taylor polynomials. If \\(a=0\\), the series is called a Maclaurin series.\nSpecifically, a Taylor series of a real or complex function \\(f(x)\\) that is infinitely differentiable in the neighborhood of point \\(a\\) is:\n\\[\\begin{align*}\n    f(x) &= f(a) + \\frac{f'(a)}{1!} (x-a) +  \\frac{f''(a)}{2!} (x-a)^2 + \\cdots\\\\\n     &= \\sum_{n=0}^\\infty \\frac{f^{(n)} (a)}{n!} (x-a)^n\n\\end{align*}\\]\nTaylor Approximation: We can often approximate the curvature of a function \\(f(x)\\) at point \\(a\\) using a 2nd order Taylor polynomial around point \\(a\\):\n\\[f(x) = f(a) + \\frac{f'(a)}{1!} (x-a) +  \\frac{f''(a)}{2!} (x-a)^2\n+ R_2\\]\n\\(R_2\\) is the remainder (R for remainder, 2 for the fact that we took two derivatives) and often treated as negligible, giving us:\n\\[f(x) \\approx f(a) + f'(a)(x-a) +  \\dfrac{f''(a)}{2} (x-a)^2\\]\nThe more derivatives that are added, the smaller the remainder \\(R\\) and the more accurate the approximation. Proofs involving limits guarantee that the remainder converges to 0 as the order of derivation increases."
  },
  {
    "objectID": "04_calculus.html#the-indefinite-integration",
    "href": "04_calculus.html#the-indefinite-integration",
    "title": "4  Calculus",
    "section": "4.7 The Indefinite Integration",
    "text": "4.7 The Indefinite Integration\nSo far, we’ve been interested in finding the derivative \\(f=F'\\) of a function \\(F\\). However, sometimes we’re interested in exactly the reverse: finding the function \\(F\\) for which \\(f\\) is its derivative. We refer to \\(F\\) as the antiderivative of \\(f\\).\n\nDefinition 4.2 (Antiderivative) The antiverivative of a function \\(f(x)\\) is a differentiable function \\(F\\) whose derivative is \\(f\\).\n\\[F^\\prime = f.\\]\n\nAnother way to describe is through the inverse formula. Let \\(DF\\) be the derivative of \\(F\\). And let \\(DF(x)\\) be the derivative of \\(F\\) evaluated at \\(x\\). Then the antiderivative is denoted by \\(D^{-1}\\) (i.e., the inverse derivative). If \\(DF=f\\), then \\(F=D^{-1}f\\).\nThis definition bolsters the main takeaway about integrals and derivatives: They are inverses of each other.\n\nExercise 4.3 (Antiderivative) Find the antiderivative of the following:\n\n\\(f(x) = \\frac{1}{x^2}\\)\n\\(f(x) = 3e^{3x}\\)\n\n\nWe know from derivatives how to manipulate \\(F\\) to get \\(f\\). But how do you express the procedure to manipulate \\(f\\) to get \\(F\\)? For that, we need a new symbol, which we will call indefinite integration.\n:::{#def-indefint}"
  },
  {
    "objectID": "04_calculus.html#indefinite-integral",
    "href": "04_calculus.html#indefinite-integral",
    "title": "4  Calculus",
    "section": "4.8 Indefinite Integral",
    "text": "4.8 Indefinite Integral\nThe indefinite integral of \\(f(x)\\) is written\n\\[\\int f(x) dx \\]\nand is equal to the antiderivative of \\(f\\).\n\nExample 4.7 (Graphing) Draw the function \\(f(x)\\) and its indefinite integral, \\(\\int\\limits f(x) dx\\)\n\\[f(x) = (x^2-4)\\]\n\n\nSolution. The Indefinite Integral of the function \\(f(x) = (x^2-4)\\) can, for example, be \\(F(x) = \\frac{1}{3}x^3 - 4x.\\) But it can also be \\(F(x) = \\frac{1}{3}x^3 - 4x + 1\\), because the constant 1 disappears when taking the derivative.\n\nSome of these functions are plotted in the bottom panel of Figure 4.4 as dotted lines.\n\n\n\n\n\nFigure 4.4: The Many Indefinite Integrals of a Function\n\n\n\n\nNotice from these examples that while there is only a single derivative for any function, there are multiple antiderivatives: one for any arbitrary constant \\(c\\). \\(c\\) just shifts the curve up or down on the \\(y\\)-axis. If more information is present about the antiderivative — e.g., that it passes through a particular point — then we can solve for a specific value of \\(c\\).\n\nCommon Rules of Integration\nSome common rules of integrals follow by virtue of being the inverse of a derivative.\n\nConstants are allowed to slip out: \\(\\int a f(x)dx = a\\int f(x)dx\\)\nIntegration of the sum is sum of integrations: \\(\\int [f(x)+g(x)]dx=\\int f(x)dx + \\int g(x)dx\\)\nReverse Power-rule: \\(\\int x^n dx = \\frac{1}{n+1} x^{n+1} + c\\)\nExponents are still exponents: \\(\\int e^x dx = e^x +c\\)\nRecall the derivative of \\(\\log(x)\\) is one over \\(x\\), and so: \\(\\int \\frac{1}{x} dx = \\log x + c\\)\nReverse chain-rule: \\(\\int e^{f(x)}f^\\prime(x)dx = e^{f(x)}+c\\)\nMore generally: \\(\\int [f(x)]^n f'(x)dx = \\frac{1}{n+1}[f(x)]^{n+1}+c\\)\nRemember the derivative of a log of a function: \\(\\int \\frac{f^\\prime(x)}{f(x)}dx=\\log f(x) + c\\)\n\n\nExample 4.8 (Common Integration) Simplify the following indefinite integrals:\n\n(3x^2 dx)\n((2x+1)dx)\n(e^x e{ex} dx)"
  },
  {
    "objectID": "04_calculus.html#the-definite-integral-the-area-under-the-curve",
    "href": "04_calculus.html#the-definite-integral-the-area-under-the-curve",
    "title": "4  Calculus",
    "section": "4.9 The Definite Integral: The Area under the Curve",
    "text": "4.9 The Definite Integral: The Area under the Curve\nIf there is a indefinite integral, there must be a definite integral. Indeed there is, but the notion of definite integrals comes from a different objective: finding the are a under a function. We will find, perhaps remarkably, that the formula we find to get the sum turns out to be expressible by the anti-derivative.\nSuppose we want to determine the area \\(A(R)\\) of a region \\(R\\) defined by a curve \\(f(x)\\) and some interval \\(a\\le x \\le b\\).\n\n\n\n\n\nFigure 4.5: The Riemann Integral as a Sum of Evaluations\n\n\n\n\nOne way to calculate the area would be to divide the interval \\(a\\le x\\le b\\) into \\(n\\) subintervals of length \\(\\Delta x\\) and then approximate the region with a series of rectangles, where the base of each rectangle is \\(\\Delta x\\) and the height is \\(f(x)\\) at the midpoint of that interval. \\(A(R)\\) would then be approximated by the area of the union of the rectangles, which is given by \\[S(f,\\Delta x)=\\sum\\limits_{i=1}^n f(x_i)\\Delta x\\] and is called a Riemann sum.\nAs we decrease the size of the subintervals \\(\\Delta x\\), making the rectangles “thinner,” we would expect our approximation of the area of the region to become closer to the true area. This allows us to express the area as a limit of a series: \\[A(R)=\\lim\\limits_{\\Delta x\\to 0}\\sum\\limits_{i=1}^n f(x_i)\\Delta x\\]\nFigure 4.5 shows that illustration. The curve depicted is \\(f(x) = -15(x - 5) + (x - 5)^3 + 50.\\) We want approximate the area under the curve between the \\(x\\) values of 0 and 10. We can do this in blocks of arbitrary width, where the sum of rectangles (the area of which is width times \\(f(x)\\) evaluated at the midpoint of the bar) shows the Riemann Sum. As the width of the bars \\(\\Delta x\\) becomes smaller, the better the estimate of \\(A(R)\\).\nThis is how we define the “Definite” Integral:\n\nDefinition 4.3 (The Definite Integral (Riemann)) If for a given function \\(f\\) the Riemann sum approaches a limit as \\(\\Delta x \\to 0\\), then that limit is called the Riemann integral of \\(f\\) from \\(a\\) to \\(b\\). We express this with the \\(\\int\\), symbol, and write \\[\\int\\limits_a^b f(x) dx= \\lim\\limits_{\\Delta x\\to 0} \\sum\\limits_{i=1}^n f(x_i)\\Delta x\\]\nThe most straightforward of a definite integral is the definite integral. That is, we read \\[\\int\\limits_a^b f(x) dx\\] as the definite integral of \\(f\\) from \\(a\\) to \\(b\\) and we defined as the area under the “curve” \\(f(x)\\) from point \\(x=a\\) to \\(x=b\\).\n\nThe fundamental theorem of calculus shows us that this sum is, in fact, the antiderivative.\n\nTheorem 4.2 (First Fundamental Theorem of Calculus) Let the function \\(f\\) be bounded on \\([a,b]\\) and continuous on \\((a,b)\\). Then, suggestively, use the symbol \\(F(x)\\) to denote the definite integral from \\(a\\) to \\(x\\): \\[F(x)=\\int\\limits_a^x f(t)dt, \\quad a\\le x\\le b\\]\nThen \\(F(x)\\) has a derivative at each point in \\((a,b)\\) and \\[F^\\prime(x)=f(x), \\quad a<x<b\\] That is, the definite integral function of \\(f\\) is the one of the antiderivatives of some \\(f\\).\n\nThis is again a long way of saying that that differentiation is the inverse of integration. But now, we’ve covered definite integrals.\nThe second theorem gives us a simple way of computing a definite integral as a function of indefinite integrals.\n\nTheorem 4.3 (Second Fundamental Theorem of Calculus) Let the function \\(f\\) be bounded on \\([a,b]\\) and continuous on \\((a,b)\\). Let \\(F\\) be any function that is continuous on \\([a,b]\\) such that \\(F^\\prime(x)=f(x)\\) on \\((a,b)\\). Then \\[\\int\\limits_a^bf(x)dx = F(b)-F(a)\\]\n\nSo the procedure to calculate a simple definite integral \\(\\int\\limits_a^b f(x)dx\\) is then\n\nFind the indefinite integral \\(F(x)\\).\nEvaluate \\(F(b)-F(a)\\).\n\n\nExample 4.9 (Definite Integral of a monomial) Solve \\(\\int\\limits_1^3 3x^2 dx.\\)\nLet \\(f(x) = 3x^2\\).\n\n\nExercise 4.4 (Indefinite integrals) What is the value of \\(\\int\\limits_{-2}^2 e^x e^{e^x} dx\\)?\n\n\nCommon Rules for Definite Integrals\nThe area-interpretation of the definite integral provides some rules for simplification.\n\nThere is no area below a point: \\[\\int\\limits_a^a f(x)dx=0\\]\nReversing the limits changes the sign of the integral: \\[\\int\\limits_a^b f(x)dx=-\\int\\limits_b^a f(x)dx\\]\nSums can be separated into their own integrals: \\[\\int\\limits_a^b [\\alpha f(x)+\\beta g(x)]dx = \\alpha \\int\\limits_a^b f(x)dx + \\beta \\int\\limits_a^b g(x)dx\\]\nAreas can be combined as long as limits are linked: \\[\\int\\limits_a^b f(x) dx +\\int\\limits_b^c f(x)dx = \\int\\limits_a^c f(x)dx\\]\n\n\nExercise 4.5 (Definite integrals) Simplify the following definite intergrals.\n\n\\(\\int\\limits_1^1 3x^2 dx =\\)\n\\(\\int\\limits_0^4 (2x+1)dx=\\)\n\\(\\int\\limits_{-2}^0 e^x e^{e^x} dx + \\int\\limits_0^2 e^x e^{e^x} dx =\\)"
  },
  {
    "objectID": "04_calculus.html#integration-by-substitution",
    "href": "04_calculus.html#integration-by-substitution",
    "title": "4  Calculus",
    "section": "4.10 Integration by Substitution",
    "text": "4.10 Integration by Substitution\nFrom the second fundamental theorem of calculus, we now that a quick way to get a definite integral is to first find the indefinite integral, and then just plug in the bounds.\nSometimes the integrand (the thing that we are trying to take an integral of) doesn’t appear integrable using common rules and antiderivatives. A method one might try is integration by substitution, which is related to the Chain Rule.\nSuppose we want to find the indefinite integral \\[\\int g(x)dx\\] but \\(g(x)\\) is complex and none of the formulas we have seen so far seem to apply immediately. The trick is to come up with a new function \\(u(x)\\) such that \\[g(x)=f[u(x)]u'(x).\\]\nWhy does an introduction of yet another function end of simplifying things? Let’s refer to the antiderivative of \\(f\\) as \\(F\\). Then the chain rule tells us that \\[\\frac{d}{dx} F[u(x)]=f[u(x)]u'(x)\\]. So, \\(F[u(x)]\\) is the antiderivative of \\(g\\). We can then write \\[\\int g(x) dx= \\int f[u(x)]u'(x)dx = \\int \\frac{d}{dx} F[u(x)]dx = F[u(x)]+c\\]\nTo summarize, the procedure to determine the indefinite integral \\(\\int g(x)dx\\) by the method of substitution:\n\nIdentify some part of \\(g(x)\\) that might be simplified by substituting in a single variable \\(u\\) (which will then be a function of \\(x\\)).\nDetermine if \\(g(x)dx\\) can be reformulated in terms of \\(u\\) and \\(du\\).\nSolve the indefinite integral.\nSubstitute back in for \\(x\\)\n\nSubstitution can also be used to calculate a definite integral. Using the same procedure as above, \\[\\int\\limits_a^b g(x)dx=\\int\\limits_c^d f(u)du = F(d)-F(c)\\] where \\(c=u(a)\\) and \\(d=u(b)\\).\n\nExample 4.10 Integration by Substitution I\nSolve the indefinite integral \\[\\int x^2 \\sqrt{x+1}dx.\\]\n\nFor the above problem, we could have also used the substitution \\(u=\\sqrt{x+1}\\). Then \\(x=u^2-1\\) and \\(dx=2u du\\). Substituting these in, we get \\[\\int x^2\\sqrt{x+1}dx=\\int (u^2-1)^2 u 2u du\\] which when expanded is again a polynomial and gives the same result as above.\nAnother case in which integration by substitution is is useful is with a fraction.\n\nExample 4.11 (Integration by Substitutiton II) Simplify \\[\\int\\limits_0^1 \\frac{5e^{2x}}{(1+e^{2x})^{1/3}}dx.\\]"
  },
  {
    "objectID": "04_calculus.html#integration-by-parts",
    "href": "04_calculus.html#integration-by-parts",
    "title": "4  Calculus",
    "section": "4.11 Integration by Parts",
    "text": "4.11 Integration by Parts\nAnother useful integration technique is integration by parts, which is related to the Product Rule of differentiation. The product rule states that \\[\\frac{d}{dx}(uv)=u\\frac{dv}{dx}+v\\frac{du}{dx}\\] Integrating this and rearranging, we get \\[\\int u\\frac{dv}{dx}dx= u v - \\int v \\frac{du}{dx}dx\\] or \\[\\int u(x) v'(x)dx=u(x)v(x) - \\int v(x)u'(x)dx\\]\nMore easily remembered with the mnemonic “Ultraviolet Voodoo”: \\[\\int u dv = u v - \\int v du\\] where \\(du=u'(x)dx\\) and \\(dv=v'(x)dx\\).\nFor definite integrals, this is simply \\[\\int\\limits_a^b u\\frac{dv}{dx}dx = \\left. u v \\right|_a^b - \\int\\limits_a^b v \\frac{du}{dx}dx\\]\nOur goal here is to find expressions for \\(u\\) and \\(dv\\) that, when substituted into the above equation, yield an expression that’s more easily evaluated.\n\nExample 4.12 (Integration by parts) Simplify the following integrals. These seemingly obscure forms of integrals come up often when integrating distributions.\n\\[\\int x e^{ax} dx\\]\n\n\nSolution. Let \\(u=x\\) and \\(\\frac{dv}{dx} = e^{ax}\\). Then \\(du=dx\\) and \\(v=(1/a)e^{ax}\\). Substituting this into the integration by parts formula, we obtain\n\\[\\begin{eqnarray}\n\\int x e^{ax} dx &=& u v - \\int v du\\nonumber\\\\\n                &=&x\\left( \\frac{1}{a}e^{ax}\\right) -\\int\\frac{1}{a}e^{ax}dx\\nonumber\\\\\n                &=&\\frac{1}{a}xe^{ax}-\\frac{1}{a^2}e^{ax}+c\\nonumber\n\\end{eqnarray}\\]\n\n\n\nExercise 4.6 (Integration by parts) \nIntegrate \\[\\int x^n e^{ax} dx\\]\nIntegrate \\[\\int x^3 e^{-x^2} dx\\]"
  },
  {
    "objectID": "05_optimization.html",
    "href": "05_optimization.html",
    "title": "5  Optimization",
    "section": "",
    "text": "To optimize, we use derivatives and calculus. Optimization is to find the maximum or minimum of a functon, and to find what value of an input gives that extremum. This has obvious uses in engineering. Many tools in the statistical toolkit use optimization. One of the most common ways of estimating a model is through “Maximum Likelihood Estimation”, done via optimizing a function (the likelihood).\nOptimization also comes up in Economics, Formal Theory, and Political Economy all the time. A go-to model of human behavior is that they optimize a certain utility function. Humans are not pure utility maximizers, of course, but nuanced models of optimization – for example, adding constraints and adding uncertainty – will prove to be quite useful."
  },
  {
    "objectID": "05_optimization.html#example-meltzer-richard",
    "href": "05_optimization.html#example-meltzer-richard",
    "title": "5  Optimization",
    "section": "Example: Meltzer-Richard",
    "text": "Example: Meltzer-Richard\nA standard backdrop in comparative political economy, the Meltzer-Richard (1981) model states that redistribution of wealth should be higher in societies where the median income is much smaller than the average income. More to the point, typically income distributions where the median is very different from the average is one of high inequality. In other words, the Meltzer-Richard model says that highly unequal economies will have more re-distribution of wealth. Why is that the case? Here is a simplified example that is not the exact model by Meltzer and Richard1, but adapted from Persson and Tabellini2\nWe will set the following things about our model human and model democracy.\n\nIndividuals are indexed by \\(i\\), and the total population is normalized to unity (“1”) without loss of generality.\n\\(U(\\cdot)\\), u for “utility”, is a function that is concave and increasing, and expresses the utility gained from public goods. This tells us that its first derivative is positive, and its second derivative is negative.\n\\(y_i\\) is the income of person \\(i\\)\n\\(W_i\\), w for “welfare”, is the welfare of person \\(i\\)\n\\(c_i\\), c for “consumption”, is the consumption utility of person \\(i\\)\n\nAlso, the government is democratically elected and sets the following redistribution output:\n\n\\(\\tau\\), t for “tax”, is a flat tax rate between 0 and 1 that is applied to everyone’s income.\n\\(g\\), “g” for “goods”, is the amount of public goods that the government provides.\n\nSuppose an individual’s welfare is given by: \\[W_i = c_i + U(g)\\]\nThe consumption good is the person’s post-tax income.\n\\[c_i = (1 - \\tau) y_i\\]\nIncome varies by person (In the next section we will cover probability, by then we will know that we can express this by saying that \\(y\\) is a random variable with the cumulative distribution function \\(F\\), i.e. \\(y \\sim F\\).). Every distribution has a mean and an median.\n\n\\(E(y)\\) is the average income of the society.\n\\(\\text{med}(y)\\) is the median income of the society.\n\nWhat will happen in this economy? What will the tax rate be set too? How much public goods will be provided?\nWe’ve skipped ahead of some formal theory results of democracy, but hopefully these are conceptually intuitive. First, if a democracy is competitive, there is no slack in the government’s goods, and all tax revenue becomes a public good. So we can go ahead and set the constraint:\n\\[g = \\sum_{i} \\tau y_i P(y_i) = \\tau E(y)\\]\nWe can do this trick because of the “normalizes to unity” setting, but this is a general property of the average.\nNow given this constraint we can re-write an individual’s welfare as\n\\[\\begin{align*}\nW_i &= \\left(1 - \\frac{g}{E(y)}\\right)y_i + U(g)\\\\\n&= \\left(E(y) - g\\right) \\frac{1}{E(y)} y_i + U(g)\\\\\n&= \\left(E(y) - g\\right) \\frac{y_i}{E(y)} + U(g)\\\\\n\\end{align*}\\]\nWhen is the individual’s welfare maximized, as a function of the public good? \\[\\begin{align*}\n\\frac{d}{dg}W_i &=  - \\frac{y_i}{E(y)} + \\frac{d}{dg}U(g)\\\\\n\\end{align*}\\]\n\\(\\frac{d}{dg}W_i = 0\\) when \\(\\frac{d}{dg}U(g) = \\frac{y_i}{E(y)}\\), and so after expressing the derivative as \\(U_g = \\frac{d}{dg}U(g)\\) for simplicity,\n\\[g_i^\\star = {U_g}^{-1}\\left(\\frac{y_i}{E(y)}\\right)\\]\nNow recall that because we assumed concavity, \\(U_g\\) is a negative sloping function whose value is positive. It can be shown that the inverse of such a function is also decreasing. Thus an individual’s preferred level of government is determined by a single continuum, the person’s income divided by the average income, and the function is decreasing in \\(y_i\\). This is consistent with our intuition that richer people prefer less redistribution.\nThat was the amount for any given person. The government has to set one value of \\(g\\), however. So what will that be? Now we will use another result, the median voter theorem. This says that under certain general electoral conditions (single-peaked preferences, two parties, majority rule), the policy winner will be that preferred by the median person in the population. Because the only thing that determines a person’s preferred level of government is \\(y_i / E(y)\\), we can presume that the median voter, whose income is \\(\\text{med}(y)\\) will prevail in their preferred choice of government. Therefore, we wil see\n\\[g^\\star = {U_g}^{-1}\\left(\\frac{\\text{med}(y)}{E(y)}\\right)\\]\nWhat does this say about the level of redistribution we observe in an economy? The higher the average income is than the median income, which often (but not always) means more inequality, there should be more redistribution."
  },
  {
    "objectID": "05_optimization.html#maxima-and-minima",
    "href": "05_optimization.html#maxima-and-minima",
    "title": "5  Optimization",
    "section": "5.1 Maxima and Minima",
    "text": "5.1 Maxima and Minima\nThe first derivative, \\(f'(x)\\), quantifies the slope of a function. Therefore, it can be used to check whether the function \\(f(x)\\) at the point \\(x\\) is increasing or decreasing at \\(x\\).\n\nIncreasing: \\(f'(x)>0\\)\nDecreasing: \\(f'(x)<0\\)\nNeither increasing nor decreasing: \\(f'(x)=0\\) i.e. a maximum, minimum, or saddle point\n\nSo for example, \\(f(x) = x^2 + 2\\) and \\(f^\\prime(x) = 2x\\)\n\n\n\n\n\nMaxima and Minima\n\n\n\n\n\nExercise 5.1 (Plotting a maximum and minimum) Plot \\(f(x)=x^3+ x^2 + 2\\), plot its derivative, and identifiy where the derivative is zero. Is there a maximum or minimum?\n\n\n\n\nThe second derivative \\(f''(x)\\) identifies whether the function \\(f(x)\\) at the point \\(x\\) is\n\nConcave down: \\(f''(x)<0\\)\nConcave up (convex): \\(f''(x)>0\\)\n\nMaximum (Minimum): \\(x_0\\) is a local maximum (minimum) if \\(f(x_0)>f(x)\\) (\\(f(x_0)<f(x))\\) for all \\(x\\) within some open interval containing \\(x_0\\). \\(x_0\\) is a global maximum (minimum) if \\(f(x_0)>f(x)\\) (\\(f(x_0)<f(x))\\) for all \\(x\\) in the domain of \\(f\\).\nGiven the function \\(f\\) defined over domain \\(D\\), all of the following are defined as critical points:\n\nAny interior point of \\(D\\) where \\(f'(x)=0\\).\nAny interior point of \\(D\\) where \\(f'(x)\\) does not exist.\nAny endpoint that is in \\(D\\).\n\nThe maxima and minima will be a subset of the critical points.\nSecond Derivative Test of Maxima/Minima: We can use the second derivative to tell us whether a point is a maximum or minimum of \\(f(x)\\).\n\nLocal Maximum: \\(f'(x)=0\\) and \\(f''(x)<0\\)\nLocal Minimum: \\(f'(x)=0\\) and \\(f''(x)>0\\)\nNeed more info: \\(f'(x)=0\\) and \\(f''(x)=0\\)\n\nGlobal Maxima and Minima Sometimes no global max or min exists — e.g., \\(f(x)\\) not bounded above or below. However, there are three situations where we can fairly easily identify global max or min.\n\nFunctions with only one critical point. If \\(x_0\\) is a local max or min of \\(f\\) and it is the only critical point, then it is the global max or min.\nGlobally concave up or concave down functions. If \\(f''(x)\\) is never zero, then there is at most one critical point. That critical point is a global maximum if \\(f''<0\\) and a global minimum if \\(f''>0\\).\nFunctions over closed and bounded intervals must have both a global maximum and a global minimum.\n\n\nExample 5.1 (Maxima and Minima by drawing) Find any critical points and identify whether they are a max, min, or saddle point:\n\n\\(f(x)=x^2+2\\)\n\\(f(x)=x^3+2\\)\n\\(f(x)=|x^2-1|\\), \\(x\\in [-2,2]\\)"
  },
  {
    "objectID": "05_optimization.html#concavity-of-a-function",
    "href": "05_optimization.html#concavity-of-a-function",
    "title": "5  Optimization",
    "section": "5.2 Concavity of a Function",
    "text": "5.2 Concavity of a Function\nConcavity helps identify the curvature of a function, \\(f(x)\\), in 2 dimensional space.\n\nDefinition 5.1 (Concave Function) A function \\(f\\) is strictly concave over the set S \\(\\forall x_1,x_2 \\in S\\) and \\(\\forall a \\in (0,1)\\), \\[f(ax_1 + (1-a)x_2) > af(x_1) + (1-a)f(x_2)\\] line connecting two points on a concave function will lie the function.\n\n\n\n\n\n\n\nDefinition 5.2 (Convex Function) Convex: A function f is strictly convex over the set S \\(\\forall x_1,x_2 \\in S\\) and \\(\\forall a \\in (0,1)\\), \\[f(ax_1 + (1-a)x_2) < af(x_1) + (1-a)f(x_2)\\]\nAny line connecting two points on a convex function will lie above the function.\n\nSometimes, concavity and convexity are strict of a requirement. For most purposes of getting solutions, what we call quasi-concavity is enough.\n\nDefinition 5.3 (Quasiconcave Function) A function f is quasiconcave over the set S if \\(\\forall x_1,x_2 \\in S\\) and \\(\\forall a \\in (0,1)\\), \\[f(ax_1 + (1-a)x_2) \\ge \\min(f(x_1),f(x_2))\\]\nNo matter what two points you select, the valued point will always be an end point.\n\n\nDefinition 5.4 (Quasiconvex Function) A function f is quasiconvex over the set \\(S\\) if \\(\\forall x_1,x_2 \\in S\\) and \\(\\forall a \\in (0,1)\\), \\[f(ax_1 + (1-a)x_2) \\le \\max(f(x_1),f(x_2))\\] No matter what two points you select, the valued point will always be an end point.\n\nSecond Derivative Test of Concavity: The second derivative can be used to understand concavity.\nIf \\[\\begin{array}{lll}\nf''(x) < 0 & \\Rightarrow & \\text{Concave}\\\\\nf''(x) > 0 & \\Rightarrow & \\text{Convex}\n\\end{array}\\]\n\nQuadratic Forms\nQuadratic forms is shorthand for a way to summarize a function. This is important for finding concavity because\n\nApproximates local curvature around a point — e.g., used to identify max vs min vs saddle point.\nThey are simple to express even in \\(n\\) dimensions:\nHave a matrix representation.\n\nQuadratic Form: A polynomial where each term is a monomial of degree 2 in any number of variables:\n\\[\\begin{align*}\n\\text{One variable: }& Q(x_1) = a_{11}x_1^2\\\\\n\\text{Two variables: }& Q(x_1,x_2) = a_{11}x_1^2 + a_{12}x_1x_2 + a_{22}x_2^2\\\\\n\\text{N variables: }& Q(x_1,\\cdots,x_n)=\\sum\\limits_{i\\le j} a_{ij}x_i x_j\n\\end{align*}\\]\nwhich can be written in matrix terms:\nOne variable\n\\[Q(\\mathbf{x}) = x_1^\\top a_{11} x_1\\]\nN variables: \\[\\begin{align*}\nQ(\\mathbf{x}) &=\\begin{pmatrix} x_1 & x_2 & \\cdots & x_n \\end{pmatrix}\\begin{pmatrix}\na_{11}&\\frac{1}{2}a_{12}&\\cdots&\\frac{1}{2}a_{1n}\\\\\n\\frac{1}{2}a_{12}&a_{22}&\\cdots&\\frac{1}{2}a_{2n}\\\\\n\\vdots&\\vdots&\\ddots&\\vdots\\\\\n\\frac{1}{2}a_{1n}&\\frac{1}{2}a_{2n}&\\cdots&a_{nn}\n\\end{pmatrix}\n\\begin{pmatrix} x_1\\\\x_2\\\\\\vdots\\\\x_n\\end{pmatrix}\\\\\n&= \\mathbf{x}^\\top\\mathbf{Ax}\n\\end{align*}\\]\nFor example, the Quadratic on \\(\\mathbf{R}^2\\): \\[\\begin{align*}\n  Q(x_1,x_2)&=\\begin{pmatrix} x_1& x_2 \\end{pmatrix} \\begin{pmatrix} a_{11}&\\frac{1}{2} a_{12}\\\\\n  \\frac{1}{2}a_{12}&a_{22}\\end{pmatrix} \\begin{pmatrix} x_1\\\\x_2 \\end{pmatrix} \\\\\n  &= a_{11}x_1^2 + a_{12}x_1x_2 + a_{22}x_2^2\n\\end{align*}\\]\n\n\nDefiniteness of Quadratic Forms\nWhen the function \\(f(\\mathbf{x})\\) has more than two inputs, determining whether it has a maxima and minima (remember, functions may have many inputs but they have only one output) is a bit more tedious. Definiteness helps identify the curvature of a function, \\(Q(\\textbf{x})\\), in n dimensional space.\nDefiniteness: By definition, a quadratic form always takes on the value of zero when \\(x = 0\\), \\(Q(\\textbf{x})=0\\) at \\(\\textbf{x}=0\\). The definiteness of the matrix \\(\\textbf{A}\\) is determined by whether the quadratic form \\(Q(\\textbf{x})=\\textbf{x}^\\top\\textbf{A}\\textbf{x}\\) is greater than zero, less than zero, or sometimes both over all \\(\\mathbf{x}\\ne 0\\)."
  },
  {
    "objectID": "05_optimization.html#foc-and-soc",
    "href": "05_optimization.html#foc-and-soc",
    "title": "5  Optimization",
    "section": "5.3 FOC and SOC",
    "text": "5.3 FOC and SOC\nWe can see from a graphical representation that if a point is a local maxima or minima, it must meet certain conditions regarding its derivative. These are so commonly used that we refer these to “First Order Conditions” (FOCs) and “Second Order Conditions” (SOCs) in the economic tradition.\n\nFirst Order Conditions\nWhen we examined functions of one variable \\(x\\), we found critical points by taking the first derivative, setting it to zero, and solving for \\(x\\). For functions of \\(n\\) variables, the critical points are found in much the same way, except now we set the partial derivatives equal to zero. Note: We will only consider critical points on the interior of a function’s domain.\nIn a derivative, we only took the derivative with respect to one variable at a time. When we take the derivative separately with respect to all variables in the elements of \\(\\mathbf{x}\\) and then express the result as a vector, we use the term Gradient and Hessian.\n\nDefinition 5.5 (Gradient) Given a function \\(f(\\textbf{x})\\) in \\(n\\) variables, the gradient \\(\\nabla f(\\mathbf{x})\\) (the greek letter nabla ) is a column vector, where the \\(i\\)th element is the partial derivative of \\(f(\\textbf{x})\\) with respect to \\(x_i\\):\n\\[\\nabla f(\\mathbf{x}) = \\begin{pmatrix}\n\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}\\\\ \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}\\\\\n  \\vdots \\\\ \\frac{\\partial f(\\mathbf{x})}{\\partial x_n} \\end{pmatrix}\\]\n\nBefore we know whether a point is a maxima or minima, if it meets the FOC it is a “Critical Point”.\n\nDefinition 5.6 (Critical Point) \\(\\mathbf{x}^*\\) is a critical point if and only if \\(\\nabla f(\\mathbf{x}^*)=0\\). If the partial derivative of f(x) with respect to \\(x^*\\) is 0, then \\(\\mathbf{x}^*\\) is a critical point. To solve for \\(\\mathbf{x}^*\\), find the gradient, set each element equal to 0, and solve the system of equations. \\[\\mathbf{x}^* = \\begin{pmatrix} x_1^*\\\\x_2^*\\\\ \\vdots \\\\ x_n^*\\end{pmatrix}\\]\n\n\nExample 5.2 Example: Given a function \\(f(\\mathbf{x})=(x_1-1)^2+x_2^2+1\\), find the (1) Gradient and (2) Critical point of \\(f(\\mathbf{x})\\).\n\n\nSolution. Gradient\n\\[\\begin{align*}\n\\nabla f(\\mathbf{x}) &= \\begin{pmatrix}\\frac{\\partial f(\\mathbf{x})}{\\partial x_1}\\\\ \\frac{\\partial f(\\mathbf{x})}{\\partial x_2} \\end{pmatrix}\\\\\n&= \\begin{pmatrix} 2(x_1-1)\\\\ 2x_2 \\end{pmatrix}\n\\end{align*}\\]\nCritical Point \\(\\mathbf{x}^* =\\)\n\\[\\begin{align*}\n&\\frac{\\partial f(\\mathbf{x})}{\\partial x_1} = 2(x_1-1) = 0\\\\\n&\\Rightarrow x_1^* = 1\\\\\n&\\frac{\\partial f(\\mathbf{x})}{\\partial x_2} = 2x_2 = 0\\\\\n&\\Rightarrow   x_2^* = 0\\\\\n\\end{align*}\\]\nSo \\[\\mathbf{x}^* = (1,0)\\]\n\n\n\nSecond Order Conditions\nWhen we found a critical point for a function of one variable, we used the second derivative as a indicator of the curvature at the point in order to determine whether the point was a min, max, or saddle (second derivative test of concavity). For functions of \\(n\\) variables, we use second order partial derivatives as an indicator of curvature.\n\nDefinition 5.7 (Hessian) Given a function \\(f(\\mathbf{x})\\) in \\(n\\) variables, the hessian \\(\\mathbf{H(x)}\\) is an \\(n\\times n\\) matrix, where the \\((i,j)\\)th element is the second order partial derivative of \\(f(\\mathbf{x})\\) with respect to \\(x_i\\) and \\(x_j\\):\n\\[\\mathbf{H(x)}=\\begin{pmatrix}\n\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1^2}&\\frac{\\partial^2f(\\mathbf{x})}{\\partial x_1 \\partial x_2}&\n\\cdots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1 \\partial x_n}\\\\\n\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2 \\partial x_1}&\\frac{\\partial^2f(\\mathbf{x})}{\\partial x_2^2}&\n\\cdots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2 \\partial x_n}\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n \\partial x_1}&\\frac{\\partial^2f(\\mathbf{x})}{\\partial x_n \\partial x_2}&\n\\cdots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n^2}\\end{pmatrix}\\]\n\nNote that the hessian will be a symmetric matrix because \\(\\frac{\\partial f(\\mathbf{x})}{\\partial x_1\\partial x_2} = \\frac{\\partial f(\\mathbf{x})}{\\partial x_2\\partial x_1}\\).\nAlso note that given that \\(f(\\mathbf{x})\\) is of quadratic form, each element of the hessian will be a constant.\nThese definitions will be employed when we determine the Second Order Conditions of a function:\nGiven a function \\(f(\\mathbf{x})\\) and a point \\(\\mathbf{x}^*\\) such that \\(\\nabla f(\\mathbf{x}^*)=0\\),\n\nHessian is Positive Definite \\(\\quad \\Longrightarrow \\quad\\) Strict Local Min\nHessian is Positive Semidefinite \\(\\forall \\mathbf{x}\\in B(\\mathbf{x}^*,\\epsilon)\\)} \\(\\quad \\Longrightarrow \\quad\\) Local Min\nHessian is Negative Definite \\(\\quad \\Longrightarrow \\quad\\) Strict Local Max\nHessian is Negative Semidefinite \\(\\forall \\mathbf{x}\\in B(\\mathbf{x}^*,\\epsilon)\\)} \\(\\quad \\Longrightarrow \\quad\\) Local Max\nHessian is Indefinite \\(\\quad \\Longrightarrow \\quad\\) Saddle Point\n\n\nExample 5.3 (Max and min with two dimensions) We found that the only critical point of \\(f(\\mathbf{x})=(x_1-1)^2+x_2^2+1\\) is at \\(\\mathbf{x}^*=(1,0)\\). Is it a min, max, or saddle point?\n\n\nSolution. The Hessian is \\[\\begin{align*}\n\\mathbf{H(x)} &= \\begin{pmatrix} 2&0\\\\0&2 \\end{pmatrix}\n\\end{align*}\\]\nThe Leading principal minors of the Hessian are \\(M_1=2; M_2=4\\). Now we consider Definiteness. Since both leading principal minors are positive, the Hessian is positive definite.\nMaxima, Minima, or Saddle Point? Since the Hessian is positive definite and the gradient equals 0, \\(x^\\star = (1,0)\\) is a strict local minimum.\nNote: Alternate check of definiteness. Is \\(\\mathbf{H(x^*)} \\geq \\leq 0 \\quad \\forall \\quad \\mathbf{x}\\ne 0\\)\n\\[\\begin{align*}\n\\mathbf{x}^\\top H(\\mathbf{x}^*) \\mathbf{x} &= \\begin{pmatrix} x_1 & x_2 \\end{pmatrix}\\\\\n&= \\begin{pmatrix} 2&0\\\\0&2 \\end{pmatrix}\\\\\n\\begin{pmatrix} x_1\\\\x_2\\end{pmatrix} &= 2x_1^2+2x_2^2\n\\end{align*}\\]\nFor any \\(\\mathbf{x}\\ne 0\\), \\(2(x_1^2+x_2^2)>0\\), so the Hessian is positive definite and \\(\\mathbf{x}^*\\) is a strict local minimum.\n\n\n\nDefiniteness and Concavity\nAlthough definiteness helps us to understand the curvature of an n-dimensional function, it does not necessarily tell us whether the function is globally concave or convex.\nWe need to know whether a function is globally concave or convex to determine whether a critical point is a global min or max. We can use the definiteness of the Hessian to determine whether a function is globally concave or convex:\n\nHessian is Positive Semidefinite \\(\\forall \\mathbf{x}\\)} \\(\\quad \\Longrightarrow \\quad\\) Globally Convex\nHessian is Negative Semidefinite \\(\\forall \\mathbf{x}\\)} \\(\\quad \\Longrightarrow \\quad\\) Globally Concave\n\nNotice that the definiteness conditions must be satisfied over the entire domain."
  },
  {
    "objectID": "05_optimization.html#global-maxima-and-minima",
    "href": "05_optimization.html#global-maxima-and-minima",
    "title": "5  Optimization",
    "section": "5.4 Global Maxima and Minima",
    "text": "5.4 Global Maxima and Minima\nGlobal Max/Min Conditions: Given a function \\(f(\\mathbf{x})\\) and a point \\(\\mathbf{x}^*\\) such that \\(\\nabla f(\\mathbf{x}^*)=0\\),\nNote that showing that \\(\\mathbf{H(x^*)}\\) is negative semidefinite is not enough to guarantee \\(\\mathbf{x}^*\\) is a local max. However, showing that \\(\\mathbf{H(x)}\\) is negative semidefinite for all \\(\\mathbf{x}\\) guarantees that \\(x^*\\) is a global max. (The same goes for positive semidefinite and minima.)\\\nExample: Take \\(f_1(x)=x^4\\) and \\(f_2(x)=-x^4\\). Both have \\(x=0\\) as a critical point. Unfortunately, \\(f''_1(0)=0\\) and \\(f''_2(0)=0\\), so we can’t tell whether \\(x=0\\) is a min or max for either. However, \\(f''_1(x)=12x^2\\) and \\(f''_2(x)=-12x^2\\). For all \\(x\\), \\(f''_1(x)\\ge 0\\) and \\(f''_2(x)\\le 0\\) — i.e., \\(f_1(x)\\) is globally convex and \\(f_2(x)\\) is globally concave. So \\(x=0\\) is a global min of \\(f_1(x)\\) and a global max of \\(f_2(x)\\).\n\nExercise 5.2 (Optimization) Given \\(f(\\mathbf{x})=x_1^3-x_2^3+9x_1x_2\\), find any maxima or minima."
  },
  {
    "objectID": "05_optimization.html#constrained-optimization",
    "href": "05_optimization.html#constrained-optimization",
    "title": "5  Optimization",
    "section": "5.5 Constrained Optimization",
    "text": "5.5 Constrained Optimization\nWe have already looked at optimizing a function in one or more dimensions over the whole domain of the function. Often, however, we want to find the maximum or minimum of a function over some restricted part of its domain.\nex: Maximizing utility subject to a budget constraint\n\n\n\nA typical Utility Function with a Budget Constraint\n\n\nTypes of Constraints: For a function \\(f(x_1, \\dots, x_n)\\), there are two types of constraints that can be imposed:\nIn any constrained optimization problem, the constrained maximum will always be less than or equal to the unconstrained maximum. If the constrained maximum is less than the unconstrained maximum, then the constraint is binding. Essentially, this means that you can treat your constraint as an equality constraint rather than an inequality constraint.\nFor example, the budget constraint binds when you spend your entire budget. This generally happens because we believe that utility is strictly increasing in consumption, i.e. you always want more so you spend everything you have.\nAny number of constraints can be placed on an optimization problem. When working with multiple constraints, always make sure that the set of constraints are not pathological; it must be possible for all of the constraints to be satisfied simultaneously.\n \\[\\max_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2)\\] \\[\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2)\\] This tells us to maximize/minimize our function, \\(f(x_1,x_2)\\), with respect to the choice variables, \\(x_1,x_2\\), subject to the constraint.\nExample: \\[\\max_{x_1,x_2} f(x_1, x_2) = -(x_1^2 + 2x_2^2) \\text{ s.t. }x_1 + x_2 = 4\\] It is easy to see that the maximum occurs at \\((x_1, x_2) = (0,0)\\), but that does not satisfy the constraint. How should we proceed?\n\nEquality Constraints\nEquality constraints are the easiest to deal with because we know that the maximum or minimum has to lie on the (intersection of the) constraint(s).\nThe trick is to change the problem from a constrained optimization problem in \\(n\\) variables to an unconstrained optimization problem in \\(n + k\\) variables, adding one variable for each equality constraint. We do this using a lagrangian multiplier.\nLagrangian function: The Lagrangian function allows us to combine the function we want to optimize and the constraint function into a single function. Once we have this single function, we can proceed as if this were an unconstrained optimization problem.\nFor each constraint, we must include a Lagrange multiplier (\\(\\lambda_i\\)) as an additional variable in the analysis. These terms are the link between the constraint and the Lagrangian function.\nGiven a two dimensional set-up: \\[\\max_{x_1,x_2}/\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2) = a\\]\nWe define the Lagrangian function \\(L(x_1,x_2,\\lambda_1)\\) as follows: \\[L(x_1,x_2,\\lambda_1) = f(x_1,x_2) - \\lambda_1 (c(x_1,x_2) - a)\\]\nMore generally, in n dimensions: \\[ L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k) = f(x_1, \\dots, x_n) - \\sum_{i=1}^k\\lambda_i(c_i(x_1,\\dots, x_n) - r_i)\\]\nGetting the sign right: Note that above we subtract the lagrangian term and we subtract the constraint constant from the constraint function. Occasionally, you may see the following alternative form of the Lagrangian, which is equivalent: \\[ L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k) = f(x_1, \\dots, x_n) + \\sum_{i=1}^k\\lambda_i(r_i - c_i(x_1,\\dots, x_n))\\] Here we add the lagrangian term and we subtract the constraining function from the constraint constant.\nUsing the Lagrangian to Find the Critical Points: To find the critical points, we take the partial derivatives of lagrangian function, \\(L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k)\\), with respect to each of its variables (all choice variables \\(\\mathbf{x}\\) and all lagrangian multipliers \\(\\mathbf{\\lambda}\\)). At a critical point, each of these partial derivatives must be equal to zero, so we obtain a system of \\(n + k\\) equations in \\(n + k\\) unknowns:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial x_1} &= \\frac{\\partial f}{\\partial x_1} - \\sum_{i = 1}^k\\lambda_i\\frac{\\partial c_i}{\\partial x_1} = 0\\\\\n\\vdots &= \\vdots \\nonumber \\\\\n\\frac{\\partial L}{\\partial x_n}  &= \\frac{\\partial f}{\\partial x_n} - \\sum_{i = 1}^k\\lambda_i\\frac{\\partial c_i}{\\partial x_n} = 0\\\\\n\\frac{\\partial L}{\\partial \\lambda_1} &= c_1(x_i, \\dots, x_n) - r_1 =  0\\\\\n\\vdots &= \\vdots \\nonumber \\\\\n\\frac{\\partial L}{\\partial \\lambda_k} &= c_k(x_i, \\dots, x_n) - r_k = 0\n\\end{align*}\\]\nWe can then solve this system of equations, because there are \\(n+k\\) equations and \\(n+k\\) unknowns, to calculate the critical point \\((x_1^*,\\dots,x_n^*,\\lambda_1^*,\\dots,\\lambda_k^*)\\).\nSecond-order Conditions and Unconstrained Optimization: There may be more than one critical point, i.e. we need to verify that the critical point we find is a maximum/minimum. Similar to unconstrained optimization, we can do this by checking the second-order conditions.\n\nExample 5.4 (Constrained optimization with two goods and a budget constraint) Find the constrained optimization of \\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. } x_1 + x_2 = 4\\]\n\n\n\nSolution. \nBegin by writing the Lagrangian: \\[L(x_1, x_2, \\lambda) =  -(x_1^2 + 2x_2^2) - \\lambda(x_1 + x_2 - 4)\\]\nTake the partial derivatives and set equal to zero:\n\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial x_1} = -2x_1 - \\lambda \\quad \\quad \\quad &= 0\\\\\n\\frac{\\partial L}{\\partial x_2}  = -4x_2 - \\lambda \\quad \\quad \\quad &= 0\\\\\n\\frac{\\partial L}{\\partial \\lambda} = -(x_1 + x_2 - 4) \\quad & = & 0\\\\\n\\end{align*}\\]\n\nSolve the system of equations: Using the first two partials, we see that \\(\\lambda = -2x_1\\) and \\(\\lambda = -4x_2\\) Set these equal to see that \\(x_1 = 2x_2\\). Using the third partial and the above equality, \\(4 = 2x_2 + x_2\\) from which we get \\[x_2^* = 4/3, x_1^* = 8/3, \\lambda = -16/3\\]\nTherefore, the only critical point is \\(x_1^* = \\frac{8}{3}\\) and \\(x_2^* = \\frac{4}{3}\\)\nThis gives \\(f(\\frac{8}{3}, \\frac{4}{3}) = -\\frac{96}{9}\\), which is less than the unconstrained optimum \\(f(0,0) = 0\\)\n\n\nNotice that when we take the partial derivative of L with respect to the Lagrangian multiplier and set it equal to 0, we return exactly our constraint! This is why signs matter."
  },
  {
    "objectID": "05_optimization.html#inequality-constraints",
    "href": "05_optimization.html#inequality-constraints",
    "title": "5  Optimization",
    "section": "5.6 Inequality Constraints",
    "text": "5.6 Inequality Constraints\nInequality constraints define the boundary of a region over which we seek to optimize the function. This makes inequality constraints more challenging because we do not know if the maximum/minimum lies along one of the constraints (the constraint binds) or in the interior of the region.\nWe must introduce more variables in order to turn the problem into an unconstrained optimization.\nSlack: For each inequality constraint \\(c_i(x_1, \\dots, x_n) \\leq a_i\\), we define a slack variable \\(s_i^2\\) for which the expression \\(c_i(x_1, \\dots, x_n) \\leq a_i - s_i^2\\) would hold with equality. These slack variables capture how close the constraint comes to binding. We use \\(s^2\\) rather than \\(s\\) to ensure that the slack is positive.\nSlack is just a way to transform our constraints.\nGiven a two-dimensional set-up and these edited constraints: \\[\\max_{x_1,x_2}/\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2) \\le a_1\\]\nAdding in Slack: \\[\\max_{x_1,x_2}/\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. } c(x_1,x_2) \\le a_1 - s_1^2\\]\nWe define the Lagrangian function \\(L(x_1,x_2,\\lambda_1,s_1)\\) as follows: \\[L(x_1,x_2,\\lambda_1,s_1) = f(x_1,x_2) - \\lambda_1 ( c(x_1,x_2) + s_1^2 - a_1)\\]\nMore generally, in n dimensions: \\[ L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k, s_1, \\dots, s_k) = f(x_1, \\dots, x_n) - \\sum_{i = 1}^k \\lambda_i(c_i(x_1,\\dots, x_n) + s_i^2 - a_i)\\]\nFinding the Critical Points: To find the critical points, we take the partial derivatives of the lagrangian function, \\(L(x_1,\\dots,x_n,\\lambda_1,\\dots,\\lambda_k,s_1,\\dots,s_k)\\), with respect to each of its variables (all choice variables \\(x\\), all lagrangian multipliers \\(\\lambda\\), and all slack variables \\(s\\)). At a critical point, each of these partial derivatives must be equal to zero, so we obtain a system of \\(n + 2k\\) equations in \\(n + 2k\\) unknowns:\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial x_1} &= \\frac{\\partial f}{\\partial x_1} - \\sum_{i = 1}^k\\lambda_i\\frac{\\partial c_i}{\\partial x_1} = 0\\\\\n\\vdots & =  \\vdots  \\\\\n\\frac{\\partial L}{\\partial x_n}  &= \\frac{\\partial f}{\\partial x_n} - \\sum_{i = 1}^k\\lambda_i\\frac{\\partial c_i}{\\partial x_n} = 0\\\\\n\\frac{\\partial L}{\\partial \\lambda_1} &= c_1(x_i, \\dots, x_n) + s_1^2 - b_1 = 0\\\\\n\\vdots & = \\vdots \\\\\n\\frac{\\partial L}{\\partial \\lambda_k} &= c_k(x_i, \\dots, x_n) + s_k^2 - b_k = 0\\\\\n\\frac{\\partial L}{\\partial s_1} &= 2s_1\\lambda_1 = 0\\\\\n\\vdots =\\vdots \\\\\n\\frac{\\partial L}{\\partial s_k} &= 2s_k\\lambda_k = 0\n\\end{align*}\\]\nComplementary slackness conditions: The last set of first order conditions of the form \\(2s_i\\lambda_i = 0\\) (the partials taken with respect to the slack variables) are known as complementary slackness conditions. These conditions can be satisfied one of three ways:\n\n\\(\\lambda_i = 0\\) and \\(s_i \\neq 0\\): This implies that the slack is positive and thus the constraint does not bind.\n\\(\\lambda_i \\neq 0\\) and \\(s_i = 0\\): This implies that there is no slack in the constraint and the constraint does bind.\n\\(\\lambda_i = 0\\) and \\(s_i = 0\\): In this case, there is no slack but the constraint binds trivially, without changing the optimum.\n\nExample: Find the critical points for the following constrained optimization: \\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. } x_1 + x_2 \\le 4\\]\n\nRewrite with the slack variables: \\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. } x_1 + x_2 \\le 4 - s_1^2\\]\nWrite the Lagrangian: \\[L(x_1,x_2,\\lambda_1,s_1) = -(x_1^2 + 2x_2^2) - \\lambda_1 (x_1 + x_2 + s_1^2 - 4)\\]\nTake the partial derivatives and set equal to 0:\n\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial x_1} = -2x_1 - \\lambda_1  &= 0\\\\\n\\frac{\\partial L}{\\partial x_2}  = -4x_2 - \\lambda_1 &=  0\\\\\n\\frac{\\partial L}{\\partial \\lambda_1} = -(x_1 + x_2 + s_1^2 - 4)&= 0\\\\\n\\frac{\\partial L}{\\partial s_1} = -2s_1\\lambda_1 &= 0\\\\\n\\end{align*}\\]\n\nConsider all ways that the complementary slackness conditions are solved:\n\nThis shows that there are two critical points: \\((0,0)\\) and \\((\\frac{8}{3},\\frac{4}{3})\\).\n\nFind maximum: Looking at the values of \\(f(x_1,x_2)\\) at the critical points, we see that \\(f(x_1,x_2)\\) is maximized at \\(x_1^* = 0\\) and \\(x_2^*=0\\).\n\n\nExercise 5.3 (Constrained optimization) Example: Find the critical points for the following constrained optimization:\n\\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. }\n\\begin{array}{l}\nx_1 + x_2 \\le 4\\\\\nx_1 \\ge 0\\\\\nx_2 \\ge 0\n\\end{array}\\]\n\n\nRewrite with the slack variables: \\[\\phantom{max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2) \\text{ s.t. }\n\\begin{array}{l}\nx_1 + x_2 \\le 4 - s_1^2\\\\\n-x_1 \\le 0 - s_2^2\\\\\n-x_2 \\le 0 - s_3^2\n\\end{array}}\\]\nWrite the Lagrangian: \\[\\phantom{L(x_1, x_2, \\lambda_1, \\lambda_2, \\lambda_3, s_1, s_2, s_3) =  -(x_1^2 + 2x_2^2) - \\lambda_1(x_1 + x_2 + s_1^2  - 4) - \\lambda_2(-x_1 + s_2^2) - \\lambda_3(-x_2 + s_3^2)}\\]\nTake the partial derivatives and set equal to zero:\n\n\n\nConsider all ways that the complementary slackness conditions are solved:\n\n\nFind maximum:"
  },
  {
    "objectID": "05_optimization.html#kuhn-tucker-conditions",
    "href": "05_optimization.html#kuhn-tucker-conditions",
    "title": "5  Optimization",
    "section": "5.7 Kuhn-Tucker Conditions",
    "text": "5.7 Kuhn-Tucker Conditions\nAs you can see, this can be a pain. When dealing explicitly with non-negativity constraints, this process is simplified by using the Kuhn-Tucker method.\nBecause the problem of maximizing a function subject to inequality and non-negativity constraints arises frequently in economics, the Kuhn-Tucker conditions provides a method that often makes it easier to both calculate the critical points and identify points that are (local) maxima.\nGiven a two-dimensional set-up: \\[\\max_{x_1,x_2}/\\min_{x_1,x_2} f(x_1,x_2) \\text{ s.t. }\n\\begin{array}{l}\nc(x_1,x_2) \\le a_1\\\\\nx_1 \\ge 0 \\\\\ngx_2 \\ge 0\n\\end{array}\\]\nWe define the Lagrangian function \\(L(x_1,x_2,\\lambda_1)\\) the same as if we did not have the non-negativity constraints: \\[L(x_1,x_2,\\lambda_2) = f(x_1,x_2) - \\lambda_1(c(x_1,x_2) - a_1)\\]\nMore generally, in n dimensions: \\[ L(x_1, \\dots, x_n, \\lambda_1, \\dots, \\lambda_k) = f(x_1, \\dots, x_n) - \\sum_{i=1}^k\\lambda_i(c_i(x_1,\\dots, x_n) - a_i)\\]\nKuhn-Tucker and Complementary Slackness Conditions: To find the critical points, we first calculate the Kuhn-Tucker conditions by taking the partial derivatives of the lagrangian function, \\(L(x_1,\\dots,x_n,\\lambda_1,\\dots,\\lambda_k)\\), with respect to each of its variables (all choice variables \\(x\\) and all lagrangian multipliers \\(\\lambda\\)) and we calculate the complementary slackness conditions by multiplying each partial derivative by its respective variable and include non-negativity conditions for all variables (choice variables \\(x\\) and lagrangian multipliers \\(\\lambda\\)).\nKuhn-Tucker Conditions\n\\[\\begin{align*}\n\\frac{\\partial L}{\\partial x_1} \\leq 0, & \\dots, \\frac{\\partial L}{\\partial x_n} \\leq 0\\\\\n\\frac{\\partial L}{\\partial \\lambda_1} \\geq 0, & \\dots, \\frac{\\partial L}{\\partial \\lambda_m} \\geq 0\n\\end{align*}\\]\nComplementary Slackness Conditions\n\\[\\begin{align*}\nx_1\\frac{\\partial L}{\\partial x_1} = 0, & \\dots, x_n\\frac{\\partial L}{\\partial x_n} = 0\\\\\n\\lambda_1\\frac{\\partial L}{\\partial \\lambda_1} = 0, & \\dots, \\lambda_m \\frac{\\partial L}{\\partial \\lambda_m} = 0\n\\end{align*}\\]\nNon-negativity Conditions \\[\\begin{eqnarray*}\nx_1 \\geq 0 & \\dots & x_n \\geq 0\\\\\n\\lambda_1 \\geq 0 & \\dots & \\lambda_m \\geq 0\n\\end{eqnarray*}\\]\nNote that some of these conditions are set equal to 0, while others are set as inequalities!\nNote also that to minimize the function \\(f(x_1, \\dots, x_n)\\), the simplest thing to do is maximize the function \\(-f(x_1, \\dots, x_n)\\); all of the conditions remain the same after reformulating as a maximization problem.\nThere are additional assumptions (notably, f(x) is quasi-concave and the constraints are convex) that are sufficient to ensure that a point satisfying the Kuhn-Tucker conditions is a global max; if these assumptions do not hold, you may have to check more than one point.\nFinding the Critical Points with Kuhn-Tucker Conditions: Given the above conditions, to find the critical points we solve the above system of equations. To do so, we must check border and interior solutions to see if they satisfy the above conditions.\nIn a two-dimensional set-up, this means we must check the following cases:\n\n\\(x_1 = 0, x_2 = 0\\) Border Solution\n\\(x_1 = 0, x_2 \\neq 0\\) Border Solution\n\\(x_1 \\neq 0, x_2 = 0\\) Border Solution\n\\(x_1 \\neq 0, x_2 \\neq 0\\) Interior Solution\n\n\nExample 5.5 (Kuhn-Tucker with two variables) Solve the following optimization problem with inequality constraints \\[\\max_{x_1,x_2} f(x) = -(x_1^2 + 2x_2^2)\\]\n\\[\\begin{align*}\n\\text{ s.t. }\n\\begin{cases}\n&x_1 + x_2 *\\le 4\\\\\n&x_1 *\\ge 0\\\\\n&x_2 *\\ge 0\n\\end{cases}\n\\end{align*}\\]\n\n\nWrite the Lagrangian: \\[L(x_1, x_2, \\lambda) =  -(x_1^2 + 2x_2^2) - \\lambda(x_1 + x_2 - 4)\\]\nFind the First Order Conditions:\n\nKuhn-Tucker Conditions \\[\\begin{align*}\n\\frac{\\partial L}{\\partial x_1} = -2x_1 - \\lambda  &\\leq 0\\\\\n\\frac{\\partial L}{\\partial x_2}  = -4x_2 - \\lambda & \\leq  0\\\\\n\\frac{\\partial L}{\\partial \\lambda} = -(x_1 + x_2 - 4)& \\geq 0\n\\end{align*}\\]\nComplementary Slackness Conditions \\[\\begin{align*}\nx_1\\frac{\\partial L}{\\partial x_2} = x_1(-2x_1 - \\lambda)  &= 0\\\\\nx_2\\frac{\\partial L}{\\partial x_2} = x_2(-4x_2 - \\lambda)  &= 0\\\\\n\\lambda\\frac{\\partial L}{\\partial \\lambda} = -\\lambda(x_1 + x_2 - 4)&= 0\n\\end{align*}\\]\nNon-negativity Conditions \\[\\begin{align*}\nx_1 & \\geq  0\\\\\nx_2 & \\geq 0\\\\\n\\lambda & \\geq 0\n\\end{align*}\\]\n\nConsider all border and interior cases:\nFind Maximum: Three of the critical points violate the requirement that \\(\\lambda \\geq 0\\), so the point \\((0,0,0)\\) is the maximum.\n\n\nExercise 5.4 (Kuhn-Tucker with logs) \\[\\max_{x_1,x_2} f(x) = \\frac{1}{3}\\log (x_1 + 1) + \\frac{2}{3}\\log (x_2 + 1) \\text{ s.t. }  \n\\begin{array}{l}\nx_1 + 2x_2 \\leq 4\\\\\n     x_1 \\geq 0\\\\\n    x_2 \\geq 0\n\\end{array}\\]"
  },
  {
    "objectID": "05_optimization.html#applications-of-quadratic-forms",
    "href": "05_optimization.html#applications-of-quadratic-forms",
    "title": "5  Optimization",
    "section": "5.8 Applications of Quadratic Forms",
    "text": "5.8 Applications of Quadratic Forms\nCurvature and The Taylor Polynomial as a Quadratic Form: The Hessian is used in a Taylor polynomial approximation to \\(f(\\mathbf{x})\\) and provides information about the curvature of \\(f({\\mathbf x})\\) at \\(\\mathbf{x}\\) — e.g., which tells us whether a critical point \\(\\mathbf{x}^*\\) is a min, max, or saddle point.\n\nThe second order Taylor polynomial about the critical point \\({\\mathbf x}^*\\) is \\[f({\\mathbf x}^*+\\mathbf h)=f({\\mathbf x}^*)+\\nabla f({\\mathbf x}^*) \\mathbf h +\\frac{1}{2} \\mathbf h^\\top\n{\\mathbf H(x^*)} \\mathbf h + R(\\mathbf h)\\]\nSince we’re looking at a critical point, \\(\\nabla f({\\mathbf x}^*)=0\\); and for small \\(\\mathbf h\\), \\(R(\\mathbf h)\\) is negligible. Rearranging, we get \\[f({\\mathbf x}^*+\\mathbf h)-f({\\mathbf x}^*)\\approx \\frac{1}{2} \\mathbf h^\\top {\\mathbf H(x^*)}\n\\mathbf h \\]\nThe Righthand side here is a quadratic form and we can determine the definiteness of \\(\\mathbf H(x^*)\\)."
  },
  {
    "objectID": "06_probability.html",
    "href": "06_probability.html",
    "title": "6  Probability Theory",
    "section": "",
    "text": "Probability and Inferences are mirror images of each other, and both are integral to social science. Probability quantifies uncertainty, which is important because many things in the social world are at first uncertain. Inference is then the study of how to learn about facts you don’t observe from facts you do observe."
  },
  {
    "objectID": "06_probability.html#counting-rules",
    "href": "06_probability.html#counting-rules",
    "title": "6  Probability Theory",
    "section": "6.1 Counting rules",
    "text": "6.1 Counting rules\nProbability in high school is usually really about combinatorics: the probability of event A is the number of ways in which A can occur divided by the number of all other possibilities. This is a very simplified version of probability, which we can call the “counting definition of probability”, essentially because each possible event to count is often equally likely and discrete. But it is still good to review the underlying rules here.\nFundamental Theorem of Counting: If an object has \\(j\\) different characteristics that are independent of each other, and each characteristic \\(i\\) has \\(n_i\\) ways of being expressed, then there are \\(\\prod_{i = 1}^j n_i\\) possible unique objects.\n\nExample 6.1 (Counting Possibilities) Suppose we are given a stack of cards. Cards can be either red or black and can take on any of 13 values. There is only one of each color-number combination. In this case,\n\n\\(j =\\)\n\\(n_{\\text{color}} =\\)\n\\(n_{\\text{number}} =\\)\nNumber of Outcomes \\(=\\)\n\n\nWe often need to count the number of ways to choose a subset from some set of possibilities. The number of outcomes depends on two characteristics of the process: does the order matter and is replacement allowed?\nIt is useful to think of any problem concretely, e.g. through a sampling table: If there are \\(n\\) objects which are numbered 1 to \\(n\\) and we select \\(k < n\\) of them, how many different outcomes are possible?\nIf the order in which a given object is selected matters, selecting 4 numbered objects in the following order (1, 3, 7, 2) and selecting the same four objects but in a different order such as (7, 2, 1, 3) will be counted as different outcomes.\nIf replacement is allowed, there are always the same \\(n\\) objects to select from. However, if replacement is not allowed, there is always one less option than the previous round when making a selection. For example, if replacement is not allowed and I am selecting 3 elements from the following set {1, 2, 3, 4, 5, 6}, I will have 6 options at first, 5 options as I make my second selection, and 4 options as I make my third.\n\nSo if order matters AND we are sampling with replacement, the number of different outcomes is \\(n^k\\).\nIf order matters AND we are sampling without replacement, the number of different outcomes is \\(n(n-1)(n-2)...(n-k+1)=\\frac{n!}{(n-k)!}\\).\nIf order doesn’t matter AND we are sampling without replacement, the number of different outcomes is \\(\\binom{n}{k} = \\frac{n!}{(n-k)!k!}\\).\n\nExpression \\(\\binom{n}{k}\\) is read as “n choose k” and denotes \\(\\frac{n!}{(n-k)!k!}\\). Also, note that \\(0! = 1\\).\n\nExample 6.2 (Counting) There are five balls numbered from 1 through 5 in a jar. Three balls are chosen. How many possible choices are there?\n\nOrdered, with replacement \\(=\\)\nOrdered, without replacement \\(=\\)\nUnordered, without replacement \\(=\\)"
  },
  {
    "objectID": "06_probability.html#sec-probdef",
    "href": "06_probability.html#sec-probdef",
    "title": "6  Probability Theory",
    "section": "7.1 Probability",
    "text": "7.1 Probability\n\nProbability Definitions: Formal and Informal\nMany things in the world are uncertain. In everyday speech, we say that we are uncertain about the outcome of random events. Probability is a formal model of uncertainty which provides a measure of uncertainty governed by a particular set of rules. A different model of uncertainty would, of course, have a set of rules different from anything we discuss here. Our focus on probability is justified because it has proven to be a particularly useful model of uncertainty.\nSample Space (S): A set or collection of all possible outcomes from some process. Outcomes in the set can be discrete elements (countable) or points along a continuous interval (uncountable).\nProbability Distribution Function: a mapping of each event in the sample space \\(S\\) to the real numbers that satisfy the following three axioms (also called Kolmogorov’s Axioms).\nFormally,\n\nDefinition 7.1 (Probability) Probability is a function that maps events from a sample space to a real number, obeying the axioms of probability.\n\nThe axioms of probability make sure that the separate events add up in terms of probability, and – for standardization purposes – that they add up to 1.\n\n\nDefinition 7.2 (Axioms of Probability) \nFor any event \\(A\\), \\(P(A)\\ge 0\\).\n\\(P(S)=1\\)\nThe Countable Additivity Axiom: For any sequence of disjoint (mutually exclusive) events \\(A_1,A_2,\\ldots\\) (of which there may be infinitely many), \\[P\\left( \\bigcup\\limits_{i=1}^k\nA_i\\right)=\\sum\\limits_{i=1}^k P(A_i)\\]\n\nThe last axiom is an extension of a union to infinite sets. When there are only two events in the space, it boils down to:\n\\[\\begin{align*}\nP(A_1 \\cup A_2) = P(A_1) + P(A_2) \\quad\\text{for disjoint } A_1, A_2\n\\end{align*}\\]\n\n\n\nProbability Operations\nUsing these three axioms, we can define all of the common rules of probability.\n\n\\(P(\\emptyset)=0\\)\nFor any event \\(A\\), \\(0\\le P(A) \\le 1\\).\n\\(P({A}^C)=1-P(A)\\)\nIf \\(A\\subset B\\) (\\(A\\) is a subset of \\(B\\)), then \\(P(A)\\le P(B)\\).\nFor any two events \\(A\\) and \\(B\\), \\(P(A\\cup B)=P(A)+P(B)-P(A\\cap B)\\)\nBoole’s Inequality: For any sequence of \\(n\\) events (which need not be disjoint) \\(A_1,A_2,\\ldots,A_n\\), then \\(P\\left( \\bigcup\\limits_{i=1}^n A_i\\right) \\leq \\sum\\limits_{i=1}^n P(A_i)\\).\n\n\nExample 7.1 (Probability) Assume we have an evenly-balanced, six-sided die.\nThen,\n\nSample space S =\n\\(P(1)=\\cdots=P(6)=\\)\n\\(P(\\emptyset)=P(7)=\\)\n\\(P\\left( \\{ 1, 3, 5 \\} \\right)=\\)\n\\(P\\left( \\{ 1, 2 \\}^C \\right)= P\\left( \\{ 3, 4, 5, 6 \\}\\right)=\\)\nLet \\(A=\\{ 1,2,3,4,5 \\}\\subset S\\). Then \\(P(A)=5/6<P(S)=\\)\nLet \\(A=\\{ 1, 2, 3 \\}\\) and \\(B=\\{ 2, 4, 6 \\}\\). Then \\(A\\cup B\\)? \\(A\\cap B\\)? \\(P(A \\cup B)\\)?\n\n\n\nExercise 7.1 (Probability) Suppose you had a pair of four-sided dice. You sum the results from a single toss. Let us call this sum, or the outcome, X.\n\nWhat is \\(P(X = 5)\\), \\(P(X = 3)\\), \\(P(X = 6)\\)?\nWhat is \\(P(X=5 \\cup X = 3)^C\\)?"
  },
  {
    "objectID": "06_probability.html#conditional-probability-and-bayes-rule",
    "href": "06_probability.html#conditional-probability-and-bayes-rule",
    "title": "6  Probability Theory",
    "section": "7.2 Conditional Probability and Bayes Rule",
    "text": "7.2 Conditional Probability and Bayes Rule\nConditional Probability: The conditional probability \\(P(A|B)\\) of an event \\(A\\) is the probability of \\(A\\), given that another event \\(B\\) has occurred. Conditional probability allows for the inclusion of other information into the calculation of the probability of an event. It is calculated as\n\\[P(A|B)=\\frac{P(A\\cap B)}{P(B)}\\]\nNote that conditional probabilities are probabilities and must also follow the Kolmagorov axioms of probability.\n\nExample 7.2 (Conditional Probability 1) Assume \\(A\\) and \\(B\\) occur with the following frequencies: \\(\\quad\\)\n\n\n\n\n\\(A\\)\n\\(A^c\\)\n\n\n\n\n\\(B\\)\n\\(n_{ab}\\)\n\\(n_{a^cb}\\)\n\n\n\\(B^C\\)\n\\(n_{ab^c}\\)\n\\(n_{(ab)^c}\\)\n\n\n\nand let \\(n_{ab}+n_{a^Cb}+n_{ab^C}+n_{(ab)^C}=N\\). Then\n\n\\(P(A)=\\)\n\\(P(B)=\\)\n\\(P(A\\cap B)=\\)\n\\(P(A|B)= \\frac{P(A\\cap B)}{P(B)}=\\)\n\\(P(B|A)= \\frac{P(A\\cap B)}{P(A)}=\\)\n\n\n\nExample 7.3 (Conditional Probability 2) A six-sided die is rolled. What is the probability of a 1, given the outcome is an odd number?\n\nYou could rearrange the fraction to highlight how a joint probability could be expressed as the product of a conditional probability.\n\nDefinition 7.3 (Multiplicative Law of Probability) The probability of the intersection of two events \\(A\\) and \\(B\\) is \\(P(A\\cap B)=P(A)P(B|A)=P(B)P(A|B)\\) which follows directly from the definition of conditional probability. More generally,\n\\[P(A_1\\cap \\cdots\\cap A_k) = P(A_k| A_{k-1}\\cap \\cdots \\cap A_1)\\times P(A_{k-1}|A_{k-2}\\cap \\cdots A_1) \\times \\ldots \\times P(A_2|A_1)\\times P(A_1)\\]\nSometimes it is easier to calculate these conditional probabilities and sum them than it is to calculate \\(P(A)\\) directly.\n\n\nDefinition 7.4 (Law of total probability) Let \\(S\\) be the sample space of some experiment and let the disjoint \\(k\\) events \\(B_1,\\ldots,B_k\\) partition \\(S\\), such that \\(P(B_1\\cup ... \\cup B_k) = P(S) = 1\\). If \\(A\\) is some other event in \\(S\\), then the events \\(A\\cap B_1, A\\cap B_2, \\ldots, A\\cap B_k\\) will form a partition of \\(A\\) and we can write \\(A\\) as \\[A=(A\\cap B_1)\\cup\\cdots\\cup (A\\cap B_k)\\].\nSince the \\(k\\) events are disjoint,\n\\[\\begin{eqnarray*}\nP(A)&=&\\sum\\limits_{i=1}^k P(A \\cap B_i)\\\\\n      &=&\\sum\\limits_{i=1}^k P(B_i)P(A|B_i)\n\\end{eqnarray*}\\]\n\nBayes Rule: Assume that events \\(B_1,\\ldots,B_k\\) form a partition of the space \\(S\\). Then by the Law of Total Probability\n\\[P(B_j|A)= \\frac{P(A \\cap B_j)} {P(A)} = \\frac{P(B_j) P(A|B_j)}{\\sum\\limits_{i=1}^k P(B_i)P(A|B_i)}\\]\nIf there are only two states of \\(B\\), then this is just \\[P(B_1|A)=\\frac{P(B_1)P(A|B_1)} {P(B_1)P(A|B_1)+P(B_2)P(A|B_2)}\\]\nBayes’ rule determines the posterior probability of a state \\(P(B_j|A)\\) by calculating the probability \\(P(A \\cap B_j)\\) that both the event \\(A\\) and the state \\(B_j\\) will occur and dividing it by the probability that the event will occur regardless of the state (by summing across all \\(B_i\\)). The states could be something like Normal/Defective, Healthy/Diseased, Republican/Democrat/Independent, etc. The event on which one conditions could be something like a sampling from a batch of components, a test for a disease, or a question about a policy position.\nPrior and Posterior Probabilities: Above, \\(P(B_1)\\) is often called the prior probability, since it’s the probability of \\(B_1\\) before anything else is known. \\(P(B_1|A)\\) is called the posterior probability, since it’s the probability after other information is taken into account.\n\nExample 7.4 (Bayes’ Rule) In a given town, 40% of the voters are Democrat and 60% are Republican. The president’s budget is supported by 50% of the Democrats and 90% of the Republicans. If a randomly (equally likely) selected voter is found to support the president’s budget, what is the probability that they are a Democrat?\n\n\nExercise 7.2 (Conditional Probability) Assume that 2% of the population of the U.S. are members of some extremist militia group. We develop a survey that positively classifies someone as being a member of a militia group given that they are a member 95% of the time and negatively classifies someone as not being a member of a militia group given that they are not a member 97% of the time. What is the probability that someone positively classified as being a member of a militia group is actually a militia member?"
  },
  {
    "objectID": "06_probability.html#independence",
    "href": "06_probability.html#independence",
    "title": "6  Probability Theory",
    "section": "7.3 Independence",
    "text": "7.3 Independence\n\nDefinition 7.5 (Independence) If the occurrence or nonoccurrence of either events \\(A\\) and \\(B\\) provides no information about the occurrence or nonoccurrence of the other, then \\(A\\) and \\(B\\) are independent.\n\nIf \\(A\\) and \\(B\\) are independent, then\n\n\\(P(A|B)=P(A)\\)\n\\(P(B|A)=P(B)\\)\n\\(P(A\\cap B)=P(A)P(B)\\)\nMore generally than the above, \\(P(\\bigcap_{i=1}^k A_i) = \\prod_{i = 1}^K P(A_i)\\)\n\nAre mutually exclusive events independent of each other?\nNo. If A and B are mutually exclusive, then they cannot happen simultaneously. If we know that A occurred, then we know that B couldn’t have occurred. Because of this, A and B aren’t independent.\nPairwise Independence: A set of more than two events \\(A_1, A_2, \\dots, A_k\\) is pairwise independent if \\(P(A_i\\cap A_j)=P(A_i)P(A_j)\\), \\(\\forall i\\neq j\\). Note that this does not necessarily imply joint independence.\nConditional Independence: If \\(A\\) and \\(B\\) are independent once you know the occurrence of a third event \\(C\\), then \\(A\\) and \\(B\\) are conditionally independent (conditional on \\(C\\)):\n\n\\(P(A|B \\cap C)=P(A|C)\\)\n\\(P(B|A \\cap C)=P(B|C)\\)\n\\(P(A\\cap B|C)=P(A|C)P(B|C)\\)\n\nJust because two events are conditionally independent does not mean that they are independent. Actually it is hard to think of real-world things that are “unconditionally” independent. That’s why it’s always important to ask about a finding: What was it conditioned on? For example, suppose that a graduate school admission decisions are done by only one professor, who picks a group of 50 bright students and flips a coin for each student to generate a class of about 25 students. Then the the probability that two students get accepted are conditionally independent, because they are determined by two separate coin tosses. However, this does not mean that their admittance is not completely independent. Knowing that student \\(A\\) got in gives us information about whether student \\(B\\) got in, if we think that the professor originally picked her pool of 50 students by merit.\nPerhaps more counter-intuitively: If two events are already independent, then it might seem that no amount of “conditioning” will make them dependent. But this is not always so. For example, imagine that you own a house with a lawn (a very extreme hypothetical!) Let \\(A\\) be the event that it rained yesterday and \\(B\\) the event that your sprinkler system went off yesterday. Suppose that your sprinkler system is set to randomly go off and so \\(A\\) and \\(B\\) are independent of one another. \\(P(A \\mid B) = P(A).\\) But now let \\(C\\) be the event that the grass is wet. The grass can be wet either due to the rain or due to the sprinkler. For conditional independence to hold here, then \\(P(A \\mid C)\\) must be equal to \\(P(A \\mid B \\cap C).\\) But this is not true.\nLet \\(P(A) = .5\\) and \\(P(B) = .5\\).\nThe marginal probability \\(P(C)\\) is\n\\[P(C) = P(A \\cup B) = P(A) + P(B) - P(A \\cap B) = .75\\] The conditional probability \\(P(A | C)\\) is\n\\[P(A|C) = \\frac{P(C|A)P(A)}{P(C)} = \\frac{1 \\times .5}{.75} = \\frac{2}{3}\\]\nThe conditional probability \\(P(A | B \\cap C)\\) is\n\\[P(A | B \\cap C) = \\frac{P(C \\cap B| A) P(A)}{P(C \\cap B)} = \\frac{P(C \\cap B| A) P(A)}{P(C|B)P(B)}  \\frac{.5\\times .5}{.5} = \\frac{1}{2}\\] Intuitively, given that the grass is wet, knowing that it rained yesterday tells us that it is less likely that the sprinkler also went off!"
  },
  {
    "objectID": "06_probability.html#random-variables",
    "href": "06_probability.html#random-variables",
    "title": "6  Probability Theory",
    "section": "7.4 Random Variables",
    "text": "7.4 Random Variables\nMost questions in the social sciences involve events, rather than numbers per se. To analyze and reason about events quantitatively, we need a way of mapping events to numbers. A random variable does exactly that.\n\n\n\n\n\nFigure 7.1: The Random Variable as a Real-Valued Function\n\n\n\n\n\nDefinition 7.6 (Random Variable) A random variable is a measurable function \\(X\\) that maps from the sample space \\(S\\) to the set of real numbers \\(R.\\) It assigns a real number to every outcome \\(s \\in S\\).\n\nFigure 7.1 shows a image of the function. It might seem strange to define a random variable as a function – which is neither random nor variable. The randomness comes from the realization of an event from the sample space \\(s\\).\nRandomness means that the outcome of some experiment is not deterministic, i.e. there is some probability (\\(0 < P(A) < 1\\)) that the event will occur.\nThe support of a random variable is all values for which there is a positive probability of occurrence.\nExample: Flip a fair coin two times. What is the sample space?\nA random variable must map events to the real line. For example, let a random variable \\(X\\) be the number of heads. The event \\((H, H)\\) gets mapped to 2 \\(X(s) = 2\\), and the events \\(\\{(H, T), (T, H)\\}\\) gets mapped to 1 \\((X(s) = 1)\\), the event \\((T, T)\\) gets mapped to 0 \\((X(s) = 0)\\).\nWhat are other possible random variables?"
  },
  {
    "objectID": "06_probability.html#distributions",
    "href": "06_probability.html#distributions",
    "title": "6  Probability Theory",
    "section": "7.5 Distributions",
    "text": "7.5 Distributions\nWe now have two main concepts in this section – probability and random variables. Given a sample space \\(S\\) and the same experiment, both probability and random variables take events as their inputs. But they output different things (probabilities measure the “size” of events, random variables give a number in a way that the analyst chose to define the random variable). How do the two concepts relate?\nThe concept of distributions is the natural bridge between these two concepts.\n\nDefinition 7.7 (Distribution of a random variable) A distribution of a random variable is a function that specifies the probabilities of all events associated with that random variable. There are several types of distributions: A probability mass function for a discrete random variable and probability density function for a continuous random variable.\n\nNotice how the definition of distributions combines two ideas of random variables and probabilities of events. First, the distribution considers a random variable, call it \\(X\\). \\(X\\) can take a number of possible numeric values.\n\nExample 7.5 (Total Number of Occurrences) Consider three binary outcomes, one for each patient recovering from a disease: \\(R_i\\) denotes the event in which patient \\(i\\) (\\(i = 1, 2, 3\\)) recovers from a disease. \\(R_1\\), \\(R_2\\), and \\(R_3\\). How would we represent the total number of people who end up recovering from the disease?\n\n\nSolution. Define the random variable \\(X\\) be the total number of people (out of three) who recover from the disease. Random variables are functions, that take as an input a set of events (in the sample space \\(S\\)) and deterministically assigns them to a number of the analyst’s choice.\n\nRecall that with each of these numerical values there is a class of events. In the previous example, for \\(X = 3\\) there is one outcome (\\(R_1, R_2, R_3\\)) and for \\(X = 1\\) there are multiple (\\(\\{(R_1, R_2^c, R_3^c), (R_1^c, R_2, R_3^c), (R_1^c, R_2^c, R_3), \\}\\)). Now, the thing to notice here is that each of these events naturally come with a probability associated with them. That is, \\(P(R_1, R_2, R_3)\\) is a number from 0 to 1, as is \\(P(R_1, R_2^c, R_3^c)\\). These all have probabilities because they are in the sample space \\(S\\). The function that tells us these probabilities that are associated with a numerical value of a random variable is called a distribution.\nIn other words, a random variable \\(X\\) induces a probability distribution \\(P\\) (sometimes written \\(P_X\\) to emphasize that the probability density is about the r.v. \\(X\\))\n\nDiscrete Random Variables\nThe formal definition of a random variable is easier to given by separating out two cases: discrete random variables when the numeric summaries of the events are discrete, and continuous random variables when they are continuous.\n\nDefinition 7.8 (Discrete Random Variable) \\(X\\) is a discrete random variable if it can assume only a finite or countably infinite number of distinct values. Examples: number of wars per year, heads or tails.\n\nThe distribution of a discrete r.v. is a PMF:\n\nDefinition 7.9 (Probability Mass Function) For a discrete random variable \\(X\\), the probability mass function (Also referred to simply as the “probability distribution.”) (PMF), \\(p(x)=P(X=x)\\), assigns probabilities to a countable number of distinct \\(x\\) values such that\n\n\\(0\\le p(x)\\le 1\\)\n\\(\\sum\\limits_y p(x)=1\\)\n\n\nExample: For a fair six-sided die, there is an equal probability of rolling any number. Since there are six sides, the probability mass function is then \\(p(y)=1/6\\) for \\(y=1,\\ldots,6\\), 0 otherwise.}\nIn a discrete random variable, cumulative distribution function , \\(F(x)\\) or \\(P(X\\le x)\\), is the probability that \\(X\\) is less than or equal to some value \\(x\\), or \\[P(X\\le x)=\\sum\\limits_{i\\le x} p(i)\\]\nProperties a CDF must satisfy:\n\n\\(F(x)\\) is non-decreasing in \\(x\\).\n\\(\\lim\\limits_{x \\to -\\infty} F(x) = 0\\) and \\(\\lim\\limits_{x \\to \\infty} F(x) = 1\\)\n\\(F(x)\\) is right-continuous.\n\nNote that \\(P(X > x) = 1 - P(X \\le x)\\).\n\nDefinition 7.10 For a fair six-sided die with its value as \\(Y\\), What are the following?\n\n\\(P(Y\\le 1)\\)\n\\(P(Y\\le 3)\\)\n\\(P(Y\\le 6)\\)\n\n\n\n\nContinuous Random Variables\nWe also have a similar definition for continuous random variables.\n\nDefinition 7.11 (Continuous Random Variable) \\(X\\) is a continuous random variable if there exists a nonnegative function \\(f(x)\\) defined for all real \\(x\\in (-\\infty,\\infty)\\), such that for any interval \\(A\\), \\(P(X\\in A)=\\int\\limits_A f(x)dx\\). Examples: age, income, GNP, temperature.\n\n\nDefinition 7.12 (Probability density function) The function \\(f\\) above is called the probability density function (pdf) of \\(X\\) and must satisfy \\[f(x)\\ge 0\\] \\[\\int\\limits_{-\\infty}^\\infty f(x)dx=1\\]\nNote also that \\(P(X = x)=0\\) — i.e., the probability of any point \\(y\\) is zero.\n\nWhile continuous random variables do not have a PMF (since the PMF would be \\(0\\) at every point), the cumulative distribution function is defined in the exact same way. The cumulative distribution gives the probability that \\(Y\\) lies on the interval \\((-\\infty,y)\\) and is defined as \\[F(x)=P(X\\le x)=\\int\\limits_{-\\infty}^x f(s)ds\\]\nWe can also make statements about the probability of \\(Y\\) falling in an interval \\(a\\le y\\le b\\). \\[P(a\\le x\\le b)=\\int\\limits_a^b f(x)dx\\]\nThe PDF and CDF are linked by the integral: The CDF of the integral of the PDF: \\[f(x) = F'(x)=\\frac{dF(x)}{dx}\\]\n\nExample 7.6 (Continuous R.V.) For \\(f(y)=1, \\quad 0<y<1\\), find: (1) The CDF \\(F(y)\\) and (2) The probability \\(P(0.5<y<0.75)\\)."
  },
  {
    "objectID": "06_probability.html#joint-distributions",
    "href": "06_probability.html#joint-distributions",
    "title": "6  Probability Theory",
    "section": "7.6 Joint Distributions",
    "text": "7.6 Joint Distributions\nOften, we are interested in two or more random variables defined on the same sample space. The distribution of these variables is called a joint distribution. Joint distributions can be made up of any combination of discrete and continuous random variables.\nJoint Probability Distribution: If both \\(X\\) and \\(Y\\) are random variable, their joint probability mass/density function assigns probabilities to each pair of outcomes\nDiscrete:\n\\[p(x, y) = P(X = x, Y = y)\\]\nsuch that \\(p(x,y) \\in [0,1]\\) and \\[\\sum\\sum p(x,y) = 1\\]\nContinuous:\n\\[f(x,y);P((X,Y) \\in A) = \\int\\!\\!\\!\\int_A f(x,y)dx dy \\]\ns.t. \\(f(x,y)\\ge 0\\) and\n\\[\\int_{-\\infty}^\\infty\\int_{-\\infty}^\\infty f(x,y)dxdy = 1\\]\nIf X and Y are independent, then \\(P(X=x,Y=y) = P(X=x)P(Y=y)\\) and \\(f(x,y) = f(x)f(y)\\)\nMarginal Probability Distribution: probability distribution of only one of the two variables (ignoring information about the other variable), we can obtain the marginal distribution by summing/integrating across the variable that we don’t care about:\n\nDiscrete: \\(p_X(x) = \\sum_i p(x, y_i)\\)\nContinuous: \\(f_X(x) = \\int_{-\\infty}^\\infty f(x,y)dy\\)\n\nConditional Probability Distribution: probability distribution for one variable, holding the other variable fixed. Recalling from the previous lecture that \\(P(A|B)=\\frac{P(A\\cap B)}{P(B)}\\), we can write the conditional distribution as\n\nDiscrete: \\(p_{Y|X}(y|x) = \\frac{p(x,y)}{p_X(x)}, \\quad p_X(x) > 0\\)\nContinuous: \\(f_{Y|X}(y|x) = \\frac{f(x,y)}{f_X(x)},\\quad f_X(x) > 0\\)\n\n\nExercise 7.3 (Discrete, Joint Distributions) Suppose we are interested in the outcomes of flipping a coin and rolling a 6-sided die at the same time. The sample space for this process contains 12 elements: \\[\\{(H, 1), (H, 2), (H, 3), (H, 4), (H, 5), (H, 6), (T, 1), (T, 2), (T, 3), (T, 4), (T, 5), (T, 6)\\}\\] We can define two random variables \\(X\\) and \\(Y\\) such that \\(X = 1\\) if heads and \\(X = 0\\) if tails, while \\(Y\\) equals the number on the die.\nWe can then make statements about the joint distribution of \\(X\\) and \\(Y\\). What are the following?\n\n\\(P(X=x)\\)\n\\(P(Y=y)\\)\n\\(P(X=x, Y=y)\\)\n\\(P(X=x|Y=y)\\)\nAre X and Y independent?"
  },
  {
    "objectID": "06_probability.html#expectation",
    "href": "06_probability.html#expectation",
    "title": "6  Probability Theory",
    "section": "7.7 Expectation",
    "text": "7.7 Expectation\nWe often want to summarize some characteristics of the distribution of a random variable. The most important summary is the expectation (or expected value, or mean), in which the possible values of a random variable are weighted by their probabilities.\n\nDefinition 7.13 (Expectation of a discrete R.V.) The expected value of a discrete random variable \\(Y\\) is \\[E(Y)=\\sum\\limits_{y} y P(Y=y)= \\sum\\limits_{y} y p(y)\\]\nIn words, it is the weighted average of all possible values of \\(Y\\), weighted by the probability that \\(y\\) occurs. It is not necessarily the number we would expect \\(Y\\) to take on, but the average value of \\(Y\\) after a large number of repetitions of an experiment.\n\n\nExample 7.7 (Expectation of a discrete R.V.) What is the expectation of a fair, six-sided die?\n\nExpectation of a Continuous Random Variable: The expected value of a continuous random variable is similar in concept to that of the discrete random variable, except that instead of summing using probabilities as weights, we integrate using the density to weight. Hence, the expected value of the continuous variable \\(Y\\) is defined by \\[E(Y)=\\int\\limits_{y} y f(y) dy\\]\n\nExample 7.8 (Expectation of a continuous R.V.) Find \\(E(Y)\\) for \\(f(y)=\\frac{1}{1.5}, \\quad 0<y<1.5\\).\n\n\nExpected Value of a Function\nRemember: An Expected Value is a type of weighted average. We can extend this to composite functions. For random variable \\(Y\\),\nIf \\(Y\\) is Discrete with PMF \\(p(y)\\),\n\\[E[g(Y)]=\\sum\\limits_y g(y)p(y)\\]\nIf \\(Y\\) is Continuous with PDF \\(f(y)\\),\n\\[E[g(Y)]=\\int\\limits_{-\\infty}^\\infty g(y)f(y)dy\\]\n\n\nProperties of Expected Values\nDealing with Expectations is easier when the thing inside is a sum. The intuition behind this that Expectation is an integral, which is a type of sum.\n\nExpectation of a constant is a constant \\[E(c)=c\\]\nConstants come out \\[E(c g(Y))= c E(g(Y))\\]\nExpectation is Linear \\[E(g(Y_1) + \\cdots + g(Y_n))=E(g(Y_1)) +\\cdots+E(g(Y_n)),\\] regardless of independence\nExpected Value of Expected Values: \\[E(E(Y)) = E(Y)\\] (because the expected value of a random variable is a constant)\n\nFinally, if \\(X\\) and \\(Y\\) are independent, even products are easy:\n\\[E(XY) = E(X)E(Y)\\]\nConditional Expectation: With joint distributions, we are often interested in the expected value of a variable \\(Y\\) if we could hold the other variable \\(X\\) fixed. This is the conditional expectation of \\(Y\\) given \\(X = x\\):\n\n\\(Y\\) discrete: \\(E(Y|X = x) = \\sum_y yp_{Y|X}(y|x)\\)\n\\(Y\\) continuous: \\(E(Y|X = x) = \\int_y yf_{Y|X}(y|x)dy\\)\n\nThe conditional expectation is often used for prediction when one knows the value of \\(X\\) but not \\(Y\\)"
  },
  {
    "objectID": "06_probability.html#variance-and-covariance",
    "href": "06_probability.html#variance-and-covariance",
    "title": "6  Probability Theory",
    "section": "7.8 Variance and Covariance",
    "text": "7.8 Variance and Covariance\nWe can also look at other summaries of the distribution, which build on the idea of taking expectations. Variance tells us about the “spread” of the distribution; it is the expected value of the squared deviations from the mean of the distribution. The standard deviation is simply the square root of the variance.\n\nDefinition 7.14 The Variance of a Random Variable \\(Y\\) is\n\\[\\text{Var}(Y) = E[(Y - E(Y))^2] =  E(Y^2)-[E(Y)]^2\\]\nThe Standard Deviation is the square root of the variance : \\[SD(Y) = \\sigma_Y= \\sqrt{\\text{Var}(Y)}\\]\n\n\nExample 7.9 Given the following PMF: \\[f(x) =  \\begin{cases}\n              \\frac{3!}{x!(3-x)!}(\\frac{1}{2})^3 \\quad x = 0,1,2,3\\\\\n               0 \\quad otherwise\n            \\end{cases}\n               \\]\nWhat is \\(\\text{Var}(x)\\)?\nHint: First calculate \\(E(X)\\) and \\(E(X^2)\\)\n\n\nDefinition 7.15 (Covariance) The covariance measures the degree to which two random variables vary together; if the covariance between \\(X\\) and \\(Y\\) is positive, X tends to be larger than its mean when Y is larger than its mean.\n\\[\\text{Cov}(X,Y) = E[(X - E(X))(Y - E(Y))] \\] We can also write this as\n\\[\\begin{align*}\n\\text{Cov}(X,Y) &= E\\left(XY - XE(Y) - E(X)Y + E(X)E(Y)\\right)\\\\\n&= E(XY) - E(X)E(Y) - E(X)E(Y) + E(X)E(Y)\\\\\n&= E(XY) - E(X)E(Y)\n\\end{align*}\\]\n\nThe covariance of a variable with itself is the variance of that variable.\nThe Covariance is unfortunately hard to interpret in magnitude. The correlation is a standardized version of the covariance, and always ranges from -1 to 1.\n\nDefinition 7.16 (Correlation) The correlation coefficient is the covariance divided by the standard deviations of \\(X\\) and \\(Y\\). It is a unitless measure and always takes on values in the interval \\([-1,1]\\).\n\\[\\text{Corr}(X, Y) = \\frac{\\text{Cov}(X,Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}} = \\frac{\\text{Cov}(X,Y)}{SD(X)SD(Y)}\\]\n\nProperties of Variance and Covariance:\n\n\\(\\text{Var}(c) = 0\\)\n\\(\\text{Var}(cY) = c^2 \\text{Var}(Y)\\)\n\\(\\text{Cov}(Y,Y) = \\text{Var}(Y)\\)\n\\(\\text{Cov}(X,Y) = \\text{Cov}(Y,X)\\)\n\\(\\text{Cov}(aX,bY) = ab \\text{Cov}(X,Y)\\)\n\\(\\text{Cov}(X+a,Y) = \\text{Cov}(X,Y)\\)\n\\(\\text{Cov}(X+Z,Y+W) = \\text{Cov}(X,Y) + \\text{Cov}(X,W) + \\text{Cov}(Z,Y) + \\text{Cov}(Z,W)\\)\n\\(\\text{Var}(X+Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X,Y)\\)\n\n\nExercise 7.4 (Expectation and Variance 1) Suppose we have a PMF with the following characteristics: \\[\\begin{eqnarray*}\n  P(X = -2) = \\frac{1}{5}\\\\\n  P(X = -1) = \\frac{1}{6}\\\\\n  P(X = 0) = \\frac{1}{5}\\\\\n  P(X = 1) = \\frac{1}{15}\\\\\n  P(X = 2) = \\frac{11}{30}\n\\end{eqnarray*}\\]\n\nCalculate the expected value of X\n\nDefine the random variable \\(Y = X^2\\).\n\nCalculate the expected value of Y. (Hint: It would help to derive the PMF of Y first in order to calculate the expected value of Y in a straightforward way)\nCalculate the variance of X.\n\n\n\n\nExercise 7.5 (Expectation and Variance 2) \nFind the expectation and variance\n\nGiven the following PDF: \\[f(x) =  \\begin{cases}\n              \\frac{3}{10}(3x - x^2) \\quad 0 \\leq x \\leq 2\\\\\n               0 \\quad otherwise\n            \\end{cases}\n               \\]\n\n\n\nExercise 7.6 (Expectation and Variance 3) \nFind the mean and standard deviation of random variable X. The PDF of this X is as follows:\n\n\\[f(x) =  \\begin{cases}\n              \\frac{1}{4}x \\quad 0 \\leq x \\leq 2\\\\\n               \\frac{1}{4}(4 - x)  \\quad 2 \\leq x \\leq 4\\\\\n               0 \\quad otherwise\n            \\end{cases}\n               \\]\n\nNext, calculate \\(P(X < \\mu - \\sigma)\\) Remember, \\(\\mu\\) is the mean and \\(\\sigma\\) is the standard deviation"
  },
  {
    "objectID": "06_probability.html#distributions-1",
    "href": "06_probability.html#distributions-1",
    "title": "6  Probability Theory",
    "section": "7.9 Distributions",
    "text": "7.9 Distributions\nA distribution is defined by its cumulative distribution function. There are many common distributions that have useful properties that appear in probability and statistics.\nTwo discrete distributions used often are:\n\nDefinition 7.17 (Binomial Distribution) \\(Y\\) is distributed binomial if it represents the number of “successes” observed in \\(n\\) independent, identical “trials,” where the probability of success in any trial is \\(p\\) and the probability of failure is \\(q=1-p\\).\n\nFor any particular sequence of \\(y\\) successes and \\(n-y\\) failures, the probability of obtaining that sequence is \\(p^y q^{n-y}\\) (by the multiplicative law and independence). However, there are \\(\\binom{n}{y}=\\frac{n!}{(n-y)!y!}\\) ways of obtaining a sequence with \\(y\\) successes and \\(n-y\\) failures. So the binomial distribution is given by \\[p(y)=\\binom{n}{y}p^y q^{n-y}, \\quad y=0,1,2,\\ldots,n\\] with mean \\(\\mu=E(Y)=np\\) and variance \\(\\sigma^2=\\text{Var}(Y)=npq\\).\n\nExample 7.10 (Binomial distribution) Republicans vote for Democrat-sponsored bills 2% of the time. What is the probability that out of 10 Republicans questioned, half voted for a particular Democrat-sponsored bill? What is the mean number of Republicans voting for Democrat-sponsored bills? The variance? 1. \\(P(Y=5)=\\) 1. \\(E(Y)=\\) 1. \\(\\text{Var}(Y)=6\\)\n\n\nDefinition 7.18 (Poisson Distribution) A random variable \\(Y\\) has a Poisson distribution if\n\\[P(Y = y)=\\frac{\\lambda^y}{y!}e^{-\\lambda}, \\quad y=0,1,2,\\ldots, \\quad \\lambda>0\\]\nThe Poisson has the unusual feature that its expectation equals its variance: \\(E(Y)=\\text{Var}(Y)=\\lambda\\). The Poisson distribution is often used to model rare event counts: counts of the number of events that occur during some unit of time. \\(\\lambda\\) is often called the “arrival rate.”\n\n\nExample 7.11 (Poisson Distribution) Border disputes occur between two countries through a Poisson Distribution, at a rate of 2 per month. What is the probability of 0, 2, and less than 5 disputes occurring in a month?\n\nTwo continuous distributions used often are:\n\nDefinition 7.19 (Uniform Distribution) A random variable \\(Y\\) has a continuous uniform distribution on the interval \\((\\alpha,\\beta)\\) if its density is given by \\[f(y)=\\frac{1}{\\beta-\\alpha}, \\quad \\alpha\\le y\\le \\beta\\] The mean and variance of \\(Y\\) are \\(E(Y)=\\frac{\\alpha+\\beta}{2}\\) and \\(\\text{Var}(Y)=\\frac{(\\beta-\\alpha)^2}{12}\\).\n\n\nExample 7.12 (Uniform) For \\(Y\\) uniformly distributed over \\((1,3)\\), what are the following probabilities?\n\n\\(P(Y=2)\\)\nIts density evaluated at 2, or \\(f(2)\\)\n\\(P(Y \\le 2)\\)\n\\(P(Y > 2)\\)\n\n\n\nDefinition 7.20 (Normal Distribution) A random variable \\(Y\\) is normally distributed with mean \\(E(Y)=\\mu\\) and variance \\(\\text{Var}(Y)=\\sigma^2\\) if its density is\n\\[f(y)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}}\\]\n\nSee Figure 7.2 are various Normal Distributions with the same \\(\\mu = 1\\) and two versions of the variance.\n\n\n\n\n\nFigure 7.2: Normal Distribution Density"
  },
  {
    "objectID": "06_probability.html#summarizing-observed-events-data",
    "href": "06_probability.html#summarizing-observed-events-data",
    "title": "6  Probability Theory",
    "section": "7.10 Summarizing Observed Events (Data)",
    "text": "7.10 Summarizing Observed Events (Data)\nSo far, we’ve talked about distributions in a theoretical sense, looking at different properties of random variables. We don’t observe random variables; we observe realizations of the random variable. These realizations of events are roughly equivalent to what we mean by “data”. We’ll spend more time in the intro class talking about this from the standpoint of estimands, estimators and estimates.\nSample mean: This is the most common measure of central tendency, calculated by summing across the observations and dividing by the number of observations. \\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\]\nDispersion: We also typically want to know how spread out the data are relative to the center of the observed distribution. There are several ways to measure dispersion.\nSample variance: The sample variance is the sum of the squared deviations from the sample mean, divided by the number of observations minus 1. \\[\\widehat{\\text{Var}}(X) = \\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\bar{x})^2\\]\nAgain, this is an estimator of the variance of a random variable; we divide by \\(n - 1\\) instead of \\(n\\) in order to get an unbiased estimator.\nStandard deviation: The sample standard deviation is the square root of the sample variance. \\[\\widehat{SD}(X) = \\sqrt{\\hat{\\text{Var}}(X)} = \\sqrt{\\frac{1}{n-1}\\sum_{i = 1}^n (x_i - \\bar{x})^2}\\]\nCovariance and Correlation: Both of these quantities measure the degree to which two variables vary together, and are estimates of the covariance and correlation of two random variables as defined above.\n\nSample covariance: \\(\\hat{\\text{Cov}}(X,Y) = \\frac{1}{n-1}\\sum_{i = 1}^n(x_i - \\bar{x})(y_i - \\bar{y})\\)\nSample correlation: \\(\\hat{\\text{Corr}} = \\frac{\\hat{\\text{Cov}}(X,Y)}{\\sqrt{\\hat{\\text{Var}}(X)\\hat{\\text{Var}}(Y)}}\\)\n\n\nExample 7.13 (Sample Covariance and Correlation) Example: Using the above table, calculate the sample versions of:\n\n\\(\\text{Cov}(X,Y)\\)\n\\(\\text{Corr}(X, Y)\\)"
  },
  {
    "objectID": "06_probability.html#asymptotic-theory",
    "href": "06_probability.html#asymptotic-theory",
    "title": "6  Probability Theory",
    "section": "7.11 Asymptotic Theory",
    "text": "7.11 Asymptotic Theory\nIn theoretical and applied research, asymptotic arguments are often made. In this section we briefly introduce some of this material.\nWhat are asymptotics? In probability theory, asymptotic analysis is the study of limiting behavior. By limiting behavior, we mean the behavior of some random process as the number of observations gets larger and larger.\nWhy is this important? We rarely know the true process governing the events we see in the social world. It is helpful to understand how such unknown processes theoretically must behave and asymptotic theory helps us do this.\n\n7.11.1 CLT and LLN\nWe are now finally ready to revisit, with a bit more precise terms, the two pillars of statistical theory we motivated Section @ref(limitsfun) with.\n\nTheorem 7.1 (Central Limit Theorem) Let \\(\\{X_n\\} = \\{X_1, X_2, \\ldots\\}\\) be a sequence of i.i.d. random variables with finite mean (\\(\\mu\\)) and variance (\\(\\sigma^2\\)). Then, the sample mean \\(\\bar{X}_n = \\frac{X_1 + X_2 + \\cdots + X_n}{n}\\) increasingly converges into a Normal distribution.\n\\[\\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\xrightarrow{d} \\text{Normal}(0, 1),\\]\nAnother way to write this as a probability statement is that for all real numbers \\(a\\),\n\\[P\\left(\\frac{\\bar{X}_n - \\mu}{\\sigma/\\sqrt{n}} \\le a\\right) \\rightarrow \\Phi(a)\\] as \\(n\\to \\infty\\), where \\[\\Phi(x) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}} \\, dx\\] is the CDF of a Normal distribution with mean 0 and variance 1.\nThis result means that, as \\(n\\) grows, the distribution of the sample mean \\(\\bar X_n = \\frac{1}{n} (X_1 + X_2 + \\cdots + X_n)\\) is approximately normal with mean \\(\\mu\\) and standard deviation \\(\\frac{\\sigma}{\\sqrt n}\\), i.e., \\[\\bar{X}_n \\approx \\mathcal{N}\\bigg(\\mu, \\frac{\\sigma^2}{n}\\bigg).\\] The standard deviation of \\(\\bar X_n\\) (which is roughly a measure of the precision of \\(\\bar X_n\\) as an estimator of \\(\\mu\\)) decreases at the rate \\(1/\\sqrt{n}\\), so, for example, to increase its precision by \\(10\\) (i.e., to get one more digit right), one needs to collect \\(10^2=100\\) times more units of data.\nIntuitively, this result also justifies that whenever a lot of small, independent processes somehow combine together to form the realized observations, practitioners often feel comfortable assuming Normality.\n\n\nTheorem 7.2 (Weak Law of Large Numbers (LLN)) For any draw of independent random variables with the same mean \\(\\mu\\), the sample average after \\(n\\) draws, \\(\\bar{X}_n = \\frac{1}{n}(X_1 + X_2 + \\ldots + X_n)\\), converges in probability to the expected value of \\(X\\), \\(\\mu\\) as \\(n \\rightarrow \\infty\\):\n\\[\\lim\\limits_{n\\to \\infty} P(|\\bar{X}_n - \\mu | > \\varepsilon) = 0\\]\nA shorthand of which is \\(\\bar{X}_n \\xrightarrow{p} \\mu\\), where the arrow is read as “converges in probability to” as \\(n\\to \\infty\\). In other words, \\(P( \\lim_{n\\to\\infty}\\bar{X}_n = \\mu) = 1\\). This is an important motivation for the widespread use of the sample mean, as well as the intuition link between averages and expected values.\n\nMore precisely this version of the LLN is called the weak law of large numbers because it leaves open the possibility that \\(|\\bar{X}_n - \\mu | > \\varepsilon\\) occurs many times. The strong law of large numbers states that, under a few more conditions, the probability that the limit of the sample average is the true mean is 1 (and other possibilities occur with probability 0), but the difference is rarely consequential in practice.\nThe Strong Law of Large Numbers holds so long as the expected value exists; no other assumptions are needed. However, the rate of convergence will differ greatly depending on the distribution underlying the observed data. When extreme observations occur often (i.e. kurtosis is large), the rate of convergence is much slower. Cf. The distribution of financial returns.\n\n\n7.11.2 Big \\(\\mathcal{O}\\) Notation\nSome of you may encounter “big-OH’’-notation. If \\(f, g\\) are two functions, we say that \\(f = \\mathcal{O}(g)\\) if there exists some constant, \\(c\\), such that \\(f(n) \\leq c \\times g(n)\\) for large enough \\(n\\). This notation is useful for simplifying complex problems in game theory, computer science, and statistics.\n\nExample 7.14 What is \\(\\mathcal{O}( 5\\exp(0.5 n) + n^2 + n / 2)\\)? Answer: \\(\\exp(n)\\). Why? Because, for large \\(n\\), \\[\n\\frac{ 5\\exp(0.5 n) + n^2 + n / 2 }{ \\exp(n)} \\leq \\frac{ c \\exp(n) }{ \\exp(n)} = c.\n\\] whenever \\(n > 4\\) and where \\(c = 1\\)."
  }
]